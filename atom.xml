<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[SHAWN LEE]]></title>
  <link href="http://shawnLeeZX.github.io/atom.xml" rel="self"/>
  <link href="http://shawnLeeZX.github.io/"/>
  <updated>2016-02-16T22:20:49+08:00</updated>
  <id>http://shawnLeeZX.github.io/</id>
  <author>
    <name><![CDATA[Shawn]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[VLC下使用中文字幕]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2016/02/16/vlcxia-shi-yong-zhong-wen-zi-mu/"/>
    <updated>2016-02-16T22:00:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2016/02/16/vlcxia-shi-yong-zhong-wen-zi-mu</id>
    <content type="html"><![CDATA[<p>记如何在VLC下使用中文字幕。</p>

<!-- more -->

<p>默认状态下，VLC会遇到两个问题，一是解码的codecs所用不对，而是用于显示字体的渲染
器(render)所用字体不对。</p>

<p>第一个问题的解决办法一是更改VLC所用的codecs；二是修改文件的codecs为utf-8。第一
种方法在<a href="http://bbs.feng.com/read-htm-tid-344593.html">这里</a>有介绍。第二种方法
我发现Vim可以完美完成，特此记之。</p>

<p>用Vim打开字幕文件，然后使用如下命令：</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class=""><span class="line">:set fileencoding=utf-8</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>保存，退出。</p>

<p>第二个问题的解决也来自之上的
<a href="http://bbs.feng.com/read-htm-tid-344593.html">链接</a>。为防止链接失效，特此重述
方法：</p>

<p>打开VLC的<code>Preferences</code>窗口（<code>Ctrl+P</code>），点击右下角的<code>all</code>，在左边的索引中依次选择
<code>Video -&gt; Subtitles/OSD -&gt; Text renderer</code>，右边的设置区第一项为<code>Font</code>，点击<code>Browse</code>按
钮选择一项中文字体，如<code>WenQuanYi Micro Hei</code>。更改完成之后需要重启VLC。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Note on Running Tensorflow in Anaconda]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2016/01/09/note-on-running-tensorflow-in-anaconda/"/>
    <updated>2016-01-09T19:25:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2016/01/09/note-on-running-tensorflow-in-anaconda</id>
    <content type="html"><![CDATA[<p>Due to conflict of protobuf version, I have to run tensorflow in a sandbox
environment, aka anaconda. This is the note to note down some of its tricky
parts I spent some time figuring out.</p>

<!-- more -->

<p>Most of the packages are backward compatible, so normal packages could be
installed on servers normally, by <a href="http://www.ansible">Ansible</a>. But if
Caffe(it seems the newest Caffe upgraded to protobuf3) and tensorflow want to
be installed in the same machine, protobuf2 and protobuf3 have to co-exist. Due
to their
<a href="https://www.tensorflow.org/versions/master/get_started/os_setup.html#mac-os-x-typeerror-init-got-an-unexpected-keyword-argument-syntax">conflict</a>,
they cannot co-exist. So to not break others environment, I have to install
tensorflow in anaconda.</p>

<p>There are two things I think I may need in the future:</p>

<ol>
  <li>To install Anaconda and all consequent python packages in it using Ansible.</li>
  <li>A bug either in pip or in conda that needs some workaround.</li>
</ol>

<h2 id="using-ansible-with-anaconda">Using Ansible with Anaconda</h2>

<p>Conda has a <a href="http://conda.pydata.org/docs/help/silent.html">silent mode</a>, so it
could be install using shell script, which could be achieved using the <code>shell</code>
module in Ansible.</p>

<p>To install consequent packages all in Anaconda environment, we could write a
playbook that has the location of <code>pip</code> as a variable, so by passing different
<code>pip</code> binary, we could install the python packages wherever we want.</p>

<h2 id="solve-cannot-remove-entries-from-nonexistent-file--easy-installpth">Solve &#8220;Cannot remove entries from nonexistent file: … easy-install.pth’’</h2>

<p>There is a bug preventing one upgrading packages in Anaconda. Where this bug
belongs to pip/setuptools or conda seems still in
<a href="https://github.com/pypa/pip/issues/2751">consideration</a>.</p>

<p>The workaround I used, one of the workarounds suggested by the above link,
which I think is the simplest one is to add <code>--ignore-installed</code> option to
<code>pip</code>.</p>

<p>If your packages in contained in <code>conda</code>’s collection, the best solution is to
install it there. For instance, for <code>numpy</code>, it is just better to install by</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">conda update numpy
</span></code></pre></td></tr></table></div></figure></notextile></div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Setting up Multi-Monitor on Gnome Ubuntu 14.04 with NVIDIA Card]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2016/01/06/setting-up-multi-monitor-on-gnome-ubuntu-14-dot-04-with-nvidia-card/"/>
    <updated>2016-01-06T08:16:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2016/01/06/setting-up-multi-monitor-on-gnome-ubuntu-14-dot-04-with-nvidia-card</id>
    <content type="html"><![CDATA[<p>I got an old monitor and spent some time tweaking the dual monitor setting of
my PC in the office. Here I note down</p>

<ol>
  <li>a tweak to make multiple monitor in Gnome functions better, and some notes
on the behavior of <code>guake</code> under multi-monitor setting.</li>
  <li>a hack to let X Windows remember the monitor layout</li>
  <li>and a short comparison between Gnome 3 and KDE Plasma 4.</li>
</ol>

<!-- more -->

<h2 id="dual-monitor-on-gnome">Dual Monitor on Gnome</h2>

<p>I uses <a href="https://www.gnome.org/">Gnome</a> as my desktop environment ever since the
time I started using Linux. So naturally, the desktop I tried this time to
manage multi-monitor support is Gnome. By default, the dual monitor worked
pretty OK. The only one thing that may need a tweak is: by default, Gnome(my
version is 3.9.90), only supports workspace in primary monitor, so when you
switch back and forth between different workspace, the secondary monitor stays
fixed on whatever it is on. This kind of makes the extra monitor many times
less useful. To make the secondary monitor attach to current workspace, so it
moves when you switch workspaces, you need to configure Gnome a little bit, by
the following command</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">gsettings <span class="nb">set </span>org.gnome.shell.overrides workspaces-only-on-primary <span class="nb">false</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>One drawback of making such a change is <code>guake</code> will stay on the secondary
window forever. Did not get the time to look into the source code to know why
:(.</p>

<p><em>Updated on Jan 9, 2016.</em></p>

<strike>It is weird. `guake` functions normally now, after a reboot. This is probably
not the first time I reboot. I guess it is the package updates that fixed
something.</strike>

<p>I figured out why. When you maximize <code>guake</code> it sticks with that monitor, but
your cancel maximization, it would reconsider it position by probing which
monitor the mouse is in and set itself there.</p>

<h2 id="physical-layout-of-monitors">Physical Layout of Monitors</h2>

<p>I do not know how much it depends on operating system, drivers and
hardware. The <code>display</code>(the GUI one of Gnome) or <code>nvidia-settings</code>(the CLI one
comes with proprietary driver) forgets the monitor layout after reboot, such as
<code>DVI-I-1</code> should be on the left of <code>DVI-D-0</code>, even if I wrote it in the
<code>xorg.conf</code>.</p>

<p>Though finally I switched the monitors physically, for some other reason, and
made peace with the forgetful display manager, I struggled some time to figure
out how to make the layout right.</p>

<p>The solution I used is to use <code>xrandr</code> after the GUI session has set up by
adding a script containing the following line in the startup application of
Gnome(there is a GUI program called <code>Startup Application</code>, though I do not know
what its CLI version is).</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">xrandr --output DVI-I-1 --mode 1920x1080 --right-of DVI-D-0
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>I also have tried to add the above line in <code>.profile</code>, but it seems the layout
setting is decided after <code>.profile</code> is loaded, so it did not work.</p>

<h2 id="a-peak-at-kde">A Peak at KDE</h2>

<p>At the first time I tried to set <code>workspaces-only-on-primary</code> to <code>false</code>, it
did not have any effect, and first all workspaces other than the first one
started to get severe artifact when moving windows around, then even the first
one started to get artifacts. It made the desktop unusable.</p>

<p>After trying to search for an solution in Google for a while, I learned there
seems Gnome do not have any multi-monitor support at all, at least they do not
consider this a feature to be proud of at their website for Gnome 3. So I think
maybe Gnome does not work for Gnome.</p>

<p>Then some video introducing Plasma let me pay some attention to KDE
desktop. The modern design of KDE Plasma 5.5 really impressed me, though in
retrospect I was dazzled by Gnome 3’s new design at the first I saw it. It is
just the case that I have been used to Gnome 3 for such a long time and do not
feel its design at all now.</p>

<p>I installed Plasma from source by</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">sudo apt-get install kubuntu-desktop
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>This is the first time I started to feel Ubuntu 14.04 is getting old. It only
has Plasma 4.14(the minor version may not be right, but it is 4).</p>

<p>After tinkering it a little bit, though it must be the case I did not get
myself familiar with it, I have the first impression as following:</p>

<ol>
  <li>It seems to have many widgets, which is better than Gnome, whose desktop
widget feels like antiques.</li>
</ol>

<p>Besides that, I did not find an obvious solution to</p>

<ol>
  <li>multiple workspaces, which is available by default in Gnome</li>
  <li>the dash application runner(I am not sure its exact name, just you press the
<code>super</code> or <code>win</code> key in you desktop and it shows up). I tried to install
a app called <code>homerun</code>, but it just adds too much icons in the desktop and
creates too much clutters.</li>
  <li>Obvious, <code>guake</code> does not work here anymore.</li>
</ol>

<p>The above three are really killer app, and cannot not be lacking.</p>

<p>So the first impression is KDE is for the GUI users.</p>

<ol>
  <li>It has a good file manager called <code>Dolphin</code>, whose functionality is better
than <code>Nautilus</code>. But I almost do not use GUI file management since I do it
all in CLI.</li>
  <li>A similar application launcher of dash of Gnome is <code>Krunner</code>. But like
Unity, it not only search for applications, but also search for files, any
opened applications etc, which creates much clutter, though this is a
desktop user wants.</li>
  <li>Again, no easy drop-down terminal like <code>guake</code>.</li>
  <li>It adds too much clutter that may not be useful, compared with a clean wall
paper of Gnome. I think Plasma 5.5 tries to fix this, but I did not have the
chance to try.</li>
</ol>

<p>As having been said, it must be the case I am not familiar with a new desktop
environment, but I guess I will settle with it, because after I was little
frustrated with the KDE desktop, I tried to switch back to Gnome. Suddenly,
everything started to work well! Maybe it is because I installed a lot of
libraries when I was installing KDE, which fixed some problems. But now I feel
current setting, the one I mentioned at the first section of this note,
awesome.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On Environment Variable Setup of Linux]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2016/01/05/on-environment-variable-setup-of-linux/"/>
    <updated>2016-01-05T11:28:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2016/01/05/on-environment-variable-setup-of-linux</id>
    <content type="html"><![CDATA[<p>I have spent some time figuring out how Linux sets up its environment variables
for login shell, non-login shell to let Emacs inherits environment variables
and make tmux loads <code>.bashrc</code> and note it here.</p>

<!-- more -->

<h2 id="login-shell">Login Shell</h2>

<p>We start by figuring out the boot process.</p>

<p>For text console,</p>

<ol>
  <li>At the end of boot the mother of all processes <code>init</code> is started. init’s
environment, including PATH, is defined in its source code and cannot be
changed at run time.</li>
  <li><code>init</code> runs the start-up scripts from <code>/etc/init.d</code> depending on the run level
set in <code>/etc/inittab</code>. Since init’s environment is very bare, the scripts
define their required environment variables within themselves.</li>
  <li><code>init</code> starts the text login process that waits for the user to log in. When
the user logs in, the login process checks <code>/etc/passwd</code> to see what shell
should be started for this particular user.</li>
  <li>The shell starts and reads its shell-specific configuration files.
    <ol>
      <li>For Bash, it first reads <code>/etc/profile</code> to get values that are defined
for all users. After reading that file, it looks for <code>~/.bash_profile</code>,
<code>~/.bash_login</code>, and <code>~/.profile</code>, in that order, and reads and executes
commands from the first of these files that exists and is readable.</li>
    </ol>
  </li>
</ol>

<p>For graphical UI,</p>

<ol>
  <li>At the end of booting, the mother of all processes – <code>init</code> – is started.</li>
  <li><code>init</code> runs the start-up scripts from <code>/etc/init.d</code> depending on the run
level set in <code>/etc/inittab</code>. Since <code>init</code>’s environment is very bare, the
scripts define required environment variables within themselves.</li>
  <li>Init starts the GDM display manager, which in turn will start the graphical
login.</li>
  <li>When the user successfully logs in, GDM starts xsession, which reads the
file <code>/etc/gdm/Xsession</code> and with it the environment variables for the
user’s session. The default version of the Xsession file first reads
<code>/etc/profile</code> for global settings and then <code>~/.profile</code> to add the user’s
individual settings.</li>
</ol>

<p>The above boot process is the process to set up environment to login shell. So
if any user specific environment that is need for a graphical program, one
could choose to put it in <code>~/.bash_profile</code>, <code>~/.bash_login</code>, and
<code>~/.profile</code>. I chose to put it in <code>.profile</code>. I actually spent time figuring
this out, so Emacs could inherit environment variables the local libraries I
installed.</p>

<p>As for system wide setup, put it in <code>/etc/profile</code>.</p>

<h2 id="non-login-shell">Non-login Shell</h2>

<p>If a shell is needed after login, the setting should go to the non-login
shell’s, <code>.bashrc</code>. For instance, the terminals created by <code>terminal</code>,
<code>terminator</code> and other terminal programs are non-login shells. This is where I
previously put all my configurations in.</p>

<p>The following comes from <code>man bash</code>’s <em>INVOCATION</em> section.</p>

<pre><code>When bash is invoked as an interactive login shell, or as a non-interactive
shell with the `--login` option, it first reads and executes commands from the
file `/etc/profile`, if that file exists.  After reading that file, it looks
for `~/.bash_profile`, `~/.bash_login`, and `~/.profile`, in that order, and
reads and executes commands from the first one that exists and is readable.
The --noprofile option may be used when the shell is started to inhibit this
behavior.

When a login shell exits, bash reads and executes commands from the file
`~/.bash_logout`, if it exists.

When an interactive shell that is not a login shell is started, bash reads and
executes commands from `/etc/bash.bashrc` and `~/.bashrc`, if these files
exist.
</code></pre>

<h2 id="distribution">Distribution</h2>

<p>Each Linux distribution may tweak files mentioned above, for instance, unset
some variables somewhere, so if you set its value before where it is unset,
your setting will not take effect. Normally, if one’s configuration does not
work, consider go through all previous configurations and understand what they
exactly do in such a distribution.</p>

<h2 id="misc">Misc</h2>

<p>If one uses <code>tmux</code>, the terminal multiplexer, note it creates login shells. So
if one wants <code>.bashrc</code>, especially aliases, to work under <code>tmux</code>, remember to
source it after whatever login shell configuration one may use.</p>

<h2 id="reference">Reference</h2>

<ol>
  <li>https://wiki.debian.org/EnvironmentVariables</li>
  <li>https://help.ubuntu.com/community/EnvironmentVariables</li>
</ol>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Optimization Summary]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/12/16/optimization-summary/"/>
    <updated>2015-12-16T15:06:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/12/16/optimization-summary</id>
    <content type="html"><![CDATA[<p>Yet another note on Math.</p>

<p>The semester’s course on Optimization is going to end. This is a summary note
to unify the mathematical picture learned during this period.</p>

<!-- more -->

<h2 id="problem-formulation">Problem Formulation</h2>

<p>In the most general form, an optimization problem is to find an extreme value,
taking minimum for ease of writing, in the following form</p>

<script type="math/tex; mode=display">
\min\ f(X)\\
G(X) \succeq \theta\\
H(X) = \theta
</script>

<p>where $X$ could be a scalar, vector or matrix; $G(X)$ is a stack of inequality
constrains, whose row is one inequality constrain; $\theta$ is zero vector;
$H(X)$ is a stack of equality constrains, whose row is one equality constrain.</p>

<p>To solve the above problem, analysis should be made to properties of $f(X),
G(X)$ and $H(X)$. Geometric intuition is the source of aspiration and algebraic
descriptions or relaxation of geometric intuition is how we could solve the
problem.</p>

<p>The geometric picture of $f(X)$ is contour of its value, whose metaphor is the
contour of the height of a mountain; or just the mountain by seeing how high
its. The first picture is in the domain of $X$, while the second one is in the
$(X, f(X))$, which adds another dimension.</p>

<p>$G(X)$ and $H(X)$ explicitly or implicitly define an sub-area of all possible
$X$. Its picture is harder to visualize, and is the difficulty aspects in
optimization.</p>

<h2 id="domain-type">Domain Type</h2>

<p>Different types of variables has different structure and properties that
enforced on the domain. As an example, Conic Linear Programming is to explore
the structureness to simplify problems.</p>

<p>It does not occur to me clearly for now how possibly the enforced peculiar
structure of Semi-definite programming or Second Order Cone Programming could
have physical meaning. But SDP how take advantage of matrix variable and
inequality is inspiring.</p>

<h2 id="geometry-of-domain">Geometry of Domain</h2>

<p>The work around is to assume only to solve problems who is convex, and call the
remaining problems non-convex, consequently classifying it as hard.</p>

<p>It seems this is rather a restrict and side step the difficult but important
problems. This was the perception I had when I first heard about Optimization
years ago. But the actually it is not after really struggling through it.</p>

<p>Convexity of a set is the atom to describe geometry of the whole set in the
following sense: if two points are in the set, then we want any points between
them are also in the set. Normally, points have some physical meaning in real
world problem, not some bizarre mathematical fabrication. In physical world,
extremity breaks thing, but not their intermediate value. Thus it is a good
model unless we discover some bizarre phenomena(which probably already exists
but I do not know).</p>

<p>Convexity and concavity of function are the only two ways how function could
vary locally. The really mattered properties of convexity is non-decreasing, so
concavity is non-increasing. They get named quasa-convex for convexity part.</p>

<p>If we could analyzed the atoms how sets compose a bigger set and how functions
composes a &#8220;larger’’ function, we begin to get a look into the whole picture.</p>

<p>Current situation of optimization is local geometry has been well studied, but
a way to generalize to the global geometry lacks. So I guess it is not the
a good understanding of convexity is the first step to understand more complex
problems.</p>

<h2 id="dimensionality-of-domain">Dimensionality of Domain</h2>

<p>This section is about the concept of <em>affine</em>.</p>

<p>The motivation of &#8220;affine’’ is to create a term that could be used to describe
the dimension of domain. So essentially, an affine set is linear variety or the
whole space. Linear variety is a concept. For example, a linear variety in 3D
space would be a line, a plane.</p>

<h2 id="unifying-optimization-duality-with-functional-analysis">Unifying Optimization Duality with Functional Analysis</h2>

<p>If we start from a Linear Programming(LP), which is the following problem</p>

<script type="math/tex; mode=display">
\min\ c^{T}x\\
Ax = b
x \geq 0
</script>

<p>and its dual</p>

<script type="math/tex; mode=display">
\max\ b^{T}y\\
A^{T}y \leq c
</script>

<p>From function analysis point of view, those two problems involves four space,
space of $x$(we call it primal space for convenience from now), dual space of
primal space, space of $y$(we call it transformed space from now), dual space
of transformed space. Duality of LP is the characterization of relationship
between those four spaces.</p>

<p>If we upgrade this view to non-linear case,</p>

<script type="math/tex; mode=display">
\min\ f(X)\\
G(X) \succeq \theta\\
H(X) = \theta
</script>

<p>we see $G(X)$ and $H(X)$ are also a transform, but not linear. But similar idea
should also apply. This is the idea of Lagrange multiplier and Lagrange
duality.</p>

<p>The idea is to analyze in the transformed space $(f(X), Z)$, where $Z$ is the
whose variables are $G(X), H(X)$(in proof involved with Lagrange duality, we
break $H(X)$ to two inequalities). $Z$ and its dual <script type="math/tex">Z^{*}</script> centralize all
duality in optimization.</p>

<p>The hard part is to analyze what the space $Z$ is like. First, different types
of variables have different properties and work with different inequalities,
such as vector and vector inequality, matrix and matrix inequality. Second,
what the transformed space is like after mapping is hard to deal with.</p>

<p>The key properties of $Z$ is whether it has an interior point and is convex,
which determines whether we could find a separating hyperplane, an element in
dual space.</p>

<p>Farkas lemma is just a special case where we could explicitly know what the
transformed space looks like.</p>

<h2 id="on-cone-and-dual-cone">On Cone and Dual Cone</h2>

<p>This section is about cone and dual cone. One more example could be seen in the
next section.</p>

<p>Cone is about direction. It is hard to describe it informally without concrete
examples. Pointed cone identifies inequality relations, which is summarized in
this <a href="http://shawnLeeZX.github.io/blog/2015/11/28/cone-dual-cone-and-generalized-inequalities/">note</a>.</p>

<p>Dual cone is about the direction that at least slightly the same with primal
cone, so in this direction values also could increase, or decrease if it is a
negative dual cone. Dual cone is a set in dual space of primal space, whose
elements are normals of hyperplane. Remember a normal of a hyperplane is about
the direction where the values goes up(or down depending on definition).</p>

<h2 id="variational-idea-kkt-condition-fritz-john-condition">Variational Idea, KKT Condition, Fritz-John Condition</h2>

<p>Existence of Lagrange multiplier is the zero order properties of a constrained
optimal point. By considering the first derivative, we could get how gradients
at the optimal point are related to each other.</p>

<p>Equality constrain in the limit is to carve subspace out, so all things should
happen in this subspace. Gradients of inequality constrains determine whether
the we could still have descent directions, which is Fritz-John or KKT
condition. The idea is if negative dual cone of positive range of gradients of
inequality constrains do not intersect with negative dual cone of $\nabla
f(x)$, then we reach a constrained minimum. The regularity conditions of KKT
just means the gradients of inequality constrains do not conflict with each
other, which if happens would only leave a feasible set that has nothing to do
with $f(x)$, which is the case the dual variable associated with $\nabla f(x)$
is zero in Fritz-John optimality condition.</p>

<h2 id="optimization-algorithms">Optimization Algorithms</h2>

<p>Few has been explored in this area for now.</p>

<p>The idea is to explore the structures of the four spaces mentioned, and the
target function to find the extreme values and corresponding solutions, either
globally, for instance using the simplex method, or locally, using gradient
based methods.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On KKT Condition and Optimality Condition of Conic Linear Programming]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/12/15/on-kkt-condition-and-optimality-condition-of-conic-linear-programming/"/>
    <updated>2015-12-15T20:18:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/12/15/on-kkt-condition-and-optimality-condition-of-conic-linear-programming</id>
    <content type="html"><![CDATA[<p>Yet another note on Math.</p>

<p>In LP and SDP, the complementary slackness are written as</p>

<script type="math/tex; mode=display">
(c - A^{T}y)^{T}x = 0\\
(C -\sum\limits_{i}y_{i}A_{i}) \bullet X = 0
</script>

<p>While KKT condition’s complementary slackness is</p>

<script type="math/tex; mode=display">
v^{T}g(x) = 0
</script>

<p>It is hard to connect them at first glance, since dual variable $v$ is dual to
the space of $g(x)$, which is not necessarily in the same space with $x$.
Especially when $x$ is the big matrix $X$ in SDP, $g(X)$ lies in vector space
instead of matrix space.</p>

<p>This is the note for the how they are connected.</p>

<!-- more -->

<h2 id="linear-programming">Linear Programming</h2>

<p>For linear programming, we write down its Lagrange</p>

<script type="math/tex; mode=display">
c^{T}x + y^{T}(b - Ax) - s^{T}x
</script>

<p>its gradient is $c - A^{T}y - s$</p>

<p>so its KKT condition is</p>

<script type="math/tex; mode=display">
c - A^{T}y - s = 0 \text{ Stationary point}\\
x \geq 0, Ax = b \text{ Primal feasibility}\\
s^{T}x = 0, s \geq 0 \text{ Complementary slackness}
</script>

<p>Now we see $(c - A^{T}y)^{T}x = 0$ is the combination of stationary point
condition and complementary slackness condition. The special structure occurs
here because</p>

<ol>
  <li>In linear problem, analytic solution of equation is possible.</li>
  <li>$g(x)$ is just $x$, so their spaces are the same.</li>
</ol>

<p>Note when LP reaches its optimal value, we always have $c^{T}x = b^{T}y =
(A^{T}y)^{T}x$, but there is a difference $s$ between $c$ and $A^{T}y$. Here we
see the specialty of LP. When one dimension of $s$ is not zero, we have
correspond dimension of $x$ to be zero. Due to the linearity of $c^{T}x$, the
zero directly reflects on the objective value, which makes correspond
dimension’s contribution to zero. Now it is clearer why duality gap is always
zero.</p>

<h2 id="semi-definite-programming">Semi-Definite Programming</h2>

<p>For SDP, if we want to draw analog with LP, the Lagrange may look like</p>

<script type="math/tex; mode=display">
C \bullet X + \sum\limits_{i}y_i(b_i - A_i \bullet X) - S \bullet X
</script>

<p>its gradient is <script type="math/tex">C - \sum\limits_{i}y_i A_i - S</script>.</p>

<p>So its KKT condition is</p>

<script type="math/tex; mode=display">
C - \sum\limits_{i}y_i A_i - S = 0\\
x \succeq 0, A_i x = b_i\\
S \bullet X = 0
</script>

<p>which is almost the same in format with that of LP.</p>

<p>But note</p>

<ol>
  <li>KKT does not work wit matrix inequality yet, so $S \bullet X$ cannot be
moved up to the Lagrange function. Though it does suggest some form of
KKT condition that could deal with matrix inequality may exist.</li>
  <li>The relationship is not linear anymore, both in $X \succeq 0$ and $C \bullet
X$ because the symmetric constrain enforced on $X$, which makes $X$ not just
a matrix form vector.</li>
  <li>$g(X) \succeq 0$ maps matrix to matrix space, so actually complementary
slackness also should be in the space of matrix, and in form of matrix inner
product.</li>
</ol>

<p>So there should be a duality gap normally.</p>

<h2 id="last-note-on-dual-variables">Last Note on Dual Variables</h2>

<p>From above, we see the reason we have matrix inner product style complementary
slackness is due to we are using dual variable in matrix space. It is
interesting to see how general dual variable or linear hyperplane is on solving
problem on any space, though I have not learned any proof of Lagrange on spaces
other than Euclidean space yet.</p>

<h2 id="last-note-on-linearity">Last Note on Linearity</h2>

<p>In conic linear programming,</p>

<ol>
  <li>when putting constrains in Lagrange function, it directly interacts with
objective function, meaning variable $x$ could be separated out.</li>
  <li>The specialty of $x \geq 0$ makes its dual variable the slack variable.</li>
  <li>Linearity makes dual function $\inf \ldots$ analytic solvable, so we only
see $\max$ in the dual problem.</li>
</ol>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On Duality in Optimization]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/12/14/on-duality-in-optimization/"/>
    <updated>2015-12-14T21:09:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/12/14/on-duality-in-optimization</id>
    <content type="html"><![CDATA[<p>Yet another note on Math.</p>

<p>A more general picture of duality in optimization emerges itself. Some time is
still needed to unify all duality in optimization, but for now I summarize a
draft version of it here using duality of linear programming as an example.</p>

<!-- more -->

<h2 id="intuition-of-lagrange-multiplier-from-functional-analysis">Intuition of Lagrange Multiplier From Functional Analysis</h2>

<p>In its most general form, optimization problem is</p>

<script type="math/tex; mode=display">
\max\ f(x)\\
G(x) \geq 0\\
H(x) = 0
</script>

<p>where $G(x)$ is the group of inequality constrains <script type="math/tex">g_i(x)</script>; $H(x)$ is the
group of equality constrains <script type="math/tex">h_i(x)</script>; $x \in X = R^{n}$ or $x \in X = R^{m
\times n}$, where $x$ is taken as matrix variables.</p>

<p>The domain of the problem is implicitly defined by $G(x)$ and
$H(x)$. Geometrically, $H(x) = 0$ describes some surface in $X$. $G(x)$
describes some &#8220;half space’’.</p>

<p>The question to ask is: what objects should we take those constrains as? so we
could internalize and reason with them.</p>

<p>In abstract sense, if we take $f(x), G(x), H(x)$ as variables, or in a more
intuitive word, as objects, in our perception the problem seems not to be that
abstract and convoluted. Their dependency on $x$ seems to gone. This is the
idea from functional analysis. We are just doing space transform on the
original space $X$. After the transform, we try to find the extreme value of a
specific coordinate of the new space, which is $f(x)$, in a sub-area of the new
space, which describes by constrains.</p>

<p>Despite of the non-linearity, every natural phenomena in nature, thus in Math,
comes from certain metamorphism of linear phenomena. To say it in another way,
though we could create very bizarre phenomena with math trick, the real world
should be analyzed starting from the linearity, not for simplicity or
computation’s sake.</p>

<p>But how could we come up with linearity?</p>

<p>This brings to think why constrains exists. It exists because in real world,
certain things has to be satisfied, it could be a fixed location, or limited
amount of resources and so on. The real world constrain is somehow connected to
the objective function, otherwise it won’t exist at all. So how could we model
such connection?</p>

<p>This is the key to the entry of duality.</p>

<p>We have to find the connection of variables $G(x), H(x)$ to another variable
$f(x)$. As having been discussed, every natural phenomena somehow comes from
metamorphism of linear phenomena. An example is the invention of calculus,
which is the how non-linear phenomena behaves locally. The way we connect those
variables is through their linear combination. This in the language of
functional analysis is to say we analyze the primal space from its dual space.</p>

<p>Now back to Lagrange duality. Lagrange multiplier is elements in dual space of
the space made up by $f(x), G(x), H(x)$.</p>

<p>This intuition unscramble constrains.</p>

<h2 id="an-example-linear-programming">An Example: Linear Programming</h2>

<p>Linear programming is the case where all things are linear. So nothing
metamorphized. When we only deal with gradients in a specific point in
non-linear programming, such as the case of KKT condition, Fritz-John
condition, it is actually exactly the optimality condition of linear
programming.</p>

<p>Previously I have noted an possible motivation of Linear programming. Now I
could see the previous note(about two months ago) is just a special case of
previous idea.</p>

<p>For a LP problem, as the following</p>

<script type="math/tex; mode=display">
\max\ c^{T}\\
Ax = b\\
x \geq 0
</script>

<p>I tried to see it from adjoin operator point of view, which is to find
something from $A^{T}$. For details, please refer to previous
<a href="http://shawnLeeZX.github.io/blog/2015/10/18/linear-programming-from-dual-mapping-point-of-view/">note</a>.</p>

<p>Now we write the Lagrange of LP, the dual function is</p>

<script type="math/tex; mode=display">
\inf\limits_{x} c^{T}x + y^{T}(Ax - b) - s^{T}x
</script>

<p>note we have $s \geq 0$.</p>

<p>Now we see how could we deduce it from previous argument of last
<a href="http://shawnLeeZX.github.io/blog/2015/10/18/linear-programming-from-dual-mapping-point-of-view/">note</a>.</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{align*}
                &  \langle 1, c^{T}x \rangle + \langle y, Ax -b \rangle - \langle s, x \rangle\\
\Leftrightarrow &  \langle c, x \rangle + \langle y, Ax -b \rangle - \langle s, x \rangle\\
\Leftrightarrow &  \langle c - s, x \rangle + \langle y, Ax \rangle - \langle y, b \rangle\\
\Leftrightarrow & - \langle y, b \rangle +  \langle c - s, x \rangle + \langle y, Ax \rangle \\
\Leftrightarrow & - \langle y, b \rangle +  \langle c - s, x \rangle + \langle A^{T}y, x \rangle \\
\Leftrightarrow & - \langle y, b \rangle +  \langle c - s + A^{T}y, x \rangle \\
\Leftrightarrow &  \langle y, b \rangle +  \langle c - s - A^{T}y, x \rangle \\
\end{align*}
 %]]&gt;</script>

<p>We find some connection between dual space and primal space now. To make the
part of dual space be a lower bound, we ask $s \geq 0$. This is just the
zooming idea previously.</p>

<p>The more geometrically picture is the geometrical intuition from Lagrange
duality.</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{align*}
 & \inf\limits_{x} \langle c, x \rangle + \langle y, Ax -b \rangle - \langle s, x \rangle\\
\Leftrightarrow & \inf\limits_{x} \langle c - s, x \rangle + \langle y, Ax \rangle - \langle y, b \rangle\\
\Leftrightarrow & - \langle y, b \rangle + \inf\limits_{x} \langle c - s, x \rangle + \langle y, Ax \rangle \\
\Leftrightarrow & - \langle y, b \rangle + \inf\limits_{x} \langle c - s, x \rangle + \langle A^{T}y, x \rangle \\
\Leftrightarrow & - \langle y, b \rangle + \inf\limits_{x} \langle c - s + A^{T}y, x \rangle \\
\Leftrightarrow &  \langle y, b \rangle + \inf\limits_{x} \langle c - s - A^{T}y, x \rangle \\
\end{align*}
 %]]&gt;</script>

<p>The $\inf$ could move the dual variable down. So we have a constrained problem
again.(Details are omitted, and could be found at <em>Nonlinear Optimization
Andrzej Ruszczynski</em> or some other books talk about Lagrange duality).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[General Transform, Linear Transform, Matrix]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/11/30/general-transform-linear-transform-matrix/"/>
    <updated>2015-11-30T10:30:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/11/30/general-transform-linear-transform-matrix</id>
    <content type="html"><![CDATA[<p>Yet another note on Math.</p>

<p>Previously, the origin of Matrix for me comes from linear transform, and
nothing more. Most of the intuitive comes from linear space transform, as in
the example of orthogonal Fourier transform or wavelet transform. As I learn
more and more optimization, and how it computes dual, matrix as a limit case of
non-linear transform comes to me. The linear transform characteristics is just
to approximate the nonlinear transform locally.</p>

<!-- more -->

<h2 id="how-matrix-originally-arises">How Matrix Originally Arises</h2>

<p>Originally, matrix origins from linear transform, and is called linear
operator.</p>

<p>The deviation comes from how a basis of space $X$ gets mapped to another space
$Y$. For details, please refer to <em>Linear Algebra Done Right</em>, <em>Introductory
Functional Analysis with Application</em>, <em>A Friendly Introduction to Wavelet</em>, or
any other books that talks about linear algebra.</p>

<p>The underlying idea is pure linear, and does not touch nonlinear at all.</p>

<h2 id="matrix-as-limit-case-of-nonlinear-transform">Matrix As Limit Case of Nonlinear Transform</h2>

<p>The study of constrained nonlinear optimization made me thinking, when seeing
it in the most general form</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{align*}
  \text{minimize  } & f(x) \\
  \text{subject to } & g_i(x) \leq 0
\end{align*}
 %]]&gt;</script>

<p>First I simplify the problem to linear programming.</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{align*}
  \text{minimize  } & f(x) \\
  \text{subject to } & Ax - b \leq 0
\end{align*}
 %]]&gt;</script>

<p>Solving system of linear equations is a central theme in Math, and it confused
me when I had no idea relating the matrix $A$ in the system of equations to the
space transform intuition of matrix.</p>

<p>If I try to explain it by normal space transform, $Ax$ becomes</p>

<script type="math/tex; mode=display">
\sum\limits_{i}\vec{a_{i}}x_{i}
</script>

<p>where $\vec{a_{i}}$ is columns of $A$.</p>

<p>It is explained as whether $b$ is in range of $A$, and range of $A$ is
picturized as a space, which have nothing to do with $A$. The connection is
broken.</p>

<p>But if we change a perspective, write $Ax$ as</p>

<script type="math/tex; mode=display">
\vec{a_{i}}^{T}x
</script>

<p>where here $\vec{a_{i}}^{T}$ is the row of $A$.</p>

<p>Denote the space $x$ belongs to as $X$, the one $Ax$ belongs to as $Y$, dual of
$X$ as $X^{*}$.</p>

<p>Assuming the bases of $X$ is orthonormal, which is normally in practice,
<script type="math/tex">\vec{a_{i}}</script> is a basis of $Y^{*}$ gets mapped to <script type="math/tex">X^*</script>.</p>

<p>Dual space $X^{*}$ consists of linear functional defined on $X$. The intuitive
of linear functional $g(x)$ is the effect of change on $x$ will influence
$g(x)$ linearly. Think it as cost or price would clarify.</p>

<p>Write <script type="math/tex">\vec{a_{i}}^{T}x = g_{i}(x)</script>, the procedure how matrix transform $x$
becomes clearer. The idea is a linear weighted combination of different
elements of $x$. <script type="math/tex">\vec{a_{i}}^{T}x = g_{i}(x) \leq b_{i}</script> means in the direction of
$\vec{a_{i}}$, the projection of $x$ on it could not exceed a certain value,
which is also could be understood as some physical meaning, such as price,
or threshold.</p>

<p>So matrix is a stack of linear functionals and overall they together make up
some linear transform. If all the linear functionals are linear independent,
the system is invertable, so the matrix has an inverse. If all the linear
functionals are orthogonal, then the weighted sum does not influence each
other.</p>

<p>Now, the rank of matrix makes a lot of sense, and matrices that are not
unitary could be of more use.</p>

<p>Back to the most general form of nonlinear optimization. When the system
approaches its optimal solution, everything becomes more and more linear. The
problem actually boiled down to again, a linear problem. Everything matters are
just <script type="math/tex">g_{i}'</script>, which is just as linear as linear programming, and as
matrix. This is the base of Lagrange multiplier methods.</p>

<h2 id="optimality-condition-of-equality-constrained-optimization-an-example">Optimality Condition of Equality Constrained Optimization: An Example</h2>

<p>An example would make the idea that matrix’s nature on linear transform
clearer. I learned this example ten days after I wrote this note.</p>

<p>Given the following equality constrained problem</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{align*}
  \text{minimize  } & f(x) \\
  \text{subject to } & H(x) = \theta
\end{align*}
 %]]&gt;</script>

<p>Note we are using vector notation now. Denote the Jacobian of $H(x)$ as
$H’(x)$; $x \in X$, $H(x) \in Z$, where $X$ is a linear vector space, while $Z$
is a normed space. Suppose this problem reaches its constrained minimum
<script type="math/tex">x^{*}</script>. We assume <script type="math/tex">x^*</script> is a regular point, which means <script type="math/tex">H'(x^*)</script> maps
$X$ onto $Z$. If $Z$ is of finite dimension, it just means <script type="math/tex">H'(x^*)</script> is of
full rank.</p>

<p>To digress a little, if the mapping <script type="math/tex">H'(^*x)</script> is not onto, it means there is
linear dependence in the gradients of <script type="math/tex">H(^*x)</script> at <script type="math/tex">x^*</script>. When equality
constrains have linear dependence, the feasible region is empty. A picture
would be two parallel hyperplane, who do not intersect each other. For more
complex examples, refer to chapters of <em>Nonlinear Programming, Bertsekas</em>, or
<em>Nonlinear Programming, Theory and Algorithms</em> on optimality conditions.</p>

<p>The above clarification of terminology is to make the argument satisfies for
both infinite dimension and finite dimension space.</p>

<p>Since <script type="math/tex">x^*</script> is minimum(for now we use $x$ instead of <script type="math/tex">x^*</script> for convenience
sake), $\nabla f(x)$ has to be orthogonal to the direction $h$, where $H’(x)h =
\theta$. It means $\nabla f(x)$ is orthogonal to $N(H’(x))$, null space of
$H’(x)$. Now we could see clearly a linear transform, aka matrix is the limit
case of a general non-linear transform, or in another word, the local
approximation of general non-linear transform $H(x)$, in form of $H’(x)$.</p>

<p>To recap the last section, from a linear algebra point of view, we internalize
$Ax$ by how a component of $x$ is represented by coordinates in the new
space. But from a transform point of view, we internalize matrix as applying
each row of $A$, a linear functional to $x$ repeatedly. So whether a matrix is
of full, or be orthogonal does not matter that much. We just create a transform
by stacking some functional row by row.</p>

<p>The latter point of view is the intrinsic nature of transform. But the reason
much efforts have been made in linear algebra is because often ultimately a
problem would be attacked from linear point of view, which is the case of this
example. With the machinery from linear algebra, a much rich structure could be
used instead of just general transform.</p>

<p>Remember in a <a href="http://shawnLeeZX.github.io/blog/2015/10/18/linear-programming-from-dual-mapping-point-of-view/">note</a>
on Linear programming, the intuition of $Ax$ is to map a point from a space $X$
of points to another space of points $Z$, then its dual map or adjoin map
$A^{T}$ is to map dual space <script type="math/tex">Z^{*}</script> to <script type="math/tex">X^{*}</script>.</p>

<p>If $\nabla f(x) \perp N(H’(x))$, it means <script type="math/tex">f(x) \in R(H'(x)^*)</script>. So there
exists a <script type="math/tex">z^{*} \in Z^{*}</script> satisfying <script type="math/tex">f(x) = z^{*}H'(x)^{*}</script>, which could
be written as</p>

<script type="math/tex; mode=display">
\nabla f(x) + \langle z^{*}, H'(x) \rangle
</script>

<p>which is the optimality condition of optimization problems with equality
constraints.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Cone, Dual Cone and Generalized Inequalities]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/11/28/cone-dual-cone-and-generalized-inequalities/"/>
    <updated>2015-11-28T11:04:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/11/28/cone-dual-cone-and-generalized-inequalities</id>
    <content type="html"><![CDATA[<p>Yet another note on Math.</p>

<p>I did not internalized the idea that a pointed cone identifies a generalized
equality until now, and would like to note it down.</p>

<!-- more -->

<h2 id="cone">Cone</h2>

<p>Let’s start with why we want inequality. We want it because we want to compare
two objects. In $R$, an object in this domain is a scalar and represents
something like length, or so. Suppose we want to compare the length of one edge
of a table and the length of a ruler. We put those two together.  Intuitively,
a table looks longer than a ruler, so we say if we want to compare anything
similar like those again, we standardize a unit, according to the reference to
the length of table or ruler, which in the ancient time is the length of some
king’s feet, give a length $x$ to object one, $y$ to object two, then if object
one is longer than object two, we call $x &gt; y$.</p>

<p>How could we generalize this idea to higher dimensional space? Consider vector
inequality. Suppose we want buy a department. The only factors we want to
consider is which floor our department is(assume the higher the better), and
how many square meters it has. What does department $x$ is better than $y$
mean? An intuitive answer is a department that is both higher and bigger is a
better choice. We call it $x \succeq y$.</p>

<p>We could see how cone abstract things here, in vector inequality.</p>

<p>First we break thing down, if we get two rulers, whose lengths are too similar
to tell who is longer in a distance, how could we tell? Without equipment, we
just put those two rules together, and see their difference. This is the mental
procedure we execute when we compare, so in scalar case, $x &gt; y$ means $x - y
&gt; 0$; in vector case, $x \succeq y$ means $x - y \succeq 0$.</p>

<p>What is special about $x - y$?</p>

<p>If we take it abstractly, $x - y$ means how much better when $x$ is compared to
$y$. How we define inequality is determined by how we measure the &#8220;better’’
amount, so the measurement makes sense. For scalar it is just their value
difference. But for vector we cannot judge when department $x$ has higher floor
number than $y$ but smaller square meters. The solution to this dilemma is to
only compare the case where the comparison makes sense. Mathematically, it
means we only compare $x, y$ when $x, y$ stay in a domain, which depends on
both $x, y$, where the comparison makes sense. If $x - y$ is in the domain, we
compare, otherwise, do not bother.</p>

<p>Though we only convert the comparison of $x, y$ to whether $x - y$ belongs to a
domain. We do not know what the domain looks like yet. We want to reach the
conclusion the domain is a pointed cone, or in another name, proper cone.</p>

<p>The next task is to figure out the properties of the domain. What properties do
we want? Let’s list them:</p>

<ol>
  <li>Comparison is about direction and it does not matter if $x$ is a hundred
bigger than $y$, or one hundred percent bigger.</li>
  <li>Strict inequality should exist.</li>
  <li>Difference could be added together: If $x$ is better than $y$, $y$ is better
tan $z$, we should have $x$ is better than $z$.</li>
  <li>Limitation stays in the domain: slightly better is still better.</li>
</ol>

<p>Denoting the domain $K$, those four are translated to</p>

<ol>
  <li>$K$ is a pointed cone, i.e., if $u \in K$ and $-u \in K$, then $u = 0$; for
any $x \in K$ and $\alpha &gt; 0$, we have $\alpha u \in K$.</li>
  <li>$K$ has non-empty interior.</li>
  <li>$K$ is non-empty and closed under addition; i.e., for any $x, y \in K$, $x +
y \in K$.</li>
  <li>$K$ is closed.</li>
</ol>

<h2 id="dual-cone">Dual Cone</h2>

<p>Dual cone is about giving each dimension of an object a linear measurement of
weight, or more intuitively a price, so:</p>

<ol>
  <li>A integrated &#8220;betterness’’ could be quantified for all pairs instead of
just $K$, a restricted set of comparable pairs.</li>
  <li>consequently could lead to dual problem, which is a upper and lower bound by
linear approximation.</li>
</ol>

<p>Due to time limitation, I will just write those for now. Some pictures and
example of minimum elements and minimal elements from <em>Chapter 2, Convex
Optimization Bloyd</em> could be helpful.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Notes on Semidefinite Programming]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/11/15/notes-on-semidefinite-programming/"/>
    <updated>2015-11-15T21:23:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/11/15/notes-on-semidefinite-programming</id>
    <content type="html"><![CDATA[<p>Yet another note on math.</p>

<!-- more -->

<p>I understand SDP as a relaxation techniques that explode the problem to a
higher dimension space with a symmetrical matrix special structure. The
original problem corresponds to a manifold in the new higher dimensional
space. So we are allowed to approach problems in direction that is not possible
in the low dimensional space. An illustration idea could be the worm hole idea
in physics. Another benefits could be to linearize original non-linear
problem. In the simplest case, $x$ gets mapped to $X = xx^{T}$, then relaxed to
$X \in S_{+}$. It just puts the second order terms of $x$ in the
matrix. Similar things could be done in for higher order terms, and finally,
any order polynomial could be achieved in some way.</p>

<strike>
I am still not thinking very clearly how operator could be put into the context
since here matrices are just a special way to put a really long
vector. Frobenius inner product is just normal inner product. The power of SDP
comes from infinite number of quadratic constraints enforced by the PD
condition.
</strike>

<p><br /></p>

<strike>
The connection could possibly be this way. It is inspired by how matrix
derivative is defined using Frobenius norm. Though operator&#8217;s nature comes from
it spectral structure, it is still made by $m \times n$ numbers put in a
special way. So a corresponding change in the corresponding position means
something. By measuring the norm, and inner product in this way, we are somehow
connected to the spectral structure of the matrix. By adding different matrices
together this way, we are somehow combining different operations, though I have
not learned any applications that matches this exactly. An perfect example of
this is the perturbation of a matrix. The perturbation in each dimension is
added on the face value(the number displayed on the entries of the matrix), so
it natural to think regardless of the spectral structure of the matrix,
whatever it may be normalized then or by changed by some other operations, the
face value change is how we perceive physical beings.
</strike>

<p><br /></p>

<p>The structure of <script type="math/tex">S_{+}</script> is defined in the exactly same way with vector
space. Its inner product is Frobenius inner product, which just vectorize
matrices and calculate normal vector inner product. The difference is the
symmetric constraints and positive semi-definite constraints.</p>

<p>But what is the connection between seeing matrix as a vector and as an operator?</p>

<p>Such structure does not connect to spectral properties of a symmetric
matrix. Frobenius norm also is not related to the semantics of an operator —
transform.</p>

<p>The intuition of the PSD matrix is to transform a vector to another vector
within the positive dual cone of the original vector. (I guess this is the
definition that could extended to asymmetric matrices, taking rotation matrix
within 90 degree as an example).</p>

<p>Spectral properties of symmetric matrices mean if we choose the bases right,
matrix multiplication is just component-wise scaling.</p>

<p>Those are illustrating pictures coming from linear algebra. But in the general
form, matrix multiplication $Ax$ works as <script type="math/tex">a_{i}^{T}x, i = 1 \ldots n</script>, where
<script type="math/tex">a_{i}^{T}</script> is the ith row of $A$, not as <script type="math/tex">\sum\limits_{i}a_{i}x_i</script>, where
<script type="math/tex">a_{i}</script> is ith column of $A$, which is the picture from linear algebra.</p>

<p>The transform is formed by stacking <script type="math/tex">n</script> linear hyperplanes, or linear
functionals together. Since linear functional is in the dual space <script type="math/tex">X^{*}</script> of
$X$, and also in finite dimensional case <script type="math/tex">X^{*}</script> equivalent to $X$, this is
the reason we could get useful relations in $X$.</p>

<p>In this case, $A - B$ calculates the difference in the linear functionals of
$A, B$. $A \bullet B$ calculates a sum value of inner products of all
functionals of $A, B$. Inner product is the way we measure difference between
hyperplanes.</p>

<p>Now, from the above sense, the structure defined before is for the matrix
itself, but not for how it could transform a vector.</p>

<p>A last note on how to solve SDP.</p>

<p>SDP is solved using interior point methods, whose intuitive is to guide the
optimization by the objective function, using gradient and hessian
information. To make sure the point stay feasible when optimizing, a term $-log
det|A|$ is added to the objective function, who will ensure $X \succeq \mu I$
for some $\mu$, meaning it is positive definite.</p>

<p>This is a very beautiful idea. Actually it is what I was looking for in
non-linear optimization so that the boundary information not only guide
optimization only when the point is near the boundary but also when it is far
in the boundary.</p>

<strike>More thinking may be added when I learned more about SDP, matrix algebra and
matrix calculus.</strike>

<p><br /></p>

<p>I guess this note is roughly finalized.</p>

<p>Updated on Dec 18th, 2015</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Note On Compiling Tensorflow]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/11/13/note-on-compiling-tensorflow/"/>
    <updated>2015-11-13T11:35:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/11/13/note-on-compiling-tensorflow</id>
    <content type="html"><![CDATA[<p>A note on setting library path for cudnn when compiling tensorflow, in case I
forget it next time.</p>

<!-- more -->

<p>Directly providing the library path to cudnn, which has the following directory
structure,</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">include  lib
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>does not work.</p>

<p>According to the error message, it seems that the configuration tries to find
header file and shared libraries directly under the provided folder, thus this
time, I made another folder specifically for tensorflow — it is not in
<code>LD_LIBRARY</code>, so other programs do not use it — then the compilation works.</p>

<p>Since I just want to make sure I could get through the compilation process to
make sure if in case there are features not provided in the official binary, I
have a way to use it, I settled for now. But since the default folder is just
where CUDA lives, I guess if I made the directory structure of CUDNN the same
as CUDA, which I just need to add a symbol link <code>lib64</code> to <code>lib</code>, the
compilation may still work.</p>

<p>So this is the note.</p>

<hr />

<p>Updated on Jan 7, 2016</p>

<p>Adding a symbol link <code>lib64</code> to <code>lib</code> under where cudnn lives does work. The
folder structure is the one mentioned above.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On Linear Programming, Duality of LP and Operator, a Functional Analysis Point of view]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/10/18/linear-programming-from-dual-mapping-point-of-view/"/>
    <updated>2015-10-18T12:39:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/10/18/linear-programming-from-dual-mapping-point-of-view</id>
    <content type="html"><![CDATA[<p>Yet another note on Math, about visualization of Linear Programming, some
thoughts on Operator and Adjoin.</p>

<!-- more -->

<h2 id="dual-map-and-adjoin-operator">Dual Map and Adjoin Operator</h2>

<p>Denote the matrix of a linear mapping $T$ corresponds to natural bases as $A$,
then $A^{T}$ is the matrix corresponds to the dual map of $T$. More
specifically, if the bases of the two space, the original space and its dual,
are orthogonal respectively, $A^{T}$ is the adjoin operator of $A$. Now suppose
$A \in R^{M \times N}$.</p>

<p>For a linear programming problem, the constraints are $Ax \leq b$, intuitively,
we understand it as a polyhedron, the intersection of finite number of
halfspaces.</p>

<p>We could also understand it from linear mapping and dual bases point of view.</p>

<p>$A$ maps points from $R^{N}$ to $R^{M}$. A column of $A$ corresponds to the
coordinates of the an natural basis of $R^{N}$ in the new $R^{M}$, meanwhile,
a column of $A^{T}$, which is a row of $A$, corresponds to the coordinates of a
dual basis of a natural basis of $R^{M}$ in $R^{N}$ if it is transformed by
$A^{T}$.</p>

<p>So a row $\vec{a_{i}}$ of $A$ is a $A^{T}$ transformed dual basis that
corresponds to one natural basis in $R^{M}$, which corresponds to a hyperplane
in $R^{N}$, also an element of the dual space of $R^{N}$.</p>

<h2 id="on-the-feasible-region-of-linear-programming">On the Feasible Region of Linear Programming</h2>

<p>Now we try to see whether we could get a picture from the above concepts.</p>

<h3 id="a-previous-possibly-wrong-attempt">A Previous Possibly Wrong Attempt</h3>

<p>This is the first visualization I have tried. It turns out not that right after
I discussed the idea with my optimization course teacher.</p>

<p>From this perspective, the polyhedron in $R^{N}$ is a squashed(or enlarged)
quadrant of $R^{M}$, which is the intersection of hyperplanes whose normals are
natural bases of $R^{M}$ — the hyperplanes only need to pass a constant
value, probably corresponding dimension of $b$(have not thought very clearly),
do not necessarily pass origin point.</p>

<p>If $M &gt; N$, $R^{M}$ gets squashed, and there are much freedom in the way how
the space gets squashed, which is analog with we have more equations than
variables, so it is easier to get solutions. Otherwise, $R^{M}$ gets enlarged,
however, no matter how the enlarging is done, it still remains as a low
dimensional space in the high dimensional space, thus the freedom is limited,
which is analog with more variables than equations, so it is harder or
impossible to get solutions.</p>

<h3 id="reason-in-the-standard-form">Reason In the Standard Form</h3>

<p>If we convert the problem to the standard form of linear programming, we could
see that the dimension or the original space is usually larger than the dual
space, otherwise, the feasible region could be easily empty. In this case, the
argument, that the dual space gets squashed, does not hold. But a different
picture turns out immediately.</p>

<p>Intuitively, which means it is not necessarily right, as long the objective
function does not parallel with one of the constraints, the solution to LP is a
basic solution, otherwise, we could move the point along one of the constraint
to change the objective value. Now we only discuss basic solutions.</p>

<p>For every basic solution, we have $N$ constraints being active. Note that $N$
is the dimension of the dual space. Thus, each set of $N$ active constraints
corresponds to a version of dual space that gets mapped from the standard basis
of dual space by those columns of $A^{T}$. More specifically, each active
hyperplane in the $R^{M}$ is a basis in the dual space $R^{N}$.</p>

<h2 id="on-duality-of-linear-programming">On Duality of Linear Programming</h2>

<p>This leads to an intuition about how on earth the dual problem of LP is
conceived in the first place, and makes its extension to conic programming
clear.</p>

<p>From my understanding, the dual in Optimization is to find a lower bound of the
distance in the original space in its dual space, being it the shortest
distance from a point to a subspace, from a point to a closed convex set or a
convex epigraph to a concave epigraph of functions. Those three examples, which
is three types of dual in infinite dimensional optimization try to find a
linear approximate lower bound for a normally non-linear objective
function. Their dual problems are usually some kind of LP, or other forms could
be easily solved. But for LP, all parts in the problem is already linear. From
this line of thinking, the dual of LP is to find a lower bound in the dual
space of $Ax$. How could this be? The key lies in the adjoin operator.</p>

<p>The standard form of LP is</p>

<script type="math/tex; mode=display">
\max\ c^{T}\\
Ax = b\\
x \geq 0
</script>

<p>We have an adjoin relation</p>

<script type="math/tex; mode=display">
\langle Ax, y\rangle = \langle x, A^{T}y \rangle\\
\langle b, y\rangle = \langle x, A^{T}y\rangle\\ 
\langle b, y\rangle \leq \langle x, c\rangle
</script>

<p>The last inequality holds because we have $x \geq 0$.</p>

<p>Conic programming just extends the meaning of $\geq$ and inner product.</p>

<h2 id="the-algebraic-nature-of-operator">The Algebraic Nature of Operator</h2>

<p>All of the thinking about originates from the way I learn Math. I want to get a
picture from the symbols and relationships. Up to now, all concepts I know
could be put into a 2D or 3D system with or without coordinates in my mind,
being it topology space, metric space, Banach space, inner product space,
Hilbert space, dual space, affine set, convex set, cone, measure, probability
measure and so on. Dual in optimization is a new concept, and I want to put it
somewhere in the system. In about 4 days, I almost finished the book
<em>Optimization by Vector Space Method</em>, which is about infinite dimensional
optimization, and learned the three kinds of duals mentioned before. I indeed
came up with similar visualization tricks mentioned in the book before I read
them. But in the section, some words rang a bell, after a few days I read them
and pondered on the meaning of adjoin, the relation between the $Ax$ and $X$.</p>

<p>At the beginning of the Chapter Six</p>

<blockquote>
  <p>Because it is difficult to obtain a simple geometric representation of an
arbitrary linear operator, the material in this chapter tends to be somewhat
more algebraic in character than that of other chapters. Effort is made,
however, to extend some of the geometric ideas used for the study of linear
functionals to general linear operators and also to interpret adjoints in
terms of relations among hyperplanes.</p>
</blockquote>

<p>The point of an operator $A$ is to transform a point in $X$ to a new space for
some purpose. It is not clear to see why it helps in the general form, but
think Fourier Transform, which is to transform a point in the signal space to
the frequency space. Boom, science advanced. In retrospect, do we need to keep
a picture in the natural basis of signal space when considering the frequency
space? No. In some research paper I read, for instance, scattering transform,
the whole is to make sure the new space has good properties.</p>

<p>So for operators, the most important is to enforce regularities to make sure
there is good properties in the new space, which is algebraic in nature instead
of geometrical.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On Teaching and Learning]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/09/21/on-teaching-and-learning/"/>
    <updated>2015-09-21T20:37:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/09/21/on-teaching-and-learning</id>
    <content type="html"><![CDATA[<p>Some notes on teaching and learning.</p>

<!-- more -->

<p>The way we teach reflects the way we learn and the way we communicate. Teaching
gives me another perspective on how may I could be taught or just, learn from
others. Such experience has led me a long way to realize my deficiency.</p>

<p>I attended a workshop on teaching today and want to note down something
learned. It is the first time I got systematical training on how to teaching,
which is equivalent to how to learn.</p>

<p>The following stuffs come from the handout in the workshop.</p>

<h3 id="seven-research-based-principles-for-smart-teaching">Seven Research-based Principles for Smart Teaching</h3>

<p>There are seven principles in teaching, which also means in learning.</p>

<ol>
  <li>prior knowledge</li>
  <li>structuring knowledge</li>
  <li>motivation</li>
  <li>self-awareness on the one’s situation</li>
  <li>synthesis of different parts of acquired knowledge </li>
  <li>feedback</li>
  <li>emotional feeling, social and intellectual climate</li>
</ol>

<p>This is a systematical summary of elements that involves in the learning
process. Prior knowledge is what you already have; structuring knowledge is how
you condense your knowledge and build inner connection between different
separate parts; motivation is power house behind all your efforts;
self-awareness is about a clear awareness of one’s current situation — what
one have known, what one do not know, what one know one do not know; synthesis
is where something new could happen; feedback is how people get to know their
mistakes, so they could fix them, and learn new things; emotional stability and
social support is very important for long term learning.</p>

<p>After some thinking, it seems that nothing is really new for me, but the
summary is helpful.</p>

<h3 id="on-motivation">On Motivation</h3>

<p>Another important part on teaching and learning discussed is what motivate
people to do better on tasks that need cognitive thinking.</p>

<p>I long have known only money is not enough. Today I got a very good summary:</p>

<blockquote>
  <p>Pay people enough to take the issue of money off the table.</p>
</blockquote>

<p>The factors that motivate to do great work is autonomy, mastery and
purpose. There should many materials online talking on this given this is a
research output from scientists.</p>

<h3 id="three-skills-on-communication">Three Skills On Communication</h3>

<ol>
  <li>Storytelling</li>
  <li>Contextualizing</li>
  <li>Sketching</li>
</ol>

<p>All those are kind of one thing. People learn from examples, so we need
storytelling; people learn from examples that they know the most, so we need
contextualize the examples with their experience; people learn bit by bit,
dynamically, so we need to present it bit by bit, like sketching a picture.</p>

<p>It is easier said that done. Practice is important.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On Linux Laptop Battery]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/09/07/on-linux-laptop-battery/"/>
    <updated>2015-09-07T14:15:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/09/07/on-linux-laptop-battery</id>
    <content type="html"><![CDATA[<p>I would like to note down the how to prolong battery life, in term of both
hours and years.</p>

<p>Roughly, there are three tricks to extend battery time, <code>laptop-mode</code>,
<code>powertop</code> and changing screen lightness, and one trick to extend life,
stopping battery charging according to thresholds. The last trick is only
applicable to Thinkpad.</p>

<!-- more -->

<h2 id="extending-battery-time">Extending Battery Time</h2>

<p>I have three tricks for extending the battery time, <code>laptop_mode</code>, <code>powertop</code>
and setting the lightness of the screen. The exact number is forgotten, but
roughly if the original time of the laptop is around 4 hours, enabling
<code>laptop_mode</code> will get me one extra, <code>powertop</code> two extra and lightness one
extra.</p>

<p>Normally, people are told to use one battery management programs considering
that different programs may conflict, but I found <code>laptop_mode</code> works well with
<code>powertop</code>, a long time ago. So I settled with it.</p>

<h3 id="laptopmode">laptop_mode</h3>

<p><a href="http://www.samwel.tk/laptop_mode/">laptop_mode</a> is about:</p>

<blockquote>
  <p>Laptop mode is a kernel “mode” that allows you to extend the battery life of
your laptop. It does this by making disk write activity “bursty”, so that only
reads of uncached data result in a disk spinup. It causes a significant
improvement in battery life (for usage patterns that allow it).</p>
</blockquote>

<p>There are configuration files for it, but I did not try to use them.</p>

<h3 id="powertop">powertop</h3>

<p><a href="https://01.org/powertop">powertop</a> is from Intel. It could tune a number of
options to save power usage. For details, refer to
<a href="https://wiki.archlinux.org/index.php/Powertop">here</a>. I will only note down
normal usage scenario.</p>

<p>After first installation, we need to run:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">sudo powertop --calibrate
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>It will take several minutes to finish, and the screen could be dark for tens
of seconds. So do not panic when this happens. Also, do not touch your laptop
when powertop is calibrating. After this, you could get power consumption in
Watt and estimated remaining time in <code>powertop</code>. If you skip this, <code>powertop</code>
will still work, but not those two information.</p>

<p>Start <code>powertop</code>, in the <code>tunable</code> tab, you could see a number of tunable
options to improve your battery time. Make all the “Bad” to “Good” will save a
lot of power consumption. However, the change is lost after you reboot. To make
it permanent, do the following.</p>

<p>Run,</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">sudo powertop --html
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>You will get a html version report under current directory. Go to the tunable
page, you could see the command to tune, similar with the following:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line"><span class="c"># Those following are the settings from powertop to save power.</span>
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;1500&#39;</span> &gt; <span class="s1">&#39;/proc/sys/vm/dirty_writeback_centisecs&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;0&#39;</span> &gt; <span class="s1">&#39;/proc/sys/kernel/nmi_watchdog&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;min_power&#39;</span> &gt; <span class="s1">&#39;/sys/class/scsi_host/host1/link_power_management_policy&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;min_power&#39;</span> &gt; <span class="s1">&#39;/sys/class/scsi_host/host2/link_power_management_policy&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;min_power&#39;</span> &gt; <span class="s1">&#39;/sys/class/scsi_host/host0/link_power_management_policy&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;auto&#39;</span> &gt; <span class="s1">&#39;/sys/bus/usb/devices/1-6/power/control&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;auto&#39;</span> &gt; <span class="s1">&#39;/sys/bus/pci/devices/0000:00:16.0/power/control&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;auto&#39;</span> &gt; <span class="s1">&#39;/sys/bus/pci/devices/0000:02:00.0/power/control&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;auto&#39;</span> &gt; <span class="s1">&#39;/sys/bus/pci/devices/0000:00:1f.3/power/control&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;auto&#39;</span> &gt; <span class="s1">&#39;/sys/bus/pci/devices/0000:00:1f.2/power/control&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;auto&#39;</span> &gt; <span class="s1">&#39;/sys/bus/pci/devices/0000:00:1f.6/power/control&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;auto&#39;</span> &gt; <span class="s1">&#39;/sys/bus/pci/devices/0000:00:1f.0/power/control&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;auto&#39;</span> &gt; <span class="s1">&#39;/sys/bus/pci/devices/0000:00:1d.0/power/control&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;auto&#39;</span> &gt; <span class="s1">&#39;/sys/bus/pci/devices/0000:00:1c.1/power/control&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;auto&#39;</span> &gt; <span class="s1">&#39;/sys/bus/pci/devices/0000:00:1c.0/power/control&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;auto&#39;</span> &gt; <span class="s1">&#39;/sys/bus/pci/devices/0000:00:14.0/power/control&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;auto&#39;</span> &gt; <span class="s1">&#39;/sys/bus/pci/devices/0000:00:02.0/power/control&#39;</span>;
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Copy all those lines, or only the ones you want to tune to <code>/etc/rc.local</code>,
then the change will be permanent.</p>

<h3 id="set-default-lightness">Set Default Lightness</h3>

<p>As least for me, no new packages are needed. Just put the following line in
<code>/etc/rc.local</code> is OK. Given the difference in hardwares, the <code>intel_backlight</code>
may be something else.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line"><span class="c"># Set default brightness. The maximum value is 852. The value 350 here is hard tuned.</span>
</span><span class="line"><span class="nb">echo </span>350 &gt; /sys/class/backlight/intel_backlight/brightness
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2 id="extending-battery-life">Extending Battery Life</h2>

<p>I am delighted to find out that Thinkpad has such a good support for
Linux. Lenovo has a good mechanism to extend battery life on Windows. It will
stop charging the battery if the battery level has exceeded some threshold,
which would prolong the battery life given the properties of Lithium battery.</p>

<p>Thinkpad still support it if you are using Linux. The solution depends on the
hardware of your Thinkpad. If you are installing on a recent Thinkpad that has
an Ivy Bridge or newer processor (X230, T430, T530, etc.), like me, you could
use a utility named <a href="http://www.thinkwiki.org/wiki/Tpacpi-bat">tpacpi-bat</a>.</p>

<p>If you are using an old Thinkpad, go
<a href="http://www.thinkwiki.org/wiki/Tp_smapi">there</a> for a solution.</p>

<h3 id="install-acpi-call">Install <code>acpi-call</code></h3>

<p>I use Ubuntu 14.04, so the procedure to install <code>tpacpi-bat</code> on Ubuntu will be
described.</p>

<p><code>tpacpi-bat</code> has a <a href="https://launchpad.net/~morgwai/+archive/ubuntu/tpbat">ppa</a>
for Debian based system. Just add the ppa to your source:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">sudo sudo add-apt-repository PPA_NAME
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><code>tpacpi-bat</code> depends on <code>acpi-call</code>, which is part of <code>acpi-call-dkms</code>. So we
need to install <code>acpi-call-dkms</code> first. It is also part of the ppa.</p>

<p>The main reason that I write this note is that the package has a bug. This bug
is widely
<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=762281">discovered</a> almost
one year ago, it is strange why it is not fixed yet. After setting up the ppa,
first try installing <code>acpi-call-dkms</code>.</p>

<p>The installation will fail with message similar with the following:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">make <span class="nv">KERNELRELEASE</span><span class="o">=</span>3.19.0-26-generic <span class="nv">KVERSION</span><span class="o">=</span>3.19.0-26-generic <span class="nv">KDIR</span><span class="o">=</span>/lib/modules/3.19.0-26-generic/build....<span class="o">(</span>bad <span class="nb">exit </span>status: 2<span class="o">)</span>
</span><span class="line">Error! Bad <span class="k">return </span>status <span class="k">for </span>module build on kernel: 3.19.0-26-generic <span class="o">(</span>x86_64<span class="o">)</span>
</span><span class="line">Consult /var/lib/dkms/acpi_call/1.1.0/build/make.log <span class="k">for </span>more information.
</span><span class="line">dpkg: error processing package acpi-call-dkms <span class="o">(</span>--configure<span class="o">)</span>:
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Have a check at the <code>make.log</code>, the compilation error is:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">Please don<span class="err">&#39;</span>t include &lt;acpi/acpi.h&gt; directly, include &lt;linux/acpi.h&gt; instead
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>So I go to <code>/var/lib/dkms/acpi_call/1.1.0/source/acpi_call.c</code>, where the
installer unpacks the source. I changed <code>&lt;acpi/acpi.h&gt;</code> to <code>&lt;linux/acpi.h&gt;</code>,
then try the installation(wit the same command) again. Wow, the compilation
passed and the installation is successful.</p>

<h3 id="install-tpacpi-bat">Install <code>tpacpi-bat</code></h3>

<p>This step is easy, just normal apt installation.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">sudo apt-get install tpacpi-bat
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="configuration">Configuration</h3>

<p>After installation, now we need to configure the charge threshold of our
battery. The help message of <code>tpacpi-bat</code> does not seem to be very clear for
me. So I will note down how to get and set charging battery thresholds.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line"><span class="c"># tpacpi-bat get start-threshold primary-battery</span>
</span><span class="line">tpacpi-bat   -g   ST             1
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Thinkpad has one primary battery and one secondary battery. 1 stands for
primary battery and 2 stands for secondary battery.</p>

<p>To set the start threshold for starting charging:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line"><span class="c"># tpacpi-bat set start-threshold primary-battery   start-threshold</span>
</span><span class="line">tpacpi-bat   -s  ST              1                 40
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>It means the battery won’t charge if the its battery level is higher than 40.</p>

<p>To make the change permanent, add the following lines in <code>/etc/rc.local</code>.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line"><span class="c"># Primary battery</span>
</span><span class="line">tpacpi-bat -s ST 1 40 <span class="c"># Start threshold</span>
</span><span class="line">tpacpi-bat -s SP 1 80 <span class="c"># Stop threshold</span>
</span><span class="line"><span class="c"># Secondary battery</span>
</span><span class="line">tpacpi-bat -s ST 2 40
</span><span class="line">tpacpi-bat -s SP 2 80
</span></code></pre></td></tr></table></div></figure></notextile></div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Note on texlive from Ubuntu Source]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/09/02/note-on-texlive-from-ubuntu-source/"/>
    <updated>2015-09-02T21:49:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/09/02/note-on-texlive-from-ubuntu-source</id>
    <content type="html"><![CDATA[<p>Some note on the installing LaTeX packages from network.</p>

<!-- more -->

<p>It is very convenient to install packages using <code>tlmgr</code>. However, sometimes
the mirror you are trying to connect would be extremely slow, which makes it
feel like tlmgr has stuck.</p>

<p>If you have not been deal with texlive installation for a long time, like me
today, the first thoughts stuck me is that there is something wrong with
texlive installation given that I was doing a fresh installation on a new
laptop I did not familiar. Only after about a hour’s debugging, the idea that
maybe it is the network issue struck me.</p>

<p>Here I want to note down some points about how tlmgr choose its mirror servers,
so I won’t be figuring out the same problem next time.</p>

<p>By default, <code>tlmgr</code>’s default repository url is a multiplexor, which will
choose a mirror in the closest network proximity to your location. See the
right pane of this <a href="ctan.org/mirrors">page</a>.</p>

<p>To set such behavior of <code>tlmgr</code>, the command is like this:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">tlmgr option repository ctan
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>where <code>ctan</code> is the nickname for tlmgr for the multiplexor mirror.</p>

<p>Today the multiplexor gave me a server that is not working my LAN
network. Luckily that I get a workable mirror from my PC and use that to solve
the network problem.</p>

<p>The url of a mirror is like this:
<code>http://ftp.yzu.edu.tw/CTAN/systems/texlive/tlnet</code>. The example here is the
mirror that works for me this time.</p>

<p><em>NOTE FOR ME</em>:</p>

<p>I have set this mirror as default for my laptop.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On Code Completion & Navigation for C/C++ in Emacs]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/08/11/on-code-completion-for-c-slash-c-plus-plus/"/>
    <updated>2015-08-11T09:21:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/08/11/on-code-completion-for-c-slash-c-plus-plus</id>
    <content type="html"><![CDATA[<p>Due to the same reason that I decided to add <code>company</code> to provide faster and
more accurate completion functionality, I switched from
<a href="http://cedet.sourceforge.net/">CEDET</a> to
<a href="https://github.com/Sarcasm/irony-mode">irony</a> +
<a href="https://github.com/leoliu/ggtags">ggtags</a>.</p>

<p>Here is the note TODO</p>

<!-- more -->

<h2 id="irony">Irony</h2>

<h3 id="installation">Installation</h3>

<p>To setup <code>irony</code>, in the <a href="https://github.com/Sarcasm/irony-mode">README</a> of
<code>irony</code>’s git repo, the installation process provided by the author is pretty
workable. The only thing may need to be noted is that what packages you need to
install if you are not going to compile <code>libclang</code> from source.</p>

<p>In Ubuntu, you need those two packages: <code>libclang-dev</code> and <code>clang</code>. By
mentioning only <code>libclang</code>, it gives me the feeling that I do not need an
executable of <code>clang</code>, however, there is some errors occurs without
<code>clang</code>. But due to the trial and error when making <code>irony-mode</code> to work, I am
not sure it is really caused by lacking of <code>clang</code>.</p>

<h3 id="make-it-work">Make It Work</h3>

<p>You need to let <code>clang</code> know where to find you source file for it to parse
it. To achieve this, <code>irony</code> provides a concept called
<a href="https://github.com/Sarcasm/irony-mode#compilation-database">compilation database</a>. Refer
to it to know how to make <code>irony</code> work. The following is some remarks.</p>

<p>Basically, the most important compilation flags are the include folder path for
header files. Since <code>irony</code> does not aim to provide code navigation function,
all information it needs are in header files.</p>

<p>One problem that bugs me a lot when I was setting up <code>irony</code> is that <code>clang</code> in
<code>irony</code> and <code>gcc</code> handles <code>-I</code> flag differently. The path must immediately
follows the <code>-I</code>, with no spaces. If there are spaces, <code>irony</code> could not find
the corresponding paths.</p>

<h3 id="limitations">Limitations</h3>

<p>During my testing with <code>irony</code>, I found that it could not handle definition
with template, which is used a lot in C++ numerical library. The limitation
also makes sense since that declarations are generated dynamically during
compilation for template definition, so maybe you could not get relevant
information just by parsing the template definition.</p>

<h2 id="ggtags">ggtags</h2>

<p><a href="http://www.gnu.org/software/global/">gtags</a> is better
<a href="http://ctags.sourceforge.net/">ctags</a> in various ways. See the
<a href="https://github.com/leoliu/ggtags">table</a> provided by
<a href="https://github.com/leoliu/ggtags">ggtags</a>’s developers.</p>

<h3 id="setup-system-tags">Setup System Tags</h3>

<p>I copy this section from this
<a href="http://tuhdo.github.io/c-ide.html#sec-7-2">tutorial</a> in case I may forget it.</p>

<p><code>GNU Global</code> has an environment variable named <code>GTAGSLIBPATH</code>. This variable holds
<code>GTAGS</code> database of external libraries that your project depends on but not
inside your project. For example, your project may rely on system headers such
as <code>stdio.h</code>, <code>stdlib.h</code>… but these headers are internal to your project. However,
remember that you can only jump to tag definitions of external dependencies,
and nothing else (such as files or references). But, again, once you are inside
the external library, you can start jumping around sicne it becomes your
current project.</p>

<p>To make <code>GNU Global</code> sees your system headers, follow these steps:</p>

<p>Export this environment variable in your shell init file, such as <code>.bashrc</code> or
<code>.zshrc</code>:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line"><span class="nb">export </span><span class="nv">GTAGSLIBPATH</span><span class="o">=</span><span class="nv">$HOME</span>/.gtags/
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Execute these commands in your terminal:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line"><span class="c"># Create a directory for holding database, since</span>
</span><span class="line"><span class="c"># you cannot create a database in your system paths</span>
</span><span class="line">mkdir ~/.gtags
</span><span class="line">
</span><span class="line"><span class="c"># Create symbolic links to your external libraries</span>
</span><span class="line">ln -s /usr/include usr-include
</span><span class="line">ln -s /usr/local/include/ usr-local-include
</span><span class="line">
</span><span class="line"><span class="c"># Generate GNU Global database</span>
</span><span class="line">gtags -c
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>The <code>-c</code> option tells <code>GNU Global</code> to generate tag database in compact format. It
is necessary because if your project contains C++ headers like <code>Boost</code>, without
<code>-c</code> your <code>GTAGS</code> database can be more than 1 GB. Same goes for <code>ctags</code>. The <code>GNU
Global</code> devs explained that it is because the <code>GTAGS</code> database includes the image
of tagged line, and the <code>Boost</code> headers have a lot of very long lines.</p>

<p>After all the above steps, restart with a shell loaded with that variable. To
verify Emacs gets the variable, <code>M-x getenv</code> and enter <code>GTAGSLIBPATH</code> and see
if your predefined value is available. Executing <code>ggtags-find-tag-dwim</code> or
<code>helm-gtags-dwim</code> jumps to the definition of a system tag like a normal tag.</p>

<p>The disadvantage of using <code>GNU Global</code> is that currently it cannot include
files without extension. In the C++ system include directory like
<code>/usr/include/c++/4.8/</code>, it contains files without extension such as
<code>iostream</code>, <code>string</code>, <code>set</code>, <code>map</code>…. so you can write <code>#include</code> directives
without having to append <code>.h</code> at the end. <code>GNU Global</code> devs are considering to
add support for this use case.</p>

<h2 id="some-remarks">Some Remarks</h2>

<ul>
  <li><code>semantic-mode</code> is still used to provide method overview for ECB. It is
configured to only parse current buffer, which is rather acceptable in speed.</li>
  <li>If you want to know more about CEDET, here is
<a href="http://alexott.net/en/writings/emacs-devenv/EmacsCedet.html">a nice introductory post</a>
explaining it.</li>
  <li>Though <code>CEDET</code> gets disabled, company still takes advantage of some part of
tools provided by <code>CEDET</code>. One of them is
<a href="http://cedet.sourceforge.net/ede.shtml">EDE</a>, the project
manager. See the github README page of
<a href="https://github.com/randomphrase/company-c-headers">company-c-headers</a> to see
how could you use <code>EDE</code> to tell <code>company</code> to use system include path.</li>
  <li><a href="https://github.com/emacs-helm/helm">helm</a> is an alternative to
<a href="https://www.masteringemacs.org/article/introduction-to-ido-mode">ido</a>. Maybe
it could be tried while I have more time.</li>
  <li><a href="https://github.com/abingham/emacs-ycmd">emacs-ycmd</a> is another completion
framework for Emacs.</li>
  <li><code>irony</code> offers a flychecker, since I already uses the google style and
cpplint, I will not try <code>flycheck-irony</code> for the time being, though it may
offer advantages such as full compilation error detection.</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On Auto Completion in Emacs]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/08/11/on-auto-completion-in-emacs/"/>
    <updated>2015-08-11T09:07:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/08/11/on-auto-completion-in-emacs</id>
    <content type="html"><![CDATA[<p>Just finished setting up Emacs using
<a href="http://company-mode.github.io/">company</a> to do auto-completion. Here I would
like to note down the reason why I made the shift from
<a href="https://github.com/auto-complete/auto-complete">auto-complete</a> to <code>company</code>
for programming. However, for tasks like writing configuration file, LaTeX
documents or markdown note, I still use <code>auto-complete</code>.</p>

<!-- more -->

<h2 id="comparison-between-company-and-auto-complete">Comparison Between <code>company</code> and <code>auto-complete</code></h2>

<p>At the first iteration of my Emacs configuration for C/C++, I followed the
following three videos to get a basic setup:</p>

<ul>
  <li><a href="https://www.youtube.com/watch?v=HTUE03LnaXA">Emacs as a C/C++ Editor/IDE (Part I): auto-complete, yasnippet, and autoplete</a></li>
  <li><a href="https://www.youtube.com/watch?v=r_HW0EB67eY">Emacs as a C/C++ Editor/IDE (Part 2): iedit, flymake-google-cpplint, google-c-style</a></li>
  <li><a href="https://www.youtube.com/watch?v=Ib914gNr0ys">Emacs as a C/C++ Editor/IDE (Part 3): Installing CEDET mode for true intellisense</a></li>
</ul>

<p>which introduces the <code>auto-complete</code> for doing automatically completion.</p>

<p>At the same time, the extension
 <a href="https://github.com/tkf/emacs-jedi">emacs-jedi</a> only supports <code>auto-complete</code>
backend. And <code>emacs-jedi</code> is the only python code completion extension for
Emacs at then, which turns out that there were a number of others I did not
notice(see previously post on Python in Emacs). So I decided to use
auto-complete.</p>

<p>Then as the projects I worked on got bigger, the possible candidates provided
by <code>auto-complete</code> becomes too large to be useful due to the reason that
<code>auto-complete</code> will fetch all candidates from all sources.</p>

<p>The same problem happens to <code>auto-complete</code> in file path completion as
well. You get a lot of non-sense completion when you only want to get
completion in the path you want, which is a rather narrow space in the whole
space of all your possible completion candidates.</p>

<p>There could be a way to dynamically change the order of sources, but <code>company</code>
seems to do this automatically or people writes the backends for <code>company</code> do
this. In whatever case, the user does not need to attend to those things.</p>

<p>That is not the fatal problem yet, <code>auto-complete</code> has a annoying problem which
I do not know how to fix is that the time needed for the completion list to
respond to new input is at the magnitude of seconds. I am pretty sure this is
not a performance problem given that the completion list comes up pretty fast.</p>

<p><code>company</code> also solves the file completion problem and c headers completion
problem by providing a separate function in their respective backends, which I
just need to map another key binding to it so the completion will be very
accurate when you are programming.</p>

<p><code>auto-complete</code> does good when you are writing text heavy contents such as
LaTeX or markdown but not logically heavy ones such as programming language.</p>

<p>For a more complete comparison you could refer to the end of the 
<a href="http://company-mode.github.io/">github page</a> of <code>company</code>.</p>

<h2 id="on-using-them-together">On Using Them Together</h2>

<p>One more realization is that those two extensions are not exclusive at all. I
did not find a backend like the sources provided by <code>auto-complete</code> for
complete word in buffers related functions, which is the area <code>auto-complete</code> 
works well.</p>

<p>Below is some sample on how to use them from my
<a href="https://github.com/shawnLeeZX/emacs.d">Emacs configuration</a>.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
</pre></td><td class="code"><pre><code class="cl"><span class="line"><span class="p">(</span><span class="nv">add-hook</span> <span class="ss">&#39;after-init-hook</span> <span class="ss">&#39;global-company-mode</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="c1">;;   &quot;Modes for which `company-mode&#39; mode is turned on by</span>
</span><span class="line"><span class="c1">;; `global-company-mode&#39;.  If nil, means no modes.  If t, then all major modes</span>
</span><span class="line"><span class="c1">;; have it turned on.  If a list, it should be a list of `major-mode&#39; symbol</span>
</span><span class="line"><span class="c1">;; names for which `company-mode&#39; should be automatically turned on.  The sense</span>
</span><span class="line"><span class="c1">;; of the list is negated if it begins with `not&#39;.  For example: (c-mode</span>
</span><span class="line"><span class="c1">;; c++-mode) means that `company-mode&#39; is turned on for buffers in C and C++</span>
</span><span class="line"><span class="c1">;; modes only.  (not message-mode) means that `company-mode&#39; is always turned</span>
</span><span class="line"><span class="c1">;; on except in `message-mode&#39; buffers.&quot;</span>
</span><span class="line"><span class="p">(</span><span class="k">setq</span> <span class="nv">company-global-modes</span> <span class="o">&#39;</span><span class="p">(</span>
</span><span class="line">                            <span class="nv">c-mode</span>
</span><span class="line">                            <span class="nv">c++-mode</span>
</span><span class="line">                            <span class="p">))</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
</pre></td><td class="code"><pre><code class="cl"><span class="line"><span class="c1">;; Enable auto-complete for modes in ac-modes by default.</span>
</span><span class="line"><span class="p">(</span><span class="nv">global-auto-complete-mode</span> <span class="no">t</span><span class="p">)</span>
</span><span class="line"><span class="c1">;; We reset the default mode for auto-complete given that we want to some modes</span>
</span><span class="line"><span class="c1">;; to use company-mode.</span>
</span><span class="line"><span class="p">(</span><span class="nv">set-default</span> <span class="ss">&#39;ac-modes</span>
</span><span class="line">             <span class="o">&#39;</span><span class="p">(</span>
</span><span class="line">               <span class="nv">magit-log-edit-mode</span>
</span><span class="line">               <span class="nv">log-edit-mode</span> <span class="nv">org-mode</span> <span class="nv">text-mode</span> <span class="nv">haml-mode</span>
</span><span class="line">               <span class="nv">git-commit-mode</span>
</span><span class="line">               <span class="nv">conf-mode</span> <span class="nv">conf-unix-mode</span> <span class="nv">conf-colon-mode</span>
</span><span class="line">               <span class="nv">inferior-emacs-lisp-mode</span> <span class="nv">inferior-python-mode</span>
</span><span class="line">               <span class="nv">sql-interactive-mode</span>
</span><span class="line">               <span class="nv">sass-mode</span> <span class="nv">yaml-mode</span> <span class="nv">csv-mode</span> <span class="nv">espresso-mode</span> <span class="nv">haskell-mode</span>
</span><span class="line">               <span class="nv">html-mode</span> <span class="nv">nxml-mode</span> <span class="nv">smarty-mode</span> <span class="nv">clojure-mode</span>
</span><span class="line">               <span class="nv">lisp-mode</span> <span class="nv">textile-mode</span> <span class="nv">markdown-mode</span> <span class="nv">tuareg-mode</span>
</span><span class="line">               <span class="nv">js3-mode</span> <span class="nv">css-mode</span> <span class="nv">less-css-mode</span> <span class="nv">sql-mode</span>
</span><span class="line">               <span class="nv">web-mode</span>
</span><span class="line">               <span class="p">))</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2 id="difference-between-tab-and-tab">Difference Between <tab> and TAB</tab></h2>

<p>The last thing I want to note down is that TAB key.</p>

<p>Emacs has two tabs, <code>(kbd "&lt;tab&gt;")</code> and <code>(kbd "TAB")</code>. To make things more
complex, <code>yasnippet</code>, <code>auto-complete</code>, indentation in Emacs, typing real tab
stops and <code>company</code> all uses <code>tab</code>, which makes it very complicated.</p>

<p>From this
<a href="https://www.reddit.com/r/emacs/comments/2aemny/difference_between_tab_and_tab/">thread</a>
in Reddit, here, I knew that <code>(kbd "&lt;tab&gt;")</code> stands for the physical key you
have pressed and <code>(kbd "TAB")</code> stands for the control character. So to speak,
normally, if you are not binding <code>&lt;tab&gt;</code> to <code>TAB</code>, the tab you typed is not
actually the control character TAB, but triggers some function that is hooked
on the physical key’s response.</p>

<p>As for the second part of the puzzle, when you are typing tab at a location
where the indentation of the statement is not right, Emacs will indent your
line first. The key to differentiate <code>yasnippet</code> and <code>auto-complete</code> is whether
you are typing or not when you pressed the tab key. If you are, completion menu
will be triggered, if you are not <code>yasnippet</code> will be triggered(this is a
mechanism that could be configured in auto-complete and is not the default, by
default, I think the completion menu will pop up automatically). As for
<code>company</code> and <code>yasnippet</code>, in my experiments, after setting the trigger key to
tab, by default it seems that snippets are always gotten expanded the first,
then <code>company-complete</code> will be triggered if no snippets could be found. See
the following code snippets for how to set up key binding for <code>company</code>(it only
uses <code>company</code> if <code>irony-mode</code> is in usage).</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="cl"><span class="line"><span class="c1">;; Setup keymapping for company-complete.</span>
</span><span class="line"><span class="p">(</span><span class="nv">add-hook</span> <span class="ss">&#39;irony-mode-hook</span> <span class="p">(</span><span class="k">lambda</span> <span class="p">()</span>
</span><span class="line">                             <span class="p">(</span><span class="nv">local-set-key</span> <span class="p">(</span><span class="nv">kbd</span> <span class="s">&quot;&lt;tab&gt;&quot;</span><span class="p">)</span> <span class="ss">&#39;company-complete-common</span><span class="p">)</span>
</span><span class="line">                             <span class="p">(</span><span class="nv">local-set-key</span> <span class="p">(</span><span class="nv">kbd</span> <span class="s">&quot;C-c C-f&quot;</span><span class="p">)</span> <span class="ss">&#39;company-files</span><span class="p">)</span>
</span><span class="line">                             <span class="p">))</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2 id="reference">Reference</h2>

<ul>
  <li><a href="https://www.youtube.com/watch?v=HTUE03LnaXA">Emacs as a C/C++ Editor/IDE (Part I): auto-complete, yasnippet, and autoplete</a></li>
  <li><a href="https://www.youtube.com/watch?v=r_HW0EB67eY">Emacs as a C/C++ Editor/IDE (Part 2): iedit, flymake-google-cpplint, google-c-style</a></li>
  <li><a href="https://www.youtube.com/watch?v=Ib914gNr0ys">Emacs as a C/C++ Editor/IDE (Part 3): Installing CEDET mode for true intellisense</a></li>
  <li><a href="http://tuhdo.github.io/c-ide.html">tutorial on customizing C/C++ environment for emacs</a></li>
  <li><a href="https://www.masteringemacs.org/article/mastering-key-bindings-emacs">Mastering Key Bindings in Emacs</a></li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On IDEs of Python in Emacs]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/08/05/on-ides-of-python-in-emacs/"/>
    <updated>2015-08-05T10:30:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/08/05/on-ides-of-python-in-emacs</id>
    <content type="html"><![CDATA[<p>I was finally annoyed enough to find a replacement of <code>auto-complete</code> in
Emacs. Reasons will be noted down later. In this note, three common extensions
for writing Python under Emacs will be compared and noted, which are:</p>

<ol>
  <li><a href="https://github.com/tkf/emacs-jedi">jedi</a></li>
  <li><a href="https://github.com/jorgenschaefer/elpy">elpy</a></li>
  <li><a href="https://github.com/proofit404/anaconda-mode">anaconda</a></li>
</ol>

<!-- more -->

<p>I always used emacs-jedi since I made the shift from Vim to Emacs.</p>

<p>The functionality provided by emacs-jedi is actually quite good. The only function
that lacks is the one to refactor. So it is not the fault of emacs-jedi that makes me
want to change extensions. However, the detail will be left to the comparison
between <code>company-mode</code> and <code>auto-complete</code>.</p>

<p>Though emacs-jedi is not bad, it is also not that good compared with elpy, in my
opinion.</p>

<p>You could get good code completion, etc, basically everything roughly equal in
those three extensions. There are some details about elpy that makes me prefer
to elpy.</p>

<p>At the time that I set up emacs-jedi, basically I copied some the author’s hacking
code to let emacs-jedi recognize my current python files, or project
automatically. It works, but it does not feel elegant.</p>

<p>I could get by with that if it is not due to the reason of <code>auto-complete</code>.</p>

<p>With elpy, you could use command <code>elpy-set-project-root</code> to tell elpy that you
need current project to be taken into account, which does not feel
automatically but it is more user friendly and elegant.</p>

<p>What’s more, elpy takes into account the <code>PYTHON_PATH</code> environment variable
into account automatically. I guess emacs-jedi does this as well.</p>

<p>As for anaconda, actually I found it prior to elpy and also gave it a
try. However, it failed when I tried to get code completion on-the-fly in my
current project and no documentation seems to hint me how to deal with that.</p>

<p>Lastly, the refactoring function provided by elpy seems exciting so that I
won’t need to use <code>search-and-replace</code> or <code>multi-occur</code> stuff. But I did not
try it yet. Look forward to.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Some Notes on IPython Startup Script]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/08/03/some-notes-on-ipython-startup-script/"/>
    <updated>2015-08-03T16:22:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/08/03/some-notes-on-ipython-startup-script</id>
    <content type="html"><![CDATA[<p>This post is going to note down how to let ipython automatically reload a
module after changing the module and how to run magic function from python
start-up scripts.</p>

<!-- more -->

<p>ipython will not reload any modules if you have changed some module under given
that ipython want to keep the interactive session so all your data during the
session is going to be kept. To overcome this situation while you are writing
some module or library code, the <code>autoload</code> magic function could be used.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="o">%</span><span class="n">load_ext</span> <span class="n">autoreload</span>
</span><span class="line">
</span><span class="line"><span class="o">%</span><span class="n">autoreload</span> <span class="mi">2</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">%autoreload
</span><span class="line">Reload all modules <span class="o">(</span>except those excluded by %aimport<span class="o">)</span> automatically now.
</span><span class="line">
</span><span class="line">%autoreload 0
</span><span class="line">Disable automatic reloading.
</span><span class="line">
</span><span class="line">%autoreload 1
</span><span class="line">Reload all modules imported with %aimport every <span class="nb">time </span>before executing the Python code typed.
</span><span class="line">
</span><span class="line">%autoreload 2
</span><span class="line">Reload all modules <span class="o">(</span>except those excluded by %aimport<span class="o">)</span> every <span class="nb">time </span>before executing the Python code typed.
</span><span class="line">
</span><span class="line">%aimport
</span><span class="line">List modules which are to be automatically imported or not to be imported.
</span><span class="line">
</span><span class="line">%aimport foo
</span><span class="line">Import module ‘foo’ and mark it to be autoreloaded <span class="k">for</span> %autoreload 1
</span><span class="line">
</span><span class="line">%aimport -foo
</span><span class="line">Mark module ‘foo’ to not be autoreloaded.
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>For more details, refer to ipython’s
<a href="http://ipython.org/ipython-doc/dev/config/extensions/autoreload.html">documentation</a>.</p>

<p>To avoid typing those magic function again and again, they could be put in the
ipython startup script(Name it with <code>.py</code> suffix under
<code>.ipython/profile_default/startup</code>. All python scripts under that folder will
be loaded according to lexical order), which looks like the following:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">from</span> <span class="nn">IPython</span> <span class="kn">import</span> <span class="n">get_ipython</span>
</span><span class="line"><span class="n">ipython</span> <span class="o">=</span> <span class="n">get_ipython</span><span class="p">()</span>
</span><span class="line">
</span><span class="line"><span class="n">ipython</span><span class="o">.</span><span class="n">magic</span><span class="p">(</span><span class="s">&quot;pylab&quot;</span><span class="p">)</span>
</span><span class="line"><span class="n">ipython</span><span class="o">.</span><span class="n">magic</span><span class="p">(</span><span class="s">&quot;load_ext autoreload&quot;</span><span class="p">)</span>
</span><span class="line"><span class="n">ipython</span><span class="o">.</span><span class="n">magic</span><span class="p">(</span><span class="s">&quot;autoreload 2&quot;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On Frameworks of Deep Learning]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/08/01/on-frameworks-of-deep-learning/"/>
    <updated>2015-08-01T14:30:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/08/01/on-frameworks-of-deep-learning</id>
    <content type="html"><![CDATA[<p>I have spent the last two days trying to figure out what do use as a solid base
for further experiments on deep learning. I decided to settle down to Keras for
the time being. But given that it may not be the optimal choice, I want to note
down what I have tried so that it would be easier to pick up in the future.</p>

<!-- more -->

<p>At first, our lab members are using Caffe, which I have spent some effort
learning it. However, as I got to know more in this field, combining with my
background in Computer Science, Caffe is not really the best platform to do
experiments, at least not for the people who want to understand and experiment
on all the details of various neural network elements and added another layer
of unnecessary engineering burden to the experiments.</p>

<p>Starting from the motivation to actually code NN from scratch, a language as
low level as C++ is not the right choice. Maybe at the time that I am really
equipped and really need large scale experiments, I will get back to Caffe.</p>

<p>Then I came to try Torch. At first I held high expectation given that:</p>

<ol>
  <li>The easy binding between Lua and C.</li>
  <li>The API of torch is rather clean and most of the non-computational intensive
are actually written in Lua, which would save a ton of time.</li>
  <li>The <code>image</code> package of Torch is great given the experience to do
visualization under Python.</li>
  <li>Lua is not a barrier to me, given that I learn a new language rather fast.</li>
</ol>

<p>Then I spent some time to learn the code organization of Torch. Basically,
Torch is a combination of <a href="http://luajit.org/">LuaJIT</a> with Lua packages and C
Libraries. It uses CMake to compile the project. So far so good.</p>

<p>But the real problem comes when I tried to find out a reasonable environment to
write Lua code. SURPRISINGLY, both Emacs and Vim does not have a work
environment for Lua. Emacs does not even have a usage syntax highlighting
for Lua. As for Vim, it does have a usage syntax highlighting, but it stops at
that. All other packages:</p>

<ul>
  <li><a href="http://www.vim.org/scripts/script.php?script_id=3169">luainspect.vim</a>:
Semantic highlighting for Lua in Vim</li>
  <li><a href="http://www.vim.org/scripts/script.php?script_id=4950">Lua Support 2</a> : Lua
IDE. Insert codesnippets, run, compile, and check the code and look up help.</li>
  <li><a href="http://www.vim.org/scripts/script.php?script_id=3625">lua.vim</a> : Lua file
type plug-in for the Vim text editor</li>
  <li><a href="http://www.vim.org/scripts/script.php?script_id=3331">lua_omni</a> : omni
completion for Lua plus few extras</li>
</ul>

<p>are buggy in some extent and I really do not have time to fix them.</p>

<p>Then I tried to find some IDE recommended by the Torch documentation. There are
Eclipse with LDT, zbs-torch and some others, which all sucks. Maybe I have been
using Emacs and Vim for too long…</p>

<p>After about one day’s struggling with all different IDEs, I decided to try new
frameworks based on Theano, even they are all in their infancy.</p>

<p><a href="https://blocks.readthedocs.org/en/latest/">Pylearn2</a> and
<a href="https://blocks.readthedocs.org/en/latest/">Blocks &amp; Fuel</a> feels a bit
convoluted in design. Opendeep, Lasagne, Keras look alike. Given Keras offers
to enforce constraints on parameters, I decided to try Keras first.</p>
]]></content>
  </entry>
  
</feed>
