<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[SHAWN LEE]]></title>
  <link href="http://shawnLeeZX.github.io/atom.xml" rel="self"/>
  <link href="http://shawnLeeZX.github.io/"/>
  <updated>2015-12-15T21:15:39+08:00</updated>
  <id>http://shawnLeeZX.github.io/</id>
  <author>
    <name><![CDATA[Shawn]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[On KKT Condition and Optimality Condition of Conic Linear Programming]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/12/15/on-kkt-condition-and-optimality-condition-of-conic-linear-programming/"/>
    <updated>2015-12-15T20:18:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/12/15/on-kkt-condition-and-optimality-condition-of-conic-linear-programming</id>
    <content type="html"><![CDATA[<p>Yet another note on Math.</p>

<p>In LP and SDP, the complementary slackness are written as</p>

<script type="math/tex; mode=display">
(c - A^{T}y)^{T}x = 0\\
(C -\sum\limits_{i}y_{i}A_{i}) \bullet X = 0
</script>

<p>While KKT condition’s complementary slackness is</p>

<script type="math/tex; mode=display">
v^{T}g(x) = 0
</script>

<p>It is hard to connect them at first glance, since dual variable $v$ is dual to
the space of $g(x)$, which is not necessarily in the same space with $x$.
Especially when $x$ is the big matrix $X$ in SDP, $g(X)$ lies in vector space
instead of matrix space.</p>

<p>This is the note for the how they are connected.</p>

<!-- more -->

<h2 id="linear-programming">Linear Programming</h2>

<p>For linear programming, we write down its Lagrange</p>

<script type="math/tex; mode=display">
c^{T}x + y^{T}(b - Ax) - s^{T}x
</script>

<p>its gradient is $c - A^{T}y - s$</p>

<p>so its KKT condition is</p>

<script type="math/tex; mode=display">
c - A^{T}y - s = 0 \text{ Stationary point}\\
x \geq 0, Ax = b \text{ Primal feasibility}\\
s^{T}x = 0, s \geq 0 \text{ Complementary slackness}
</script>

<p>Now we see $(c - A^{T}y)^{T}x = 0$ is the combination of stationary point
condition and complementary slackness condition. The special structure occurs
here because</p>

<ol>
  <li>In linear problem, analytic solution of equation is possible.</li>
  <li>$g(x)$ is just $x$, so their spaces are the same.</li>
</ol>

<p>Note when LP reaches its optimal value, we always have $c^{T}x = b^{T}y =
(A^{T}y)^{T}x$, but there is a difference $s$ between $c$ and $A^{T}y$. Here we
see the specialty of LP. When one dimension of $s$ is not zero, we have
correspond dimension of $x$ to be zero. Due to the linearity of $c^{T}x$, the
zero directly reflects on the objective value, which makes correspond
dimension’s contribution to zero. Now it is clearer why duality gap is always
zero.</p>

<h2 id="semi-definite-programming">Semi-Definite Programming</h2>

<p>For SDP, if we want to draw analog with LP, the Lagrange may look like</p>

<script type="math/tex; mode=display">
C \bullet X + \sum\limits_{i}y_i(b_i - A_i \bullet X) - S \bullet X
</script>

<p>its gradient is <script type="math/tex">C - \sum\limits_{i}y_i A_i - S</script>.</p>

<p>So its KKT condition is</p>

<script type="math/tex; mode=display">
C - \sum\limits_{i}y_i A_i - S = 0\\
x \succeq 0, A_i x = b_i\\
S \bullet X = 0
</script>

<p>which is almost the same in format with that of LP.</p>

<p>But note</p>

<ol>
  <li>KKT does not work wit matrix inequality yet, so $S \bullet X$ cannot be
moved up to the Lagrange function. Though it does suggest some form of
KKT condition that could deal with matrix inequality may exist.</li>
  <li>The relationship is not linear anymore, both in $X \succeq 0$ and $C \bullet
X$ because the symmetric constrain enforced on $X$, which makes $X$ not just
a matrix form vector.</li>
  <li>$g(X) \succeq 0$ maps matrix to matrix space, so actually complementary
slackness also should be in the space of matrix, and in form of matrix inner
product.</li>
</ol>

<p>So there should be a duality gap normally.</p>

<h2 id="last-note-on-dual-variables">Last Note on Dual Variables</h2>

<p>From above, we see the reason we have matrix inner product style complementary
slackness is due to we are using dual variable in matrix space. It is
interesting to see how general dual variable or linear hyperplane is on solving
problem on any space, though I have not learned any proof of Lagrange on spaces
other than Euclidean space yet.</p>

<h2 id="last-note-on-linearity">Last Note on Linearity</h2>

<p>In conic linear programming,</p>

<ol>
  <li>when putting constrains in Lagrange function, it directly interacts with
objective function, meaning variable $x$ could be separated out.</li>
  <li>The specialty of $x \geq 0$ makes its dual variable the slack variable.</li>
  <li>Linearity makes dual function $\inf \ldots$ analytic solvable, so we only
see $\max$ in the dual problem.</li>
</ol>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On Duality in Optimization]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/12/14/on-duality-in-optimization/"/>
    <updated>2015-12-14T21:09:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/12/14/on-duality-in-optimization</id>
    <content type="html"><![CDATA[<p>Yet another note on Math.</p>

<p>A more general picture of duality in optimization emerges itself. Some time is
still needed to unify all duality in optimization, but for now I summarize a
draft version of it here using duality of linear programming as an example.</p>

<!-- more -->

<h2 id="intuition-of-lagrange-multiplier-from-functional-analysis">Intuition of Lagrange Multiplier From Functional Analysis</h2>

<p>In its most general form, optimization problem is</p>

<script type="math/tex; mode=display">
\max\ f(x)\\
G(x) \geq 0\\
H(x) = 0
</script>

<p>where $G(x)$ is the group of inequality constrains <script type="math/tex">g_i(x)</script>; $H(x)$ is the
group of equality constrains <script type="math/tex">h_i(x)</script>; $x \in X = R^{n}$ or $x \in X = R^{m
\times n}$, where $x$ is taken as matrix variables.</p>

<p>The domain of the problem is implicitly defined by $G(x)$ and
$H(x)$. Geometrically, $H(x) = 0$ describes some surface in $X$. $G(x)$
describes some &#8220;half space’’.</p>

<p>The question to ask is: what objects should we take those constrains as? so we
could internalize and reason with them.</p>

<p>In abstract sense, if we take $f(x), G(x), H(x)$ as variables, or in a more
intuitive word, as objects, in our perception the problem seems not to be that
abstract and convoluted. Their dependency on $x$ seems to gone. This is the
idea from functional analysis. We are just doing space transform on the
original space $X$. After the transform, we try to find the extreme value of a
specific coordinate of the new space, which is $f(x)$, in a sub-area of the new
space, which describes by constrains.</p>

<p>Despite of the non-linearity, every natural phenomena in nature, thus in Math,
comes from certain metamorphism of linear phenomena. To say it in another way,
though we could create very bizarre phenomena with math trick, the real world
should be analyzed starting from the linearity, not for simplicity or
computation’s sake.</p>

<p>But how could we come up with linearity?</p>

<p>This brings to think why constrains exists. It exists because in real world,
certain things has to be satisfied, it could be a fixed location, or limited
amount of resources and so on. The real world constrain is somehow connected to
the objective function, otherwise it won’t exist at all. So how could we model
such connection?</p>

<p>This is the key to the entry of duality.</p>

<p>We have to find the connection of variables $G(x), H(x)$ to another variable
$f(x)$. As having been discussed, every natural phenomena somehow comes from
metamorphism of linear phenomena. An example is the invention of calculus,
which is the how non-linear phenomena behaves locally. The way we connect those
variables is through their linear combination. This in the language of
functional analysis is to say we analyze the primal space from its dual space.</p>

<p>Now back to Lagrange duality. Lagrange multiplier is elements in dual space of
the space made up by $f(x), G(x), H(x)$.</p>

<p>This intuition unscramble constrains.</p>

<h2 id="an-example-linear-programming">An Example: Linear Programming</h2>

<p>Linear programming is the case where all things are linear. So nothing
metamorphized. When we only deal with gradients in a specific point in
non-linear programming, such as the case of KKT condition, Fritz-John
condition, it is actually exactly the optimality condition of linear
programming.</p>

<p>Previously I have noted an possible motivation of Linear programming. Now I
could see the previous note(about two months ago) is just a special case of
previous idea.</p>

<p>For a LP problem, as the following</p>

<script type="math/tex; mode=display">
\max\ c^{T}\\
Ax = b\\
x \geq 0
</script>

<p>I tried to see it from adjoin operator point of view, which is to find
something from $A^{T}$. For details, please refer to previous
<a href="http://shawnLeeZX.github.io/blog/2015/10/18/linear-programming-from-dual-mapping-point-of-view/">note</a>.</p>

<p>Now we write the Lagrange of LP, the dual function is</p>

<script type="math/tex; mode=display">
\inf\limits_{x} c^{T}x + y^{T}(Ax - b) - s^{T}x
</script>

<p>note we have $s \geq 0$.</p>

<p>Now we see how could we deduce it from previous argument of last
<a href="http://shawnLeeZX.github.io/blog/2015/10/18/linear-programming-from-dual-mapping-point-of-view/">note</a>.</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{align*}
                &  \langle 1, c^{T}x \rangle + \langle y, Ax -b \rangle - \langle s, x \rangle\\
\Leftrightarrow &  \langle c, x \rangle + \langle y, Ax -b \rangle - \langle s, x \rangle\\
\Leftrightarrow &  \langle c - s, x \rangle + \langle y, Ax \rangle - \langle y, b \rangle\\
\Leftrightarrow & - \langle y, b \rangle +  \langle c - s, x \rangle + \langle y, Ax \rangle \\
\Leftrightarrow & - \langle y, b \rangle +  \langle c - s, x \rangle + \langle A^{T}y, x \rangle \\
\Leftrightarrow & - \langle y, b \rangle +  \langle c - s + A^{T}y, x \rangle \\
\Leftrightarrow &  \langle y, b \rangle +  \langle c - s - A^{T}y, x \rangle \\
\end{align*}
 %]]&gt;</script>

<p>We find some connection between dual space and primal space now. To make the
part of dual space be a lower bound, we ask $s \geq 0$. This is just the
zooming idea previously.</p>

<p>The more geometrically picture is the geometrical intuition from Lagrange
duality.</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{align*}
 & \inf\limits_{x} \langle c, x \rangle + \langle y, Ax -b \rangle - \langle s, x \rangle\\
\Leftrightarrow & \inf\limits_{x} \langle c - s, x \rangle + \langle y, Ax \rangle - \langle y, b \rangle\\
\Leftrightarrow & - \langle y, b \rangle + \inf\limits_{x} \langle c - s, x \rangle + \langle y, Ax \rangle \\
\Leftrightarrow & - \langle y, b \rangle + \inf\limits_{x} \langle c - s, x \rangle + \langle A^{T}y, x \rangle \\
\Leftrightarrow & - \langle y, b \rangle + \inf\limits_{x} \langle c - s + A^{T}y, x \rangle \\
\Leftrightarrow &  \langle y, b \rangle + \inf\limits_{x} \langle c - s - A^{T}y, x \rangle \\
\end{align*}
 %]]&gt;</script>

<p>The $\inf$ could move the dual variable down. So we have a constrained problem
again.(Details are omitted, and could be found at <em>Nonlinear Optimization
Andrzej Ruszczynski</em> or some other books talk about Lagrange duality).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[General Transform, Linear Transform, Matrix]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/11/30/general-transform-linear-transform-matrix/"/>
    <updated>2015-11-30T10:30:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/11/30/general-transform-linear-transform-matrix</id>
    <content type="html"><![CDATA[<p>Yet another note on Math.</p>

<p>Previously, the origin of Matrix for me comes from linear transform, and
nothing more. Most of the intuitive comes from linear space transform, as in
the example of orthogonal Fourier transform or wavelet transform. As I learn
more and more optimization, and how it computes dual, matrix as a limit case of
non-linear transform comes to me. The linear transform characteristics is just
to approximate the nonlinear transform locally.</p>

<!-- more -->

<h2 id="how-matrix-originally-arises">How Matrix Originally Arises</h2>

<p>Originally, matrix origins from linear transform, and is called linear
operator.</p>

<p>The deviation comes from how a basis of space $X$ gets mapped to another space
$Y$. For details, please refer to <em>Linear Algebra Done Right</em>, <em>Introductory
Functional Analysis with Application</em>, <em>A Friendly Introduction to Wavelet</em>, or
any other books that talks about linear algebra.</p>

<p>The underlying idea is pure linear, and does not touch nonlinear at all.</p>

<h2 id="matrix-as-limit-case-of-nonlinear-transform">Matrix As Limit Case of Nonlinear Transform</h2>

<p>The study of constrained nonlinear optimization made me thinking, when seeing
it in the most general form</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{align*}
  \text{minimize  } & f(x) \\
  \text{subject to } & g_i(x) \leq 0
\end{align*}
 %]]&gt;</script>

<p>First I simplify the problem to linear programming.</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{align*}
  \text{minimize  } & f(x) \\
  \text{subject to } & Ax - b \leq 0
\end{align*}
 %]]&gt;</script>

<p>Solving system of linear equations is a central theme in Math, and it confused
me when I had no idea relating the matrix $A$ in the system of equations to the
space transform intuition of matrix.</p>

<p>If I try to explain it by normal space transform, $Ax$ becomes</p>

<script type="math/tex; mode=display">
\sum\limits_{i}\vec{a_{i}}x_{i}
</script>

<p>where $\vec{a_{i}}$ is columns of $A$.</p>

<p>It is explained as whether $b$ is in range of $A$, and range of $A$ is
picturized as a space, which have nothing to do with $A$. The connection is
broken.</p>

<p>But if we change a perspective, write $Ax$ as</p>

<script type="math/tex; mode=display">
\vec{a_{i}}^{T}x
</script>

<p>where here $\vec{a_{i}}^{T}$ is the row of $A$.</p>

<p>Denote the space $x$ belongs to as $X$, the one $Ax$ belongs to as $Y$, dual of
$X$ as $X^{*}$.</p>

<p>Assuming the bases of $X$ is orthonormal, which is normally in practice,
<script type="math/tex">\vec{a_{i}}</script> is a basis of $Y^{*}$ gets mapped to <script type="math/tex">X^*</script>.</p>

<p>Dual space $X^{*}$ consists of linear functional defined on $X$. The intuitive
of linear functional $g(x)$ is the effect of change on $x$ will influence
$g(x)$ linearly. Think it as cost or price would clarify.</p>

<p>Write <script type="math/tex">\vec{a_{i}}^{T}x = g_{i}(x)</script>, the procedure how matrix transform $x$
becomes clearer. The idea is a linear weighted combination of different
elements of $x$. <script type="math/tex">\vec{a_{i}}^{T}x = g_{i}(x) \leq b_{i}</script> means in the direction of
$\vec{a_{i}}$, the projection of $x$ on it could not exceed a certain value,
which is also could be understood as some physical meaning, such as price,
or threshold.</p>

<p>So matrix is a stack of linear functionals and overall they together make up
some linear transform. If all the linear functionals are linear independent,
the system is invertable, so the matrix has an inverse. If all the linear
functionals are orthogonal, then the weighted sum does not influence each
other.</p>

<p>Now, the rank of matrix makes a lot of sense, and matrices that are not
unitary could be of more use.</p>

<p>Back to the most general form of nonlinear optimization. When the system
approaches its optimal solution, everything becomes more and more linear. The
problem actually boiled down to again, a linear problem. Everything matters are
just <script type="math/tex">g_{i}'</script>, which is just as linear as linear programming, and as
matrix. This is the base of Lagrange multiplier methods.</p>

<h2 id="optimality-condition-of-equality-constrained-optimization-an-example">Optimality Condition of Equality Constrained Optimization: An Example</h2>

<p>An example would make the idea that matrix’s nature on linear transform
clearer. I learned this example ten days after I wrote this note.</p>

<p>Given the following equality constrained problem</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{align*}
  \text{minimize  } & f(x) \\
  \text{subject to } & H(x) = \theta
\end{align*}
 %]]&gt;</script>

<p>Note we are using vector notation now. Denote the Jacobian of $H(x)$ as
$H’(x)$; $x \in X$, $H(x) \in Z$, where $X$ is a linear vector space, while $Z$
is a normed space. Suppose this problem reaches its constrained minimum
<script type="math/tex">x^{*}</script>. We assume <script type="math/tex">x^*</script> is a regular point, which means <script type="math/tex">H'(x^*)</script> maps
$X$ onto $Z$. If $Z$ is of finite dimension, it just means <script type="math/tex">H'(x^*)</script> is of
full rank.</p>

<p>To digress a little, if the mapping <script type="math/tex">H'(^*x)</script> is not onto, it means there is
linear dependence in the gradients of <script type="math/tex">H(^*x)</script> at <script type="math/tex">x^*</script>. When equality
constrains have linear dependence, the feasible region is empty. A picture
would be two parallel hyperplane, who do not intersect each other. For more
complex examples, refer to chapters of <em>Nonlinear Programming, Bertsekas</em>, or
<em>Nonlinear Programming, Theory and Algorithms</em> on optimality conditions.</p>

<p>The above clarification of terminology is to make the argument satisfies for
both infinite dimension and finite dimension space.</p>

<p>Since <script type="math/tex">x^*</script> is minimum(for now we use $x$ instead of <script type="math/tex">x^*</script> for convenience
sake), $\nabla f(x)$ has to be orthogonal to the direction $h$, where $H’(x)h =
\theta$. It means $\nabla f(x)$ is orthogonal to $N(H’(x))$, null space of
$H’(x)$. Now we could see clearly a linear transform, aka matrix is the limit
case of a general non-linear transform, or in another word, the local
approximation of general non-linear transform $H(x)$, in form of $H’(x)$.</p>

<p>To recap the last section, from a linear algebra point of view, we internalize
$Ax$ by how a component of $x$ is represented by coordinates in the new
space. But from a transform point of view, we internalize matrix as applying
each row of $A$, a linear functional to $x$ repeatedly. So whether a matrix is
of full, or be orthogonal does not matter that much. We just create a transform
by stacking some functional row by row.</p>

<p>The latter point of view is the intrinsic nature of transform. But the reason
much efforts have been made in linear algebra is because often ultimately a
problem would be attacked from linear point of view, which is the case of this
example. With the machinery from linear algebra, a much rich structure could be
used instead of just general transform.</p>

<p>Remember in a <a href="http://shawnLeeZX.github.io/blog/2015/10/18/linear-programming-from-dual-mapping-point-of-view/">note</a>
on Linear programming, the intuition of $Ax$ is to map a point from a space $X$
of points to another space of points $Z$, then its dual map or adjoin map
$A^{T}$ is to map dual space <script type="math/tex">Z^{*}</script> to <script type="math/tex">X^{*}</script>.</p>

<p>If $\nabla f(x) \perp N(H’(x))$, it means <script type="math/tex">f(x) \in R(H'(x)^*)</script>. So there
exists a <script type="math/tex">z^{*} \in Z^{*}</script> satisfying <script type="math/tex">f(x) = z^{*}H'(x)^{*}</script>, which could
be written as</p>

<script type="math/tex; mode=display">
\nabla f(x) + \langle z^{*}, H'(x) \rangle
</script>

<p>which is the optimality condition of optimization problems with equality
constraints.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Cone, Dual Cone and Generalized Inequalities]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/11/28/cone-dual-cone-and-generalized-inequalities/"/>
    <updated>2015-11-28T11:04:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/11/28/cone-dual-cone-and-generalized-inequalities</id>
    <content type="html"><![CDATA[<p>Yet another note on Math.</p>

<p>I did not internalized the idea that a pointed cone identifies a generalized
equality until now, and would like to note it down.</p>

<!-- more -->

<h2 id="cone">Cone</h2>

<p>Let’s start with why we want inequality. We want it because we want to compare
two objects. In $R$, an object in this domain is a scalar and represents
something like length, or so. Suppose we want to compare the length of one edge
of a table and the length of a ruler. We put those two together.  Intuitively,
a table looks longer than a ruler, so we say if we want to compare anything
similar like those again, we standardize a unit, according to the reference to
the length of table or ruler, which in the ancient time is the length of some
king’s feet, give a length $x$ to object one, $y$ to object two, then if object
one is longer than object two, we call $x &gt; y$.</p>

<p>How could we generalize this idea to higher dimensional space? Consider vector
inequality. Suppose we want buy a department. The only factors we want to
consider is which floor our department is(assume the higher the better), and
how many square meters it has. What does department $x$ is better than $y$
mean? An intuitive answer is a department that is both higher and bigger is a
better choice. We call it $x \succeq y$.</p>

<p>We could see how cone abstract things here, in vector inequality.</p>

<p>First we break thing down, if we get two rulers, whose lengths are too similar
to tell who is longer in a distance, how could we tell? Without equipment, we
just put those two rules together, and see their difference. This is the mental
procedure we execute when we compare, so in scalar case, $x &gt; y$ means $x - y
&gt; 0$; in vector case, $x \succeq y$ means $x - y \succeq 0$.</p>

<p>What is special about $x - y$?</p>

<p>If we take it abstractly, $x - y$ means how much better when $x$ is compared to
$y$. How we define inequality is determined by how we measure the &#8220;better’’
amount, so the measurement makes sense. For scalar it is just their value
difference. But for vector we cannot judge when department $x$ has higher floor
number than $y$ but smaller square meters. The solution to this dilemma is to
only compare the case where the comparison makes sense. Mathematically, it
means we only compare $x, y$ when $x, y$ stay in a domain, which depends on
both $x, y$, where the comparison makes sense. If $x - y$ is in the domain, we
compare, otherwise, do not bother.</p>

<p>Though we only convert the comparison of $x, y$ to whether $x - y$ belongs to a
domain. We do not know what the domain looks like yet. We want to reach the
conclusion the domain is a pointed cone, or in another name, proper cone.</p>

<p>The next task is to figure out the properties of the domain. What properties do
we want? Let’s list them:</p>

<ol>
  <li>Comparison is about direction and it does not matter if $x$ is a hundred
bigger than $y$, or one hundred percent bigger.</li>
  <li>Strict inequality should exist.</li>
  <li>Difference could be added together: If $x$ is better than $y$, $y$ is better
tan $z$, we should have $x$ is better than $z$.</li>
  <li>Limitation stays in the domain: slightly better is still better.</li>
</ol>

<p>Denoting the domain $K$, those four are translated to</p>

<ol>
  <li>$K$ is a pointed cone, i.e., if $u \in K$ and $-u \in K$, then $u = 0$; for
any $x \in K$ and $\alpha &gt; 0$, we have $\alpha u \in K$.</li>
  <li>$K$ has non-empty interior.</li>
  <li>$K$ is non-empty and closed under addition; i.e., for any $x, y \in K$, $x +
y \in K$.</li>
  <li>$K$ is closed.</li>
</ol>

<h2 id="dual-cone">Dual Cone</h2>

<p>Dual cone is about giving each dimension of an object a linear measurement of
weight, or more intuitively a price, so:</p>

<ol>
  <li>A integrated &#8220;betterness’’ could be quantified for all pairs instead of
just $K$, a restricted set of comparable pairs.</li>
  <li>consequently could lead to dual problem, which is a upper and lower bound by
linear approximation.</li>
</ol>

<p>Due to time limitation, I will just write those for now. Some pictures and
example of minimum elements and minimal elements from <em>Chapter 2, Convex
Optimization Bloyd</em> could be helpful.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Notes on Semidefinite Programming]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/11/15/notes-on-semidefinite-programming/"/>
    <updated>2015-11-15T21:23:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/11/15/notes-on-semidefinite-programming</id>
    <content type="html"><![CDATA[<p>Yet another note on math.</p>

<!-- more -->

<p>SDP is actually a relaxation techniques that projects the problem to a higher
dimension space with a symmetrical matrix special structure. So the original
non-linear problem gets linearized. In the simplest case, $x$ gets mapped to
$X = xx^{T}$, then relaxed to $X \in S_{+}$ It just puts the second order terms
of $x$ in the matrix. Similar things could be done in for higher order terms,
and finally, any order polynomial could be achieved in some way.</p>

<p>I am still not thinking very clearly how operator could be put into the context
since here matrices are just a special way to put a really long
vector. Frobenius inner product is just normal inner product. The power of SDP
comes from infinite number of quadratic constraints enforced by the PD
condition.</p>

<p>The connection could possibly be this way. It is inspired by how matrix
derivative is defined using Frobenius norm. Though operator’s nature comes from
it spectral structure, it is still made by $m \times n$ numbers put in a
special way. So a corresponding change in the corresponding position means
something. By measuring the norm, and inner product in this way, we are somehow
connected to the spectral structure of the matrix. By adding different matrices
together this way, we are somehow combining different operations, though I have
not learned any applications that matches this exactly. An perfect example of
this is the perturbation of a matrix. The perturbation in each dimension is
added on the face value(the number displayed on the entries of the matrix), so
it natural to think regardless of the spectral structure of the matrix,
whatever it may be normalized then or by changed by some other operations, the
face value change is how we perceive physical beings.</p>

<p>SDP is solved using interior point methods, whose intuitive is to guide the
optimization by the objective function, using gradient and hessian
information. To make sure the point stay feasible when optimizing, a term $-log
det|A|$ is added to the objective function, who will ensure $X \succeq \mu I$
for some $\mu$, meaning it is positive definite.</p>

<p>This is a very beautiful idea. Actually it is what I was looking for in
non-linear optimization so that the boundary information not only guide
optimization only when the point is near the boundary but also when it is far
in the boundary.</p>

<p>More thinking may be added when I learned more about SDP, matrix algebra and
matrix calculus.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Note On Compiling Tensorflow]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/11/13/note-on-compiling-tensorflow/"/>
    <updated>2015-11-13T11:35:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/11/13/note-on-compiling-tensorflow</id>
    <content type="html"><![CDATA[<p>A note on setting library path for cudnn when compiling tensorflow, in case I
forget it next time.</p>

<!-- more -->

<p>Directly providing the library path to cudnn, which has the following directory
structure,</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">include  lib
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>does not work.</p>

<p>According to the error message, it seems that the configuration tries to find
header file and shared libraries directly under the provided folder, thus this
time, I made another folder specifically for tensorflow — it is not in
<code>LD_LIBRARY</code>, so other programs do not use it — then the compilation works.</p>

<p>Since I just want to make sure I could get through the compilation process to
make sure if in case there are features not provided in the official binary, I
have a way to use it, I settled for now. But since the default folder is just
where CUDA lives, I guess if I made the directory structure of CUDNN the same
as CUDA, which I just need to add a symbol link <code>lib64</code> to <code>lib</code>, the
compilation may still work.</p>

<p>So this is the note.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On Linear Programming, Duality of LP and Operator, a Functional Analysis Point of view]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/10/18/linear-programming-from-dual-mapping-point-of-view/"/>
    <updated>2015-10-18T12:39:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/10/18/linear-programming-from-dual-mapping-point-of-view</id>
    <content type="html"><![CDATA[<p>Yet another note on Math, about visualization of Linear Programming, some
thoughts on Operator and Adjoin.</p>

<!-- more -->

<h2 id="dual-map-and-adjoin-operator">Dual Map and Adjoin Operator</h2>

<p>Denote the matrix of a linear mapping $T$ corresponds to natural bases as $A$,
then $A^{T}$ is the matrix corresponds to the dual map of $T$. More
specifically, if the bases of the two space, the original space and its dual,
are orthogonal respectively, $A^{T}$ is the adjoin operator of $A$. Now suppose
$A \in R^{M \times N}$.</p>

<p>For a linear programming problem, the constraints are $Ax \leq b$, intuitively,
we understand it as a polyhedron, the intersection of finite number of
halfspaces.</p>

<p>We could also understand it from linear mapping and dual bases point of view.</p>

<p>$A$ maps points from $R^{N}$ to $R^{M}$. A column of $A$ corresponds to the
coordinates of the an natural basis of $R^{N}$ in the new $R^{M}$, meanwhile,
a column of $A^{T}$, which is a row of $A$, corresponds to the coordinates of a
dual basis of a natural basis of $R^{M}$ in $R^{N}$ if it is transformed by
$A^{T}$.</p>

<p>So a row $\vec{a_{i}}$ of $A$ is a $A^{T}$ transformed dual basis that
corresponds to one natural basis in $R^{M}$, which corresponds to a hyperplane
in $R^{N}$, also an element of the dual space of $R^{N}$.</p>

<h2 id="on-the-feasible-region-of-linear-programming">On the Feasible Region of Linear Programming</h2>

<p>Now we try to see whether we could get a picture from the above concepts.</p>

<h3 id="a-previous-possibly-wrong-attempt">A Previous Possibly Wrong Attempt</h3>

<p>This is the first visualization I have tried. It turns out not that right after
I discussed the idea with my optimization course teacher.</p>

<p>From this perspective, the polyhedron in $R^{N}$ is a squashed(or enlarged)
quadrant of $R^{M}$, which is the intersection of hyperplanes whose normals are
natural bases of $R^{M}$ — the hyperplanes only need to pass a constant
value, probably corresponding dimension of $b$(have not thought very clearly),
do not necessarily pass origin point.</p>

<p>If $M &gt; N$, $R^{M}$ gets squashed, and there are much freedom in the way how
the space gets squashed, which is analog with we have more equations than
variables, so it is easier to get solutions. Otherwise, $R^{M}$ gets enlarged,
however, no matter how the enlarging is done, it still remains as a low
dimensional space in the high dimensional space, thus the freedom is limited,
which is analog with more variables than equations, so it is harder or
impossible to get solutions.</p>

<h3 id="reason-in-the-standard-form">Reason In the Standard Form</h3>

<p>If we convert the problem to the standard form of linear programming, we could
see that the dimension or the original space is usually larger than the dual
space, otherwise, the feasible region could be easily empty. In this case, the
argument, that the dual space gets squashed, does not hold. But a different
picture turns out immediately.</p>

<p>Intuitively, which means it is not necessarily right, as long the objective
function does not parallel with one of the constraints, the solution to LP is a
basic solution, otherwise, we could move the point along one of the constraint
to change the objective value. Now we only discuss basic solutions.</p>

<p>For every basic solution, we have $N$ constraints being active. Note that $N$
is the dimension of the dual space. Thus, each set of $N$ active constraints
corresponds to a version of dual space that gets mapped from the standard basis
of dual space by those columns of $A^{T}$. More specifically, each active
hyperplane in the $R^{M}$ is a basis in the dual space $R^{N}$.</p>

<h2 id="on-duality-of-linear-programming">On Duality of Linear Programming</h2>

<p>This leads to an intuition about how on earth the dual problem of LP is
conceived in the first place, and makes its extension to conic programming
clear.</p>

<p>From my understanding, the dual in Optimization is to find a lower bound of the
distance in the original space in its dual space, being it the shortest
distance from a point to a subspace, from a point to a closed convex set or a
convex epigraph to a concave epigraph of functions. Those three examples, which
is three types of dual in infinite dimensional optimization try to find a
linear approximate lower bound for a normally non-linear objective
function. Their dual problems are usually some kind of LP, or other forms could
be easily solved. But for LP, all parts in the problem is already linear. From
this line of thinking, the dual of LP is to find a lower bound in the dual
space of $Ax$. How could this be? The key lies in the adjoin operator.</p>

<p>The standard form of LP is</p>

<script type="math/tex; mode=display">
\max\ c^{T}\\
Ax = b\\
x \geq 0
</script>

<p>We have an adjoin relation</p>

<script type="math/tex; mode=display">
\langle Ax, y\rangle = \langle x, A^{T}y \rangle\\
\langle b, y\rangle = \langle x, A^{T}y\rangle\\ 
\langle b, y\rangle \leq \langle x, c\rangle
</script>

<p>The last inequality holds because we have $x \geq 0$.</p>

<p>Conic programming just extends the meaning of $\geq$ and inner product.</p>

<h2 id="the-algebraic-nature-of-operator">The Algebraic Nature of Operator</h2>

<p>All of the thinking about originates from the way I learn Math. I want to get a
picture from the symbols and relationships. Up to now, all concepts I know
could be put into a 2D or 3D system with or without coordinates in my mind,
being it topology space, metric space, Banach space, inner product space,
Hilbert space, dual space, affine set, convex set, cone, measure, probability
measure and so on. Dual in optimization is a new concept, and I want to put it
somewhere in the system. In about 4 days, I almost finished the book
<em>Optimization by Vector Space Method</em>, which is about infinite dimensional
optimization, and learned the three kinds of duals mentioned before. I indeed
came up with similar visualization tricks mentioned in the book before I read
them. But in the section, some words rang a bell, after a few days I read them
and pondered on the meaning of adjoin, the relation between the $Ax$ and $X$.</p>

<p>At the beginning of the Chapter Six</p>

<blockquote>
  <p>Because it is difficult to obtain a simple geometric representation of an
arbitrary linear operator, the material in this chapter tends to be somewhat
more algebraic in character than that of other chapters. Effort is made,
however, to extend some of the geometric ideas used for the study of linear
functionals to general linear operators and also to interpret adjoints in
terms of relations among hyperplanes.</p>
</blockquote>

<p>The point of an operator $A$ is to transform a point in $X$ to a new space for
some purpose. It is not clear to see why it helps in the general form, but
think Fourier Transform, which is to transform a point in the signal space to
the frequency space. Boom, science advanced. In retrospect, do we need to keep
a picture in the natural basis of signal space when considering the frequency
space? No. In some research paper I read, for instance, scattering transform,
the whole is to make sure the new space has good properties.</p>

<p>So for operators, the most important is to enforce regularities to make sure
there is good properties in the new space, which is algebraic in nature instead
of geometrical.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On Teaching and Learning]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/09/21/on-teaching-and-learning/"/>
    <updated>2015-09-21T20:37:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/09/21/on-teaching-and-learning</id>
    <content type="html"><![CDATA[<p>Some notes on teaching and learning.</p>

<!-- more -->

<p>The way we teach reflects the way we learn and the way we communicate. Teaching
gives me another perspective on how may I could be taught or just, learn from
others. Such experience has led me a long way to realize my deficiency.</p>

<p>I attended a workshop on teaching today and want to note down something
learned. It is the first time I got systematical training on how to teaching,
which is equivalent to how to learn.</p>

<p>The following stuffs come from the handout in the workshop.</p>

<h3 id="seven-research-based-principles-for-smart-teaching">Seven Research-based Principles for Smart Teaching</h3>

<p>There are seven principles in teaching, which also means in learning.</p>

<ol>
  <li>prior knowledge</li>
  <li>structuring knowledge</li>
  <li>motivation</li>
  <li>self-awareness on the one’s situation</li>
  <li>synthesis of different parts of acquired knowledge </li>
  <li>feedback</li>
  <li>emotional feeling, social and intellectual climate</li>
</ol>

<p>This is a systematical summary of elements that involves in the learning
process. Prior knowledge is what you already have; structuring knowledge is how
you condense your knowledge and build inner connection between different
separate parts; motivation is power house behind all your efforts;
self-awareness is about a clear awareness of one’s current situation — what
one have known, what one do not know, what one know one do not know; synthesis
is where something new could happen; feedback is how people get to know their
mistakes, so they could fix them, and learn new things; emotional stability and
social support is very important for long term learning.</p>

<p>After some thinking, it seems that nothing is really new for me, but the
summary is helpful.</p>

<h3 id="on-motivation">On Motivation</h3>

<p>Another important part on teaching and learning discussed is what motivate
people to do better on tasks that need cognitive thinking.</p>

<p>I long have known only money is not enough. Today I got a very good summary:</p>

<blockquote>
  <p>Pay people enough to take the issue of money off the table.</p>
</blockquote>

<p>The factors that motivate to do great work is autonomy, mastery and
purpose. There should many materials online talking on this given this is a
research output from scientists.</p>

<h3 id="three-skills-on-communication">Three Skills On Communication</h3>

<ol>
  <li>Storytelling</li>
  <li>Contextualizing</li>
  <li>Sketching</li>
</ol>

<p>All those are kind of one thing. People learn from examples, so we need
storytelling; people learn from examples that they know the most, so we need
contextualize the examples with their experience; people learn bit by bit,
dynamically, so we need to present it bit by bit, like sketching a picture.</p>

<p>It is easier said that done. Practice is important.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On Linux Laptop Battery]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/09/07/on-linux-laptop-battery/"/>
    <updated>2015-09-07T14:15:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/09/07/on-linux-laptop-battery</id>
    <content type="html"><![CDATA[<p>I would like to note down the how to prolong battery life, in term of both
hours and years.</p>

<p>Roughly, there are three tricks to extend battery time, <code>laptop-mode</code>,
<code>powertop</code> and changing screen lightness, and one trick to extend life,
stopping battery charging according to thresholds. The last trick is only
applicable to Thinkpad.</p>

<!-- more -->

<h2 id="extending-battery-time">Extending Battery Time</h2>

<p>I have three tricks for extending the battery time, <code>laptop_mode</code>, <code>powertop</code>
and setting the lightness of the screen. The exact number is forgotten, but
roughly if the original time of the laptop is around 4 hours, enabling
<code>laptop_mode</code> will get me one extra, <code>powertop</code> two extra and lightness one
extra.</p>

<p>Normally, people are told to use one battery management programs considering
that different programs may conflict, but I found <code>laptop_mode</code> works well with
<code>powertop</code>, a long time ago. So I settled with it.</p>

<h3 id="laptopmode">laptop_mode</h3>

<p><a href="http://www.samwel.tk/laptop_mode/">laptop_mode</a> is about:</p>

<blockquote>
  <p>Laptop mode is a kernel “mode” that allows you to extend the battery life of
your laptop. It does this by making disk write activity “bursty”, so that only
reads of uncached data result in a disk spinup. It causes a significant
improvement in battery life (for usage patterns that allow it).</p>
</blockquote>

<p>There are configuration files for it, but I did not try to use them.</p>

<h3 id="powertop">powertop</h3>

<p><a href="https://01.org/powertop">powertop</a> is from Intel. It could tune a number of
options to save power usage. For details, refer to
<a href="https://wiki.archlinux.org/index.php/Powertop">here</a>. I will only note down
normal usage scenario.</p>

<p>After first installation, we need to run:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">sudo powertop --calibrate
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>It will take several minutes to finish, and the screen could be dark for tens
of seconds. So do not panic when this happens. Also, do not touch your laptop
when powertop is calibrating. After this, you could get power consumption in
Watt and estimated remaining time in <code>powertop</code>. If you skip this, <code>powertop</code>
will still work, but not those two information.</p>

<p>Start <code>powertop</code>, in the <code>tunable</code> tab, you could see a number of tunable
options to improve your battery time. Make all the “Bad” to “Good” will save a
lot of power consumption. However, the change is lost after you reboot. To make
it permanent, do the following.</p>

<p>Run,</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">sudo powertop --html
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>You will get a html version report under current directory. Go to the tunable
page, you could see the command to tune, similar with the following:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line"><span class="c"># Those following are the settings from powertop to save power.</span>
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;1500&#39;</span> &gt; <span class="s1">&#39;/proc/sys/vm/dirty_writeback_centisecs&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;0&#39;</span> &gt; <span class="s1">&#39;/proc/sys/kernel/nmi_watchdog&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;min_power&#39;</span> &gt; <span class="s1">&#39;/sys/class/scsi_host/host1/link_power_management_policy&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;min_power&#39;</span> &gt; <span class="s1">&#39;/sys/class/scsi_host/host2/link_power_management_policy&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;min_power&#39;</span> &gt; <span class="s1">&#39;/sys/class/scsi_host/host0/link_power_management_policy&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;auto&#39;</span> &gt; <span class="s1">&#39;/sys/bus/usb/devices/1-6/power/control&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;auto&#39;</span> &gt; <span class="s1">&#39;/sys/bus/pci/devices/0000:00:16.0/power/control&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;auto&#39;</span> &gt; <span class="s1">&#39;/sys/bus/pci/devices/0000:02:00.0/power/control&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;auto&#39;</span> &gt; <span class="s1">&#39;/sys/bus/pci/devices/0000:00:1f.3/power/control&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;auto&#39;</span> &gt; <span class="s1">&#39;/sys/bus/pci/devices/0000:00:1f.2/power/control&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;auto&#39;</span> &gt; <span class="s1">&#39;/sys/bus/pci/devices/0000:00:1f.6/power/control&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;auto&#39;</span> &gt; <span class="s1">&#39;/sys/bus/pci/devices/0000:00:1f.0/power/control&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;auto&#39;</span> &gt; <span class="s1">&#39;/sys/bus/pci/devices/0000:00:1d.0/power/control&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;auto&#39;</span> &gt; <span class="s1">&#39;/sys/bus/pci/devices/0000:00:1c.1/power/control&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;auto&#39;</span> &gt; <span class="s1">&#39;/sys/bus/pci/devices/0000:00:1c.0/power/control&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;auto&#39;</span> &gt; <span class="s1">&#39;/sys/bus/pci/devices/0000:00:14.0/power/control&#39;</span>;
</span><span class="line"><span class="nb">echo</span> <span class="s1">&#39;auto&#39;</span> &gt; <span class="s1">&#39;/sys/bus/pci/devices/0000:00:02.0/power/control&#39;</span>;
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Copy all those lines, or only the ones you want to tune to <code>/etc/rc.local</code>,
then the change will be permanent.</p>

<h3 id="set-default-lightness">Set Default Lightness</h3>

<p>As least for me, no new packages are needed. Just put the following line in
<code>/etc/rc.local</code> is OK. Given the difference in hardwares, the <code>intel_backlight</code>
may be something else.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line"><span class="c"># Set default brightness. The maximum value is 852. The value 350 here is hard tuned.</span>
</span><span class="line"><span class="nb">echo </span>350 &gt; /sys/class/backlight/intel_backlight/brightness
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2 id="extending-battery-life">Extending Battery Life</h2>

<p>I am delighted to find out that Thinkpad has such a good support for
Linux. Lenovo has a good mechanism to extend battery life on Windows. It will
stop charging the battery if the battery level has exceeded some threshold,
which would prolong the battery life given the properties of Lithium battery.</p>

<p>Thinkpad still support it if you are using Linux. The solution depends on the
hardware of your Thinkpad. If you are installing on a recent Thinkpad that has
an Ivy Bridge or newer processor (X230, T430, T530, etc.), like me, you could
use a utility named <a href="http://www.thinkwiki.org/wiki/Tpacpi-bat">tpacpi-bat</a>.</p>

<p>If you are using an old Thinkpad, go
<a href="http://www.thinkwiki.org/wiki/Tp_smapi">there</a> for a solution.</p>

<h3 id="install-acpi-call">Install <code>acpi-call</code></h3>

<p>I use Ubuntu 14.04, so the procedure to install <code>tpacpi-bat</code> on Ubuntu will be
described.</p>

<p><code>tpacpi-bat</code> has a <a href="https://launchpad.net/~morgwai/+archive/ubuntu/tpbat">ppa</a>
for Debian based system. Just add the ppa to your source:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">sudo sudo add-apt-repository PPA_NAME
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><code>tpacpi-bat</code> depends on <code>acpi-call</code>, which is part of <code>acpi-call-dkms</code>. So we
need to install <code>acpi-call-dkms</code> first. It is also part of the ppa.</p>

<p>The main reason that I write this note is that the package has a bug. This bug
is widely
<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=762281">discovered</a> almost
one year ago, it is strange why it is not fixed yet. After setting up the ppa,
first try installing <code>acpi-call-dkms</code>.</p>

<p>The installation will fail with message similar with the following:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">make <span class="nv">KERNELRELEASE</span><span class="o">=</span>3.19.0-26-generic <span class="nv">KVERSION</span><span class="o">=</span>3.19.0-26-generic <span class="nv">KDIR</span><span class="o">=</span>/lib/modules/3.19.0-26-generic/build....<span class="o">(</span>bad <span class="nb">exit </span>status: 2<span class="o">)</span>
</span><span class="line">Error! Bad <span class="k">return </span>status <span class="k">for </span>module build on kernel: 3.19.0-26-generic <span class="o">(</span>x86_64<span class="o">)</span>
</span><span class="line">Consult /var/lib/dkms/acpi_call/1.1.0/build/make.log <span class="k">for </span>more information.
</span><span class="line">dpkg: error processing package acpi-call-dkms <span class="o">(</span>--configure<span class="o">)</span>:
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Have a check at the <code>make.log</code>, the compilation error is:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">Please don<span class="err">&#39;</span>t include &lt;acpi/acpi.h&gt; directly, include &lt;linux/acpi.h&gt; instead
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>So I go to <code>/var/lib/dkms/acpi_call/1.1.0/source/acpi_call.c</code>, where the
installer unpacks the source. I changed <code>&lt;acpi/acpi.h&gt;</code> to <code>&lt;linux/acpi.h&gt;</code>,
then try the installation(wit the same command) again. Wow, the compilation
passed and the installation is successful.</p>

<h3 id="install-tpacpi-bat">Install <code>tpacpi-bat</code></h3>

<p>This step is easy, just normal apt installation.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">sudo apt-get install tpacpi-bat
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="configuration">Configuration</h3>

<p>After installation, now we need to configure the charge threshold of our
battery. The help message of <code>tpacpi-bat</code> does not seem to be very clear for
me. So I will note down how to get and set charging battery thresholds.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line"><span class="c"># tpacpi-bat get start-threshold primary-battery</span>
</span><span class="line">tpacpi-bat   -g   ST             1
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Thinkpad has one primary battery and one secondary battery. 1 stands for
primary battery and 2 stands for secondary battery.</p>

<p>To set the start threshold for starting charging:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line"><span class="c"># tpacpi-bat set start-threshold primary-battery   start-threshold</span>
</span><span class="line">tpacpi-bat   -s  ST              1                 40
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>It means the battery won’t charge if the its battery level is higher than 40.</p>

<p>To make the change permanent, add the following lines in <code>/etc/rc.local</code>.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line"><span class="c"># Primary battery</span>
</span><span class="line">tpacpi-bat -s ST 1 40 <span class="c"># Start threshold</span>
</span><span class="line">tpacpi-bat -s SP 1 80 <span class="c"># Stop threshold</span>
</span><span class="line"><span class="c"># Secondary battery</span>
</span><span class="line">tpacpi-bat -s ST 2 40
</span><span class="line">tpacpi-bat -s SP 2 80
</span></code></pre></td></tr></table></div></figure></notextile></div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Note on texlive from Ubuntu Source]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/09/02/note-on-texlive-from-ubuntu-source/"/>
    <updated>2015-09-02T21:49:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/09/02/note-on-texlive-from-ubuntu-source</id>
    <content type="html"><![CDATA[<p>Some note on the installing LaTeX packages from network.</p>

<!-- more -->

<p>It is very convenient to install packages using <code>tlmgr</code>. However, sometimes
the mirror you are trying to connect would be extremely slow, which makes it
feel like tlmgr has stuck.</p>

<p>If you have not been deal with texlive installation for a long time, like me
today, the first thoughts stuck me is that there is something wrong with
texlive installation given that I was doing a fresh installation on a new
laptop I did not familiar. Only after about a hour’s debugging, the idea that
maybe it is the network issue struck me.</p>

<p>Here I want to note down some points about how tlmgr choose its mirror servers,
so I won’t be figuring out the same problem next time.</p>

<p>By default, <code>tlmgr</code>’s default repository url is a multiplexor, which will
choose a mirror in the closest network proximity to your location. See the
right pane of this <a href="ctan.org/mirrors">page</a>.</p>

<p>To set such behavior of <code>tlmgr</code>, the command is like this:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">tlmgr option repository ctan
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>where <code>ctan</code> is the nickname for tlmgr for the multiplexor mirror.</p>

<p>Today the multiplexor gave me a server that is not working my LAN
network. Luckily that I get a workable mirror from my PC and use that to solve
the network problem.</p>

<p>The url of a mirror is like this:
<code>http://ftp.yzu.edu.tw/CTAN/systems/texlive/tlnet</code>. The example here is the
mirror that works for me this time.</p>

<p><em>NOTE FOR ME</em>:</p>

<p>I have set this mirror as default for my laptop.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On Code Completion & Navigation for C/C++ in Emacs]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/08/11/on-code-completion-for-c-slash-c-plus-plus/"/>
    <updated>2015-08-11T09:21:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/08/11/on-code-completion-for-c-slash-c-plus-plus</id>
    <content type="html"><![CDATA[<p>Due to the same reason that I decided to add <code>company</code> to provide faster and
more accurate completion functionality, I switched from
<a href="http://cedet.sourceforge.net/">CEDET</a> to
<a href="https://github.com/Sarcasm/irony-mode">irony</a> +
<a href="https://github.com/leoliu/ggtags">ggtags</a>.</p>

<p>Here is the note TODO</p>

<!-- more -->

<h2 id="irony">Irony</h2>

<h3 id="installation">Installation</h3>

<p>To setup <code>irony</code>, in the <a href="https://github.com/Sarcasm/irony-mode">README</a> of
<code>irony</code>’s git repo, the installation process provided by the author is pretty
workable. The only thing may need to be noted is that what packages you need to
install if you are not going to compile <code>libclang</code> from source.</p>

<p>In Ubuntu, you need those two packages: <code>libclang-dev</code> and <code>clang</code>. By
mentioning only <code>libclang</code>, it gives me the feeling that I do not need an
executable of <code>clang</code>, however, there is some errors occurs without
<code>clang</code>. But due to the trial and error when making <code>irony-mode</code> to work, I am
not sure it is really caused by lacking of <code>clang</code>.</p>

<h3 id="make-it-work">Make It Work</h3>

<p>You need to let <code>clang</code> know where to find you source file for it to parse
it. To achieve this, <code>irony</code> provides a concept called
<a href="https://github.com/Sarcasm/irony-mode#compilation-database">compilation database</a>. Refer
to it to know how to make <code>irony</code> work. The following is some remarks.</p>

<p>Basically, the most important compilation flags are the include folder path for
header files. Since <code>irony</code> does not aim to provide code navigation function,
all information it needs are in header files.</p>

<p>One problem that bugs me a lot when I was setting up <code>irony</code> is that <code>clang</code> in
<code>irony</code> and <code>gcc</code> handles <code>-I</code> flag differently. The path must immediately
follows the <code>-I</code>, with no spaces. If there are spaces, <code>irony</code> could not find
the corresponding paths.</p>

<h3 id="limitations">Limitations</h3>

<p>During my testing with <code>irony</code>, I found that it could not handle definition
with template, which is used a lot in C++ numerical library. The limitation
also makes sense since that declarations are generated dynamically during
compilation for template definition, so maybe you could not get relevant
information just by parsing the template definition.</p>

<h2 id="ggtags">ggtags</h2>

<p><a href="http://www.gnu.org/software/global/">gtags</a> is better
<a href="http://ctags.sourceforge.net/">ctags</a> in various ways. See the
<a href="https://github.com/leoliu/ggtags">table</a> provided by
<a href="https://github.com/leoliu/ggtags">ggtags</a>’s developers.</p>

<h3 id="setup-system-tags">Setup System Tags</h3>

<p>I copy this section from this
<a href="http://tuhdo.github.io/c-ide.html#sec-7-2">tutorial</a> in case I may forget it.</p>

<p><code>GNU Global</code> has an environment variable named <code>GTAGSLIBPATH</code>. This variable holds
<code>GTAGS</code> database of external libraries that your project depends on but not
inside your project. For example, your project may rely on system headers such
as <code>stdio.h</code>, <code>stdlib.h</code>… but these headers are internal to your project. However,
remember that you can only jump to tag definitions of external dependencies,
and nothing else (such as files or references). But, again, once you are inside
the external library, you can start jumping around sicne it becomes your
current project.</p>

<p>To make <code>GNU Global</code> sees your system headers, follow these steps:</p>

<p>Export this environment variable in your shell init file, such as <code>.bashrc</code> or
<code>.zshrc</code>:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line"><span class="nb">export </span><span class="nv">GTAGSLIBPATH</span><span class="o">=</span><span class="nv">$HOME</span>/.gtags/
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Execute these commands in your terminal:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line"><span class="c"># Create a directory for holding database, since</span>
</span><span class="line"><span class="c"># you cannot create a database in your system paths</span>
</span><span class="line">mkdir ~/.gtags
</span><span class="line">
</span><span class="line"><span class="c"># Create symbolic links to your external libraries</span>
</span><span class="line">ln -s /usr/include usr-include
</span><span class="line">ln -s /usr/local/include/ usr-local-include
</span><span class="line">
</span><span class="line"><span class="c"># Generate GNU Global database</span>
</span><span class="line">gtags -c
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>The <code>-c</code> option tells <code>GNU Global</code> to generate tag database in compact format. It
is necessary because if your project contains C++ headers like <code>Boost</code>, without
<code>-c</code> your <code>GTAGS</code> database can be more than 1 GB. Same goes for <code>ctags</code>. The <code>GNU
Global</code> devs explained that it is because the <code>GTAGS</code> database includes the image
of tagged line, and the <code>Boost</code> headers have a lot of very long lines.</p>

<p>After all the above steps, restart with a shell loaded with that variable. To
verify Emacs gets the variable, <code>M-x getenv</code> and enter <code>GTAGSLIBPATH</code> and see
if your predefined value is available. Executing <code>ggtags-find-tag-dwim</code> or
<code>helm-gtags-dwim</code> jumps to the definition of a system tag like a normal tag.</p>

<p>The disadvantage of using <code>GNU Global</code> is that currently it cannot include
files without extension. In the C++ system include directory like
<code>/usr/include/c++/4.8/</code>, it contains files without extension such as
<code>iostream</code>, <code>string</code>, <code>set</code>, <code>map</code>…. so you can write <code>#include</code> directives
without having to append <code>.h</code> at the end. <code>GNU Global</code> devs are considering to
add support for this use case.</p>

<h2 id="some-remarks">Some Remarks</h2>

<ul>
  <li><code>semantic-mode</code> is still used to provide method overview for ECB. It is
configured to only parse current buffer, which is rather acceptable in speed.</li>
  <li>If you want to know more about CEDET, here is
<a href="http://alexott.net/en/writings/emacs-devenv/EmacsCedet.html">a nice introductory post</a>
explaining it.</li>
  <li>Though <code>CEDET</code> gets disabled, company still takes advantage of some part of
tools provided by <code>CEDET</code>. One of them is
<a href="http://cedet.sourceforge.net/ede.shtml">EDE</a>, the project
manager. See the github README page of
<a href="https://github.com/randomphrase/company-c-headers">company-c-headers</a> to see
how could you use <code>EDE</code> to tell <code>company</code> to use system include path.</li>
  <li><a href="https://github.com/emacs-helm/helm">helm</a> is an alternative to
<a href="https://www.masteringemacs.org/article/introduction-to-ido-mode">ido</a>. Maybe
it could be tried while I have more time.</li>
  <li><a href="https://github.com/abingham/emacs-ycmd">emacs-ycmd</a> is another completion
framework for Emacs.</li>
  <li><code>irony</code> offers a flychecker, since I already uses the google style and
cpplint, I will not try <code>flycheck-irony</code> for the time being, though it may
offer advantages such as full compilation error detection.</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On Auto Completion in Emacs]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/08/11/on-auto-completion-in-emacs/"/>
    <updated>2015-08-11T09:07:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/08/11/on-auto-completion-in-emacs</id>
    <content type="html"><![CDATA[<p>Just finished setting up Emacs using
<a href="http://company-mode.github.io/">company</a> to do auto-completion. Here I would
like to note down the reason why I made the shift from
<a href="https://github.com/auto-complete/auto-complete">auto-complete</a> to <code>company</code>
for programming. However, for tasks like writing configuration file, LaTeX
documents or markdown note, I still use <code>auto-complete</code>.</p>

<!-- more -->

<h2 id="comparison-between-company-and-auto-complete">Comparison Between <code>company</code> and <code>auto-complete</code></h2>

<p>At the first iteration of my Emacs configuration for C/C++, I followed the
following three videos to get a basic setup:</p>

<ul>
  <li><a href="https://www.youtube.com/watch?v=HTUE03LnaXA">Emacs as a C/C++ Editor/IDE (Part I): auto-complete, yasnippet, and autoplete</a></li>
  <li><a href="https://www.youtube.com/watch?v=r_HW0EB67eY">Emacs as a C/C++ Editor/IDE (Part 2): iedit, flymake-google-cpplint, google-c-style</a></li>
  <li><a href="https://www.youtube.com/watch?v=Ib914gNr0ys">Emacs as a C/C++ Editor/IDE (Part 3): Installing CEDET mode for true intellisense</a></li>
</ul>

<p>which introduces the <code>auto-complete</code> for doing automatically completion.</p>

<p>At the same time, the extension
 <a href="https://github.com/tkf/emacs-jedi">emacs-jedi</a> only supports <code>auto-complete</code>
backend. And <code>emacs-jedi</code> is the only python code completion extension for
Emacs at then, which turns out that there were a number of others I did not
notice(see previously post on Python in Emacs). So I decided to use
auto-complete.</p>

<p>Then as the projects I worked on got bigger, the possible candidates provided
by <code>auto-complete</code> becomes too large to be useful due to the reason that
<code>auto-complete</code> will fetch all candidates from all sources.</p>

<p>The same problem happens to <code>auto-complete</code> in file path completion as
well. You get a lot of non-sense completion when you only want to get
completion in the path you want, which is a rather narrow space in the whole
space of all your possible completion candidates.</p>

<p>There could be a way to dynamically change the order of sources, but <code>company</code>
seems to do this automatically or people writes the backends for <code>company</code> do
this. In whatever case, the user does not need to attend to those things.</p>

<p>That is not the fatal problem yet, <code>auto-complete</code> has a annoying problem which
I do not know how to fix is that the time needed for the completion list to
respond to new input is at the magnitude of seconds. I am pretty sure this is
not a performance problem given that the completion list comes up pretty fast.</p>

<p><code>company</code> also solves the file completion problem and c headers completion
problem by providing a separate function in their respective backends, which I
just need to map another key binding to it so the completion will be very
accurate when you are programming.</p>

<p><code>auto-complete</code> does good when you are writing text heavy contents such as
LaTeX or markdown but not logically heavy ones such as programming language.</p>

<p>For a more complete comparison you could refer to the end of the 
<a href="http://company-mode.github.io/">github page</a> of <code>company</code>.</p>

<h2 id="on-using-them-together">On Using Them Together</h2>

<p>One more realization is that those two extensions are not exclusive at all. I
did not find a backend like the sources provided by <code>auto-complete</code> for
complete word in buffers related functions, which is the area <code>auto-complete</code> 
works well.</p>

<p>Below is some sample on how to use them from my
<a href="https://github.com/shawnLeeZX/emacs.d">Emacs configuration</a>.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
</pre></td><td class="code"><pre><code class="cl"><span class="line"><span class="p">(</span><span class="nv">add-hook</span> <span class="ss">&#39;after-init-hook</span> <span class="ss">&#39;global-company-mode</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="c1">;;   &quot;Modes for which `company-mode&#39; mode is turned on by</span>
</span><span class="line"><span class="c1">;; `global-company-mode&#39;.  If nil, means no modes.  If t, then all major modes</span>
</span><span class="line"><span class="c1">;; have it turned on.  If a list, it should be a list of `major-mode&#39; symbol</span>
</span><span class="line"><span class="c1">;; names for which `company-mode&#39; should be automatically turned on.  The sense</span>
</span><span class="line"><span class="c1">;; of the list is negated if it begins with `not&#39;.  For example: (c-mode</span>
</span><span class="line"><span class="c1">;; c++-mode) means that `company-mode&#39; is turned on for buffers in C and C++</span>
</span><span class="line"><span class="c1">;; modes only.  (not message-mode) means that `company-mode&#39; is always turned</span>
</span><span class="line"><span class="c1">;; on except in `message-mode&#39; buffers.&quot;</span>
</span><span class="line"><span class="p">(</span><span class="k">setq</span> <span class="nv">company-global-modes</span> <span class="o">&#39;</span><span class="p">(</span>
</span><span class="line">                            <span class="nv">c-mode</span>
</span><span class="line">                            <span class="nv">c++-mode</span>
</span><span class="line">                            <span class="p">))</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
</pre></td><td class="code"><pre><code class="cl"><span class="line"><span class="c1">;; Enable auto-complete for modes in ac-modes by default.</span>
</span><span class="line"><span class="p">(</span><span class="nv">global-auto-complete-mode</span> <span class="no">t</span><span class="p">)</span>
</span><span class="line"><span class="c1">;; We reset the default mode for auto-complete given that we want to some modes</span>
</span><span class="line"><span class="c1">;; to use company-mode.</span>
</span><span class="line"><span class="p">(</span><span class="nv">set-default</span> <span class="ss">&#39;ac-modes</span>
</span><span class="line">             <span class="o">&#39;</span><span class="p">(</span>
</span><span class="line">               <span class="nv">magit-log-edit-mode</span>
</span><span class="line">               <span class="nv">log-edit-mode</span> <span class="nv">org-mode</span> <span class="nv">text-mode</span> <span class="nv">haml-mode</span>
</span><span class="line">               <span class="nv">git-commit-mode</span>
</span><span class="line">               <span class="nv">conf-mode</span> <span class="nv">conf-unix-mode</span> <span class="nv">conf-colon-mode</span>
</span><span class="line">               <span class="nv">inferior-emacs-lisp-mode</span> <span class="nv">inferior-python-mode</span>
</span><span class="line">               <span class="nv">sql-interactive-mode</span>
</span><span class="line">               <span class="nv">sass-mode</span> <span class="nv">yaml-mode</span> <span class="nv">csv-mode</span> <span class="nv">espresso-mode</span> <span class="nv">haskell-mode</span>
</span><span class="line">               <span class="nv">html-mode</span> <span class="nv">nxml-mode</span> <span class="nv">smarty-mode</span> <span class="nv">clojure-mode</span>
</span><span class="line">               <span class="nv">lisp-mode</span> <span class="nv">textile-mode</span> <span class="nv">markdown-mode</span> <span class="nv">tuareg-mode</span>
</span><span class="line">               <span class="nv">js3-mode</span> <span class="nv">css-mode</span> <span class="nv">less-css-mode</span> <span class="nv">sql-mode</span>
</span><span class="line">               <span class="nv">web-mode</span>
</span><span class="line">               <span class="p">))</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2 id="difference-between-tab-and-tab">Difference Between <tab> and TAB</tab></h2>

<p>The last thing I want to note down is that TAB key.</p>

<p>Emacs has two tabs, <code>(kbd "&lt;tab&gt;")</code> and <code>(kbd "TAB")</code>. To make things more
complex, <code>yasnippet</code>, <code>auto-complete</code>, indentation in Emacs, typing real tab
stops and <code>company</code> all uses <code>tab</code>, which makes it very complicated.</p>

<p>From this
<a href="https://www.reddit.com/r/emacs/comments/2aemny/difference_between_tab_and_tab/">thread</a>
in Reddit, here, I knew that <code>(kbd "&lt;tab&gt;")</code> stands for the physical key you
have pressed and <code>(kbd "TAB")</code> stands for the control character. So to speak,
normally, if you are not binding <code>&lt;tab&gt;</code> to <code>TAB</code>, the tab you typed is not
actually the control character TAB, but triggers some function that is hooked
on the physical key’s response.</p>

<p>As for the second part of the puzzle, when you are typing tab at a location
where the indentation of the statement is not right, Emacs will indent your
line first. The key to differentiate <code>yasnippet</code> and <code>auto-complete</code> is whether
you are typing or not when you pressed the tab key. If you are, completion menu
will be triggered, if you are not <code>yasnippet</code> will be triggered(this is a
mechanism that could be configured in auto-complete and is not the default, by
default, I think the completion menu will pop up automatically). As for
<code>company</code> and <code>yasnippet</code>, in my experiments, after setting the trigger key to
tab, by default it seems that snippets are always gotten expanded the first,
then <code>company-complete</code> will be triggered if no snippets could be found. See
the following code snippets for how to set up key binding for <code>company</code>(it only
uses <code>company</code> if <code>irony-mode</code> is in usage).</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="cl"><span class="line"><span class="c1">;; Setup keymapping for company-complete.</span>
</span><span class="line"><span class="p">(</span><span class="nv">add-hook</span> <span class="ss">&#39;irony-mode-hook</span> <span class="p">(</span><span class="k">lambda</span> <span class="p">()</span>
</span><span class="line">                             <span class="p">(</span><span class="nv">local-set-key</span> <span class="p">(</span><span class="nv">kbd</span> <span class="s">&quot;&lt;tab&gt;&quot;</span><span class="p">)</span> <span class="ss">&#39;company-complete-common</span><span class="p">)</span>
</span><span class="line">                             <span class="p">(</span><span class="nv">local-set-key</span> <span class="p">(</span><span class="nv">kbd</span> <span class="s">&quot;C-c C-f&quot;</span><span class="p">)</span> <span class="ss">&#39;company-files</span><span class="p">)</span>
</span><span class="line">                             <span class="p">))</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2 id="reference">Reference</h2>

<ul>
  <li><a href="https://www.youtube.com/watch?v=HTUE03LnaXA">Emacs as a C/C++ Editor/IDE (Part I): auto-complete, yasnippet, and autoplete</a></li>
  <li><a href="https://www.youtube.com/watch?v=r_HW0EB67eY">Emacs as a C/C++ Editor/IDE (Part 2): iedit, flymake-google-cpplint, google-c-style</a></li>
  <li><a href="https://www.youtube.com/watch?v=Ib914gNr0ys">Emacs as a C/C++ Editor/IDE (Part 3): Installing CEDET mode for true intellisense</a></li>
  <li><a href="http://tuhdo.github.io/c-ide.html">tutorial on customizing C/C++ environment for emacs</a></li>
  <li><a href="https://www.masteringemacs.org/article/mastering-key-bindings-emacs">Mastering Key Bindings in Emacs</a></li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On IDEs of Python in Emacs]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/08/05/on-ides-of-python-in-emacs/"/>
    <updated>2015-08-05T10:30:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/08/05/on-ides-of-python-in-emacs</id>
    <content type="html"><![CDATA[<p>I was finally annoyed enough to find a replacement of <code>auto-complete</code> in
Emacs. Reasons will be noted down later. In this note, three common extensions
for writing Python under Emacs will be compared and noted, which are:</p>

<ol>
  <li><a href="https://github.com/tkf/emacs-jedi">jedi</a></li>
  <li><a href="https://github.com/jorgenschaefer/elpy">elpy</a></li>
  <li><a href="https://github.com/proofit404/anaconda-mode">anaconda</a></li>
</ol>

<!-- more -->

<p>I always used emacs-jedi since I made the shift from Vim to Emacs.</p>

<p>The functionality provided by emacs-jedi is actually quite good. The only function
that lacks is the one to refactor. So it is not the fault of emacs-jedi that makes me
want to change extensions. However, the detail will be left to the comparison
between <code>company-mode</code> and <code>auto-complete</code>.</p>

<p>Though emacs-jedi is not bad, it is also not that good compared with elpy, in my
opinion.</p>

<p>You could get good code completion, etc, basically everything roughly equal in
those three extensions. There are some details about elpy that makes me prefer
to elpy.</p>

<p>At the time that I set up emacs-jedi, basically I copied some the author’s hacking
code to let emacs-jedi recognize my current python files, or project
automatically. It works, but it does not feel elegant.</p>

<p>I could get by with that if it is not due to the reason of <code>auto-complete</code>.</p>

<p>With elpy, you could use command <code>elpy-set-project-root</code> to tell elpy that you
need current project to be taken into account, which does not feel
automatically but it is more user friendly and elegant.</p>

<p>What’s more, elpy takes into account the <code>PYTHON_PATH</code> environment variable
into account automatically. I guess emacs-jedi does this as well.</p>

<p>As for anaconda, actually I found it prior to elpy and also gave it a
try. However, it failed when I tried to get code completion on-the-fly in my
current project and no documentation seems to hint me how to deal with that.</p>

<p>Lastly, the refactoring function provided by elpy seems exciting so that I
won’t need to use <code>search-and-replace</code> or <code>multi-occur</code> stuff. But I did not
try it yet. Look forward to.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Some Notes on IPython Startup Script]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/08/03/some-notes-on-ipython-startup-script/"/>
    <updated>2015-08-03T16:22:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/08/03/some-notes-on-ipython-startup-script</id>
    <content type="html"><![CDATA[<p>This post is going to note down how to let ipython automatically reload a
module after changing the module and how to run magic function from python
start-up scripts.</p>

<!-- more -->

<p>ipython will not reload any modules if you have changed some module under given
that ipython want to keep the interactive session so all your data during the
session is going to be kept. To overcome this situation while you are writing
some module or library code, the <code>autoload</code> magic function could be used.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="o">%</span><span class="n">load_ext</span> <span class="n">autoreload</span>
</span><span class="line">
</span><span class="line"><span class="o">%</span><span class="n">autoreload</span> <span class="mi">2</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">%autoreload
</span><span class="line">Reload all modules <span class="o">(</span>except those excluded by %aimport<span class="o">)</span> automatically now.
</span><span class="line">
</span><span class="line">%autoreload 0
</span><span class="line">Disable automatic reloading.
</span><span class="line">
</span><span class="line">%autoreload 1
</span><span class="line">Reload all modules imported with %aimport every <span class="nb">time </span>before executing the Python code typed.
</span><span class="line">
</span><span class="line">%autoreload 2
</span><span class="line">Reload all modules <span class="o">(</span>except those excluded by %aimport<span class="o">)</span> every <span class="nb">time </span>before executing the Python code typed.
</span><span class="line">
</span><span class="line">%aimport
</span><span class="line">List modules which are to be automatically imported or not to be imported.
</span><span class="line">
</span><span class="line">%aimport foo
</span><span class="line">Import module ‘foo’ and mark it to be autoreloaded <span class="k">for</span> %autoreload 1
</span><span class="line">
</span><span class="line">%aimport -foo
</span><span class="line">Mark module ‘foo’ to not be autoreloaded.
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>For more details, refer to ipython’s
<a href="http://ipython.org/ipython-doc/dev/config/extensions/autoreload.html">documentation</a>.</p>

<p>To avoid typing those magic function again and again, they could be put in the
ipython startup script(Name it with <code>.py</code> suffix under
<code>.ipython/profile_default/startup</code>. All python scripts under that folder will
be loaded according to lexical order), which looks like the following:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">from</span> <span class="nn">IPython</span> <span class="kn">import</span> <span class="n">get_ipython</span>
</span><span class="line"><span class="n">ipython</span> <span class="o">=</span> <span class="n">get_ipython</span><span class="p">()</span>
</span><span class="line">
</span><span class="line"><span class="n">ipython</span><span class="o">.</span><span class="n">magic</span><span class="p">(</span><span class="s">&quot;pylab&quot;</span><span class="p">)</span>
</span><span class="line"><span class="n">ipython</span><span class="o">.</span><span class="n">magic</span><span class="p">(</span><span class="s">&quot;load_ext autoreload&quot;</span><span class="p">)</span>
</span><span class="line"><span class="n">ipython</span><span class="o">.</span><span class="n">magic</span><span class="p">(</span><span class="s">&quot;autoreload 2&quot;</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On Frameworks of Deep Learning]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/08/01/on-frameworks-of-deep-learning/"/>
    <updated>2015-08-01T14:30:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/08/01/on-frameworks-of-deep-learning</id>
    <content type="html"><![CDATA[<p>I have spent the last two days trying to figure out what do use as a solid base
for further experiments on deep learning. I decided to settle down to Keras for
the time being. But given that it may not be the optimal choice, I want to note
down what I have tried so that it would be easier to pick up in the future.</p>

<!-- more -->

<p>At first, our lab members are using Caffe, which I have spent some effort
learning it. However, as I got to know more in this field, combining with my
background in Computer Science, Caffe is not really the best platform to do
experiments, at least not for the people who want to understand and experiment
on all the details of various neural network elements and added another layer
of unnecessary engineering burden to the experiments.</p>

<p>Starting from the motivation to actually code NN from scratch, a language as
low level as C++ is not the right choice. Maybe at the time that I am really
equipped and really need large scale experiments, I will get back to Caffe.</p>

<p>Then I came to try Torch. At first I held high expectation given that:</p>

<ol>
  <li>The easy binding between Lua and C.</li>
  <li>The API of torch is rather clean and most of the non-computational intensive
are actually written in Lua, which would save a ton of time.</li>
  <li>The <code>image</code> package of Torch is great given the experience to do
visualization under Python.</li>
  <li>Lua is not a barrier to me, given that I learn a new language rather fast.</li>
</ol>

<p>Then I spent some time to learn the code organization of Torch. Basically,
Torch is a combination of <a href="http://luajit.org/">LuaJIT</a> with Lua packages and C
Libraries. It uses CMake to compile the project. So far so good.</p>

<p>But the real problem comes when I tried to find out a reasonable environment to
write Lua code. SURPRISINGLY, both Emacs and Vim does not have a work
environment for Lua. Emacs does not even have a usage syntax highlighting
for Lua. As for Vim, it does have a usage syntax highlighting, but it stops at
that. All other packages:</p>

<ul>
  <li><a href="http://www.vim.org/scripts/script.php?script_id=3169">luainspect.vim</a>:
Semantic highlighting for Lua in Vim</li>
  <li><a href="http://www.vim.org/scripts/script.php?script_id=4950">Lua Support 2</a> : Lua
IDE. Insert codesnippets, run, compile, and check the code and look up help.</li>
  <li><a href="http://www.vim.org/scripts/script.php?script_id=3625">lua.vim</a> : Lua file
type plug-in for the Vim text editor</li>
  <li><a href="http://www.vim.org/scripts/script.php?script_id=3331">lua_omni</a> : omni
completion for Lua plus few extras</li>
</ul>

<p>are buggy in some extent and I really do not have time to fix them.</p>

<p>Then I tried to find some IDE recommended by the Torch documentation. There are
Eclipse with LDT, zbs-torch and some others, which all sucks. Maybe I have been
using Emacs and Vim for too long…</p>

<p>After about one day’s struggling with all different IDEs, I decided to try new
frameworks based on Theano, even they are all in their infancy.</p>

<p><a href="https://blocks.readthedocs.org/en/latest/">Pylearn2</a> and
<a href="https://blocks.readthedocs.org/en/latest/">Blocks &amp; Fuel</a> feels a bit
convoluted in design. Opendeep, Lasagne, Keras look alike. Given Keras offers
to enforce constraints on parameters, I decided to try Keras first.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Small Emacs auto-complete-mode Trick]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/08/01/small-emacs-auto-complete-mode-trick/"/>
    <updated>2015-08-01T14:15:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/08/01/small-emacs-auto-complete-mode-trick</id>
    <content type="html"><![CDATA[<p>Just knew another small trick. Note it down in case I forgot it.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="cl"><span class="line"><span class="p">(</span><span class="nv">eval-after-load</span> <span class="s">&quot;auto-complete&quot;</span> <span class="o">&#39;</span><span class="p">(</span><span class="nv">add-to-list</span> <span class="ss">&#39;ac-modes</span> <span class="ss">&#39;lua-mode</span><span class="p">))</span><span class="o">.</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[暂时的人生终极意义]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/07/29/zan-shi-de-ren-sheng-zhong-ji-yi-yi/"/>
    <updated>2015-07-29T12:16:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/07/29/zan-shi-de-ren-sheng-zhong-ji-yi-yi</id>
    <content type="html"><![CDATA[<!-- more -->

<p>近日闲暇时间重新看了看大约十年前的电视剧《仙剑奇侠传》，勾起了许许多多的回忆。在
缅怀的同时，也不由得思考起了许多问题。</p>

<p>从非正统的道家书籍——玄幻小说处得知过一句话：修炼有三个境界；一为看山是山，看水是
水；二为看山不是山，看水不是水；三为看山还是山，看水还是水。</p>

<p>自五年前大学入学开始，可以说是世界在我眼前开始展现其真实的面貌，我开始一点一点地
搭建自己的世界观、价值观、人生观。与此同时，当今社会各种各样丑陋的事情也我眼前一
一略过。人间失格，偌大的中国于我看来不过是一个崩坏的社会。从小看见的一个表象上合
理的世界逐渐崩坏，是以看山不是山，看水不是水。</p>

<p>自有彼领悟之后，我过得有些“世人皆醉吾独醒”的味道。</p>

<p>现代历史学对历史学家的定义是研究人类文明进程的学者，而不是将人类的历史视为一个循
环往复的无尽轮回。而历史进程的发展的源动力于我看来和马克思的观点相仿——底层基础决
定上层建筑。世界人口的增长导致的植物和猎物的不足促使人类由食物的采集者和狩猎者演
变成为农耕民族；对自然规律的发现引发的世界工业化和现代化降低了知识传播的成本，继
而开启民智，使得社会由集权统治、精英统治转变向民主社会。每一个社会的变化期总是会
导致人们思想的剧烈动荡，继而引起文化的变革。在这些社会变革的时期，普通人是最为迷
惘和痛苦的；而对于境界超越普通人的可能影响最后文化形成的社会精英来说，由于同类数
量的稀少，他们也是极为孤独的。这是民族或者种族进化时期个体所不可避免的阵痛。</p>

<p>但这个变革时期的哲学家们需要思考这个时代人们的生命的终极意义。我们究竟因何而来，
又将往何处而去？</p>

<p>在过往千年的人类文明中，哲学家们给出的答案大约可以归为两种：一个大众容易理解的答
案和一个大众不能理解的答案。前者告诉我们世界是有一个万能的神创造的，我们生命的所
有答案都可以由他那里得到解答。这种答案由于其亲和性往往在社会中处于统治地位；而后
者中的思考者希望寻求自己的答案，然而由于人类经验、观察、推理和知识积累的局限，导
致最终这类哲学家的答案往往是：生活是一个谜团，永远不要尝试去弄明白他。</p>

<p>对于第一种答案来说，西方社会中世纪千年的经验告诉我们这类“便宜”的信仰往往使人和社
会停滞不前，但是对于一个真正的答案的寻找需要同样昂贵的代价。自文艺复兴之后，西方
人便开始重新寻找终极问题的答案。十八世纪，黑格尔将人类文明的进化视为一个“世界精
神”的进化历程。但“世界精神”的进化需要的是一代代极度聪慧的人毕生对于自然、社会和
自身的思考：达尔文的《物种起源》；马克思的《资本论》；弗洛伊德的《精神分析》；赫
伯的《行为组织》（Organization of Behavior)；第谷穷其一生的观星；开普勒的三定律；
牛顿的万有引力定律；爱因斯坦的相对论。我想这个列表还可以排很长。</p>

<p>一代代人类最具天赋的人在去尝试去解决一个花费时长注定超越其生命历程的巨大问题的极
小部分。这种对于“我们因何而来？又讲往何处而去”的探寻若从参与其中的人最终能够走出
的步伐来看，不能不说是悲壮的史诗。但从另一个角度来想，这也是人类历史的上少有的机
遇，不足二百年以前绝大部分的智人都处在常年饥饿的状态中，穷其一生但求温饱，极少有
人能够有机会能够去思考这些最根本的问题。</p>

<p>这种思考是人类意识给予人最独特的天赋。在人们觉得有意义的事情大致可以分为三类：一
为独善其身；二为兼济天下；三即为那些仰望群星璀璨的夜空的时候，思考我们最初从哪里
来，又最终往何处去。第一类我们可以归其为生物自身的生存所带来的意义，第二类我们可
以归其为种族自身生存所带来的意义。这两类意义任何动物均具有，唯有第三类意义——对生
命与世界最终极的思考是唯有人类才能够尝试去探寻的。</p>

<p>回到之前所谓看山不是山，看水不是水的崩坏的现代中国。如今社会残酷的资本竞争和生存
压力使得人类从之前三类之中的天然有意义的生活转变到一种人造的虚幻的生活之中，纸醉
金迷、灯红酒绿，看似狂欢盛世，实际却是人人皆处于无边寂寞的精神孤岛之中。几乎所有
社会承认的名望、地位、财富都是虚幻，此所谓看山不是山，看水不是水。</p>

<p>但如克尔凯郭尔认为黑格尔的人类文明是“世界精神”的进化的理论里没有人类个体的角色，
继而缺乏对个人生说的指导一样，这样宏大的第三类意义也不能指导我们去过好我们的一生。
即使着世界再过于崩坏，我们还是不得不生存在其中。侠气地讲，有人的地方就有江湖。</p>

<p>所以当我问自己我能在第三条类路上走到何处时，我总是想起孔子的六个字“尽人事，知天
命”。</p>

<p>一年以前，在粗浅了解中国传统社会统一的价值文化——士文化和美国现代社会自由、民主、
平等、博爱、创新的价值文化之后，中国传统文化中的僵化礼制和祖先崇拜在我对中国传统
文化的认知中被视为非常邪恶，在这样于过去中不可自拔的文化注定在新世界里是没有位置
的。而对这种氏族组织的社会的彻底转变需要的是几代人上百年的逐渐演变，如中世纪西欧
社会所经历的千年中世纪。</p>

<p>但最近我逐渐发觉自由、创新这类现代公民的素质和对人生终极意义的寻找并不是同一个类
别的事物。西方社会纵然是一个“现代”社会，但其并没有对人生的应该如何度过有自己统一
的答案。如电影《少年时代》里描述的普通美国人的一生，我想他们社会的大众其实和我们
一样迷惘，一样不知所措。世界变化太快，人类对于自己和社会的认识永远处于一种滞后的
状态。但对于其中的最杰出者，其对于生命的领悟和中国古代圣人的领悟多少殊途同归——华
盛顿、查理芒格、乔布斯：华盛顿历任两任总统之后归隐田园类似道家道士修为初成下山历
练，功成之后回到山宗，归隐山野；《穷查理宝典》的作者给查理一生的总结即是：正心、
修身、齐家、致富、助天下，正是一个儒家士人最终极的理想；而乔布斯对于内心的追随正
应合了阳明心学与知行合一。而对于现代快节奏生活最有用的抗压技能反而是佛家的冥想。</p>

<p>然后我就想起了一百年前当时青年所讨论的西方社会什么该学，中华文化什么该留，古人的
思想虽然有其社会的局限，但其智慧却是超越时空的疆界的。如此，就到了最后那句话：看
山还是山，看水还是水。西方社会在寻找外在世界的答案的过程中远远超越了东方，但对于
内心世界答案的寻找大家都半斤八两。</p>

<p>理了这么长的思路，最终好像能再尝试总结一个暂时的答案。</p>

<p>道家在这个答案里占总纲地位。人生是一次修行，我们要经历独自的修行来获得我们的真元，
为儒家之正心、修身，亦为习得冥想和心学；小成之后需下山经滚滚红尘世界，历千百聚散
离合，走过儒家的齐家、治国、平天下的士人理想；大成之后归隐山林，小隐隐于野，大隐
隐于十，收徒著书，协助“世界精神”向前迈进一小步。</p>

<p>最终终得坐化，或者飞升。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Add Text to Scanned Pdf Without Text]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/07/14/how-to-add-text-to-scanned-pdf-without-text/"/>
    <updated>2015-07-14T10:43:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/07/14/how-to-add-text-to-scanned-pdf-without-text</id>
    <content type="html"><![CDATA[<p>I am reading some paper that is decades ago so no pdf file with text could
found, so I looked up to some solution. Here it is.</p>

<!-- more -->

<p><a href="https://github.com/gkovacs/pdfocr">Pdfocr</a> is a ruby script that integrates
open source tools to add text layer to pdf files.</p>

<p>To be able to use it, there are some dependence needed, just as shell scripts.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">sudo apt-get install pdftk
</span><span class="line">sudo apt-get install tesseract-ocr tesseract-ocr-eng exactimage
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>You can infer what those programs are used for based what the author
<a href="http://ubuntuforums.org/showthread.php?t=1456756">said</a> below.</p>

<blockquote>
  <p>pdfocr was written by me (Geza Kovacs). It is simply a script which automates
the following process:</p>

  <ol>
    <li>Splitting the PDF file into separate pages using pdftk</li>
    <li>Extracting out the image data using pdfimages</li>
    <li>Doing OCR (optical character recognition) using cuneiform</li>
    <li>Embedding the detected text back into the PDF file using hocr2pdf</li>
    <li>Merging together the files using pdftk.</li>
  </ol>
</blockquote>

<p>Lastly, clone the ruby code.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">git clone https://github.com/gkovacs/pdfocr
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Then enjoy.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
</pre></td><td class="code"><pre><code class="bash"><span class="line">pdfocr.rb -i foo.pdf -o out.pdf
</span></code></pre></td></tr></table></div></figure></notextile></div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Zoom In and Out Gnome Using Mouse]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/07/02/zoom-in-and-out-gnome-using-mouse/"/>
    <updated>2015-07-02T17:18:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/07/02/zoom-in-and-out-gnome-using-mouse</id>
    <content type="html"><![CDATA[<p>Just tried to find a solution to zoom in and out in the GNOME desktop, so that
things could be seen better in case they are too small during presentation.</p>

<!-- more -->

<p>The solution a program called <code>mousewheelzoom</code>, whose source is held at github:
<a href="https://github.com/tobiasquinn/gnome-shell-mousewheel-zoom">gnome-shell-mousewheel-zoom</a>.</p>

<p>The installation instructions could be found there.</p>

<hr />

<p>Besides the solution that works, two solutions that did not work are also going
to noted below.</p>

<h3 id="compiz-setting">Compiz Setting</h3>

<p>At first I tried to changing setting in Compizconfig Settingsmanager, as
suggested in the
<a href="http://askubuntu.com/questions/82398/how-to-zoom-inzoom-out">link</a>. It turns
out that compiz is used by Unity, not GNOME. Since I have changed the desktop
environment, it does not obviously.</p>

<h3 id="gnome-native-solution">GNOME Native solution</h3>

<p>Then GNOME also offers such function directly in their <em>Universal Access</em>,
under <em>Seeing</em> tab, in category Zoom — just type Universal Access in the
Dock. However, it does not work either.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Three Laws of Human Being]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/07/02/three-laws-of-human-being/"/>
    <updated>2015-07-02T14:46:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/07/02/three-laws-of-human-being</id>
    <content type="html"><![CDATA[<p>All those years of studying philosophy, religion, science, history and all the
experience that I will not try to list here, it leads me to think that
consciousness is an emergent phenomenon. I just asked myself, if human beings
are designed, and within current framework of Artificial Intelligence Research,
the source power of consciousness is the optimization of certain functions.</p>

<p>Inspired by the Three Laws of Robots, three optimization functions for human
race came into my mind:</p>

<ol>
  <li>A human must ensure its own gene and spirit ‘s survival on the first
priority.</li>
  <li>A human must ensure its own race’s survival on the first priority given the
rules listed numerically above are obeyed.</li>
  <li>A human must pursue the intellectual understanding of the universe on the
first priority given the rules listed numerically above are obeyed.</li>
</ol>

<p>I think I will revise it when I have some other ideas.</p>

<p>For those who want to consider it seriously, don’t.</p>
]]></content>
  </entry>
  
</feed>
