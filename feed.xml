<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Shawn</title>
    <description>&lt;h1&gt;World Hacker's Notebook&lt;/h1&gt;</description>
    <link>http://shawnLeeZX.github.io/</link>
    <atom:link href="http://shawnLeeZX.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Fri, 28 Oct 2016 17:41:39 +0800</pubDate>
    <lastBuildDate>Fri, 28 Oct 2016 17:41:39 +0800</lastBuildDate>
    <generator>Jekyll v3.2.1</generator>
    
      <item>
        <title>Key points of Understanding Deep Conv Net</title>
        <description>&lt;p&gt;This note tries to summarize the keypoints of the paper by Mallat:
&lt;a href=&quot;http://www.ncbi.nlm.nih.gov/pubmed/26953183&quot;&gt;Understanding deep convolutional networks&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Key concepts: contraction, linearization, fibre, parallel transport,
multi-scale support vector&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;Mechanically, Convolutional Neural Network could be formalized using cascading
the following of operators that compose a function $f$, whose value is in $R$
for regression problems, and is the index of the sample’s class for
classification problems.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;x_j = \rho W_j x_{j-1}&lt;/script&gt;

&lt;p&gt;where $j$ indicates the depth of a network.&lt;/p&gt;

&lt;p&gt;Essentially, neural network is a way to combat the curse of dimensionality. In
the paper, Mallat formalizes this process using linearization of hierarchical
symmetry, space contraction and sparse separation. In short, it is done by
defining a new variable $\Phi(x)$, where $\Phi$ is a &lt;em&gt;contractive&lt;/em&gt; operator
that reduces the range of variations of $x$, while still &lt;em&gt;separating&lt;/em&gt; different
values of $f: \Phi(x) \not= \Phi(x’)$ if $f(x) \not= f(x’)$. $\Phi$ should have
the properties to &lt;strong&gt;linearize hierarchical symmetries, does space contraction and
achieve sparse separation&lt;/strong&gt; to keep classification margin (value margin for
regression). $\Phi$ is called the new representation of $x$.&lt;/p&gt;

&lt;h2 id=&quot;linearization-of-symmetries&quot;&gt;Linearization of symmetries&lt;/h2&gt;

&lt;p&gt;Neural network finds equivalence classes $\Phi(x)$ that linearize
$f$. $\Phi(x)$ is built by collapsing complex symmetry groups.&lt;/p&gt;

&lt;h3 id=&quot;linearization&quot;&gt;Linearization&lt;/h3&gt;

&lt;p&gt;By definition, linearization means to find a representation $\Phi$ that $f$ on
$x \in \Omega$, where the domain $\Omega$ is a high dimensional open set, which
could be $L^2(R^n)$ or $R^d$, could be approximated by a linear combination&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\bar{f} = \sum_i\Phi_i(x)&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;The idea of linearization is to find important yet highly complex basis vector
that linearly contributes to $f$, so $f$ is a linear projection of
&lt;script type=&quot;math/tex&quot;&gt;\Phi_i(x)&lt;/script&gt;. An example would be the word vector, like &lt;code class=&quot;highlighter-rouge&quot;&gt;actor - man + woman =
actress&lt;/code&gt;. Similar phenomenon is observed in images as well.&lt;/p&gt;

&lt;p&gt;On the other hand, it also means $\Phi(x)$ absorbs in the variability that is
not related to $f$. An example could be translation variability, which is
absorbed by subsampling in NN.&lt;/p&gt;

&lt;p&gt;It is difficulty for me to understand what does Mallat mean by&lt;/p&gt;

&lt;p&gt;``We can then optimize a low-dimensional linear projection along directions where
$f$ is constant.’’&lt;/p&gt;

&lt;p&gt;The above is the meaning I have guessed. In summary, if $\Phi$ is fixed, the
optimization works on the linear projection’s weight. ``$f$ is constant’’ means
after the change of variable, the variability in the original space $\Omega$
has been absorbed, so a variability in the direction that does not change
$\Phi$ does not change $f$.&lt;/p&gt;

&lt;h3 id=&quot;space-collapse&quot;&gt;Space collapse&lt;/h3&gt;

&lt;p&gt;The key is to find $\Phi$ that linearizes $f$, which is to find $\Phi$ that
collapses the directions that $f$ remains constant. Mallat formalizes this
``collapse’’ in term of group theory, or more particularly the group of
transformations.&lt;/p&gt;

&lt;p&gt;The word collapse is my own creation, which tries to summarize the key point of
building invariant representation $\Phi$ utilizing groups of
symmetry. It corresponds to the absorbing of variability in previous
section. &lt;script type=&quot;math/tex&quot;&gt;\Phi_i(x)&lt;/script&gt; represents an equivalence class (could be the orbit of
the group, more on this later) of $x$. Collapse is the process of combining
those classes together to form an equivalence class.&lt;/p&gt;

&lt;p&gt;Formally, if $f$ is invariant to an operator $g$ that preserves the value of
$f$, which is to say $f(gx) = f(x)$, we can safely incorporate $g$ in $\Phi(x)$
(putting $gx$ in an equivalence class), so any transformation $g$ on $x$, aka
$gx$, does not change $\Phi(x)$, consequently it does not change $f$. Acting as
an equivalence class, they contribute to the linearization of $f$.&lt;/p&gt;

&lt;p&gt;An example could be the translation group as an example, $f(gx) = f(x - u)$,
where $u \in \Omega$, representing the displacement of the translation. $f$’s
value does not change by translation, so by averaging (subsampling) spatially,
a direction that $f$ remains constant is collapsed out. This direction is part
of a equivalence class formed by collapsing out the translation group.&lt;/p&gt;

&lt;p&gt;By pinpointing those equivalence classes $\Phi(x)$, linearization is achieved
by doing linearly projection on them.&lt;/p&gt;

&lt;h2 id=&quot;more-details&quot;&gt;More details&lt;/h2&gt;

&lt;p&gt;The high level plan stops here. Those above two are the main components making
up the framework of NN. Now we fill in the details, aka sparse separation,
space contraction, separation of scales and complex interaction among
multi-scale.&lt;/p&gt;

&lt;h3 id=&quot;the-functional-form-of-phi&quot;&gt;The functional form of $\Phi$&lt;/h3&gt;

&lt;p&gt;$\Phi$ is handcrafted basis when the time of dictionary learning or deep
learning has not come. It is a vector that captures important (in any criteria
matters for the problem at hand) features.&lt;/p&gt;

&lt;h3 id=&quot;contraction-for-sparsity&quot;&gt;Contraction for sparsity&lt;/h3&gt;

&lt;p&gt;There are some general criteria for basis $\Phi$, one of which may require them
be sparse. A sparse signal brings to better linear separation. Or in other
word, factors of variation are better disentangled.&lt;/p&gt;

&lt;p&gt;For fixed basis vectors, such as wavelets in scattering network they are
defined to separate scale and frequency. Thus for signals that only contains a
few of those, the wavelet coefficients would be rather sparse.&lt;/p&gt;

&lt;p&gt;For an adaptive basis vector, to promote sparsity, Mallat puts forward the
concept of space contraction, which is achieved through the non-linear
activation function, a modulus or a ReLU. It explicitly contract the volume of
the space to achieve a sparse representation.&lt;/p&gt;

&lt;p&gt;In the case of fixed basis like wavelet, if the representation is already
sparse, non-linear activation won’t reduce the volume too much since most of
the dimensions are already zero.&lt;/p&gt;

&lt;h3 id=&quot;diffeomorphism-calls-for-multi-scale-separation&quot;&gt;Diffeomorphism calls for multi-scale separation&lt;/h3&gt;

&lt;p&gt;Diffeomorphism can also be modeled a group symmetry. Diffeomorphism could be
factorized as a translation and a scaling effects. So to linearize
diffeomorphism, a multi-scale basis to separate the scaling effects are needed.&lt;/p&gt;

&lt;h3 id=&quot;multi-scale-interaction&quot;&gt;Multi-scale interaction&lt;/h3&gt;

&lt;p&gt;It is not enough to only separate signal using basis vectors, but also to model
their interactions. This justifies a deep architecture.&lt;/p&gt;

&lt;h2 id=&quot;combining-all-the-above-together&quot;&gt;Combining all the above together&lt;/h2&gt;

&lt;p&gt;Now we could map each symbol in the following to their functional roles.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;x_j = \rho W_j x_{j-1}&lt;/script&gt;

&lt;p&gt;Each row of $W$ is the basis vector; $\rho$ is the contraction operator to
promote sparsity; &lt;script type=&quot;math/tex&quot;&gt;x_j = ... x_{j-1}&lt;/script&gt; is the recursive form that takes cares
multi-scale separation and interaction.&lt;/p&gt;

&lt;p&gt;At the same time, &lt;script type=&quot;math/tex&quot;&gt;W_{j-1}x_{j-1}&lt;/script&gt; linearizes &lt;script type=&quot;math/tex&quot;&gt;W_j x_j&lt;/script&gt;. If we adding
pooling in, it corresponds to collapsing the direction where $f$ remains
constant.&lt;/p&gt;

&lt;h2 id=&quot;recast-in-term-of-differential-geometry&quot;&gt;Recast in term of differential geometry&lt;/h2&gt;

&lt;p&gt;Mallat use the formalism in differential geometry to succinctly define the
hierarchically built $\Phi$.&lt;/p&gt;

&lt;p&gt;According to Mallat, the power of Neural Network is it is able learn such a
representation that linearize hierarchical symmetry groups, which is formalized
using fibres of hierarchical symmetry groups. Nonlinear contraction reduces the
variability of each fibre, so removing the variability that is not directly
related to currently sample being processed. Fibres of current layer are
transported to fibres of next layers, which are fibres of large
groups. Cascadingly applying the parallel transport on a sample, we obtain
multi-scale support vectors that are sparse.&lt;/p&gt;

&lt;p&gt;However, it is hard to map these math names to the operational name of conv
net. Here is my best guess up to now.&lt;/p&gt;

&lt;p&gt;Each channel of a conv filter is a part of the orbits.
The equivalence class is the cross-channel sum of orbits of filters. The index
$P_j$ is the indices of orbits, which could be understood as the spatial
indices (orbits of translation group) and channel indices (orbits of those
groups, such as rotation groups). Since we have done a summation, how each 2D
filter corresponds to each part of the orbit does not matter, thus we get an
equivalence class.&lt;/p&gt;

&lt;p&gt;Each equivalence class is called a fibre, which is just the fancy in
differential geometry to call an operator. In this case, the fibre is just the
cascadingly built operator $ρW_j$ mentioned at the beginning section. $ρW_j$
computes an approximate mapping from fibre of layer $j-1$ to $j$, which is
called a parallel transport in $P_j$.
A parallel transport is defined by a group $G_j$ of symmetries acting on the
index set $P_j$ of a layer $x_j$.
It is called an approximate mapping because fibre is supposed to be an
equivalence class of orbits of $x_{j-1}$, and the transport be mapping from
those equivalence class. however $pW_j$ starts from $x_{j-1}$, not
equivalence classes of orbits of $x_{j-1}$. So it is assumed to be approximated
by applying $g$ to $x_j$, we get $\bar{g}$ on $x_{j-1}$. Again implicitly
$x_{j}$ will be unrolled to the equivalence class of orbit of this layer,
which is a larger groups which is semidirect products of groups of layer $j-1$,
and groups (corresponding to channels in layer $j$) of layer $j$. The
approximation only makes sense by corresponding each channel of a filter to be
a part of a orbit of $g$, as in the previous paragraph. The channel of filters
are the groups of layer $j-1$, while the number of filters (output channel
number in most convnet implementations) is the groups of the layer
$j$. Assuming each filter channel corresponds to a part of the
orbit, $g.x_{j} = g.[\rho W_j x_{j-1}] \approx \rho W_j[\bar{g}.x_{j-1}]$
in the paper makes sense, since the summation cross channel would absorb $g$ in
$W_{j}$.&lt;/p&gt;

&lt;p&gt;So the convolution is called convolutions along the fibres. Implicitly, $\rho
W_j$ expands $x_{j-1}$ to its orbits, then computes equivalence classes of
orbits of $x_{j}$ by cross-channelly adding the result of applying filters on
those orbits. If in this sense, $x_{j-1}$ is indeed an equivalence class of
orbits. I guess the approximation means that this is just an assumption, since
no constrains are enforced to make sure channels of a filter are orbits of
$x_{j-1}$.&lt;/p&gt;

&lt;p&gt;In this model, network filters are guiding nonlinear contractions, to reduce the
data variability in directions of local symmetries. The classification margin
can be controlled by sparse separations along network fibres&lt;/p&gt;

&lt;p&gt;Each fibre is complex basis vector. Sparsity ensures separateness. Mallat
introduces the concept of multi-scale support vector, explained in the
following. To avoid further contracting their distance, they can be separated
along different fibres indexed by $b$. The separation is achieved by filters
$w_{j,h.b}$, which transform $x_{j−1}$ and $x’_{j−1}$ into $x_{j}(g, h,
b)$and $x’_{j}(g, h, b)$ having sparse supports on different fibres $b$. The
next contraction $ρW_{j+1}$ reduces distances along fibres indexed by $(g, h)
\in G_j$,but not across $b \in B_j$,which preserves distances.&lt;/p&gt;
</description>
        <pubDate>Mon, 29 Aug 2016 10:41:00 +0800</pubDate>
        <link>http://shawnLeeZX.github.io/blog/2016/08/29/key-points-of-understanding-deep-conv-net/</link>
        <guid isPermaLink="true">http://shawnLeeZX.github.io/blog/2016/08/29/key-points-of-understanding-deep-conv-net/</guid>
        
        
        <category>CNN</category>
        
      </item>
    
      <item>
        <title>[Repost] Explosion of the Space Shuttle Challenger Address to the Nation</title>
        <description>&lt;p&gt;Accidentially heared the &lt;a href=&quot;https://youtu.be/SBOVkptjJhE?t=3959&quot;&gt;speech&lt;/a&gt; given by
Reagan to the nation after Challenger crashed.&lt;/p&gt;

&lt;p&gt;Below is an excerpt. Full transcript is after that. The
&lt;a href=&quot;http://history.nasa.gov/reagan12886.html&quot;&gt;transcript&lt;/a&gt; is from NASA website.&lt;/p&gt;

&lt;h2 id=&quot;excerpts&quot;&gt;Excerpts&lt;/h2&gt;

&lt;p&gt;We’ve grown used to wonders in this century. It’s hard to dazzle us. But for 25
years the United States space program has been doing just that. We’ve grown
used to the idea of space, and perhaps we forget that we’ve only just
begun. We’re still pioneers. They, the members of the Challenger crew, were
pioneers.&lt;/p&gt;

&lt;p&gt;I know it is hard to understand, but sometimes painful things like this
happen. It’s all part of the process of exploration and discovery. It’s all
part of taking a chance and expanding man’s horizons. &lt;strong&gt;The future doesn’t belong
to the fainthearted; it belongs to the brave&lt;/strong&gt;. The Challenger crew was pulling
us into the future, and we’ll continue to follow them.&lt;/p&gt;

&lt;p&gt;There’s a coincidence today. On this day 390 years ago, the great explorer Sir
Francis Drake died aboard ship off the coast of Panama. &lt;strong&gt;In his lifetime the
great frontiers were the oceans, and an historian later said, “He lived by the
sea, died on it, and was buried in it.”&lt;/strong&gt; Well, today we can say of the
Challenger crew: Their dedication was, like Drake’s, complete.&lt;/p&gt;

&lt;p&gt;The crew of the space shuttle Challenger honored us by the manner in which they
lived their lives. &lt;strong&gt;We will never forget them, nor the last time we saw them,
this morning, as they prepared for their journey and waved goodbye and “slipped
the surly bonds of earth” to “touch the face of God.”&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;full-speech&quot;&gt;Full Speech&lt;/h2&gt;

&lt;!-- more --&gt;

&lt;p&gt;Ladies and gentlemen, I’d planned to speak to you tonight to report on the
state of the Union, but the events of earlier today have led me to change those
plans. Today is a day for mourning and remembering.&lt;/p&gt;

&lt;p&gt;Nancy and I are pained to the core by the tragedy of the shuttle Challenger. We
know we share this pain with all of the people of our country. This is truly a
national loss.&lt;/p&gt;

&lt;p&gt;Nineteen years ago, almost to the day, we lost three astronauts in a terrible
accident on the ground. But we’ve never lost an astronaut in flight; we’ve
never had a tragedy like this. And perhaps we’ve forgotten the courage it took
for the crew of the shuttle; but they, the Challenger Seven, were aware of the
dangers, but overcame them and did their jobs brilliantly. We mourn seven
heroes: Michael Smith, Dick Scobee, Judith Resnik, Ronald McNair, Ellison
Onizuka, Gregory Jarvis, and Christa McAuliffe. We mourn their loss as a nation
together.&lt;/p&gt;

&lt;p&gt;For the families of the seven, we cannot bear, as you do, the full impact of
this tragedy. But we feel the loss, and we’re thinking about you so very
much. Your loved ones were daring and brave, and they had that special grace,
that special spirit that says, “Give me a challenge and I’ll meet it with joy.”
They had a hunger to explore the universe and discover its truths. They wished
to serve, and they did. They served all of us.&lt;/p&gt;

&lt;p&gt;We’ve grown used to wonders in this century. It’s hard to dazzle us. But for 25
years the United States space program has been doing just that. We’ve grown
used to the idea of space, and perhaps we forget that we’ve only just
begun. We’re still pioneers. They, the members of the Challenger crew, were
pioneers.&lt;/p&gt;

&lt;p&gt;And I want to say something to the schoolchildren of America who were watching
the live coverage of the shuttle’s takeoff. I know it is hard to understand,
but sometimes painful things like this happen. It’s all part of the process of
exploration and discovery. It’s all part of taking a chance and expanding man’s
horizons. The future doesn’t belong to the fainthearted; it belongs to the
brave. The Challenger crew was pulling us into the future, and we’ll continue
to follow them.&lt;/p&gt;

&lt;p&gt;I’ve always had great faith in and respect for our space program, and what
happened today does nothing to diminish it. We don’t hide our space program. We
don’t keep secrets and cover things up. We do it all up front and in
public. That’s the way freedom is, and we wouldn’t change it for a minute.&lt;/p&gt;

&lt;p&gt;We’ll continue our quest in space. There will be more shuttle flights and more
shuttle crews and, yes, more volunteers, more civilians, more teachers in
space. Nothing ends here; our hopes and our journeys continue.&lt;/p&gt;

&lt;p&gt;I want to add that I wish I could talk to every man and woman who works for
NASA or who worked on this mission and tell them: “Your dedication and
professionalism have moved and impressed us for decades. And we know of your
anguish. We share it.”&lt;/p&gt;

&lt;p&gt;There’s a coincidence today. On this day 390 years ago, the great explorer Sir
Francis Drake died aboard ship off the coast of Panama. In his lifetime the
great frontiers were the oceans, and an historian later said, “He lived by the
sea, died on it, and was buried in it.” Well, today we can say of the
Challenger crew: Their dedication was, like Drake’s, complete.&lt;/p&gt;

&lt;p&gt;The crew of the space shuttle Challenger honored us by the manner in which they
lived their lives. We will never forget them, nor the last time we saw them,
this morning, as they prepared for their journey and waved goodbye and “slipped
the surly bonds of earth” to “touch the face of God.”&lt;/p&gt;
</description>
        <pubDate>Sat, 30 Jul 2016 08:42:00 +0800</pubDate>
        <link>http://shawnLeeZX.github.io/blog/2016/07/30/repost-explosion-of-the-space-shuttle-challenger-address-to-the-nation/</link>
        <guid isPermaLink="true">http://shawnLeeZX.github.io/blog/2016/07/30/repost-explosion-of-the-space-shuttle-challenger-address-to-the-nation/</guid>
        
        
        <category>Repost</category>
        
        <category>Life</category>
        
      </item>
    
      <item>
        <title>Note On Representation of Operator</title>
        <description>&lt;p&gt;A note to remind me of some intuition ruminated. Do not have the time to write
down detailed proof.&lt;/p&gt;

&lt;p&gt;It is about spectral theorem of matrix, adjoint operator, SVD and tensor.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h2 id=&quot;spectral-theorem&quot;&gt;Spectral Theorem&lt;/h2&gt;

&lt;p&gt;The representation theory of linear functional is essentially one dimension
version of group representation theory. The $w$ in the inner product $\langle
x, w \rangle$ representation of functional $f(x)$ is essentially the normal of
the hyperplane, which is the functional’s representation in the dual space. The
process of applying $f$ on $x$ is a process of projection.&lt;/p&gt;

&lt;p&gt;For a general operator $T: X \rightarrow Y$, whose representation is denoted
$A$, if the bases of the $X, Y$ are orthogonal, the adjoint operator $T^{*}$ of
$T$’s representation is $A^{T}$(on the condition that bases of $X, Y$ is chosen
to be orthogonal). The process of applying $T$ on $x$ is a process of first
doing multiple projection, then sum those projection together. The fact that
adjoint operator has the spectral theorem is just because in certain bases,
when we are applying the multiple projection, we are not projecting at all, but
just scale along the hyperplane. The process of changing bases, applying
scaling, then changing bases back written in form of matrix multiplication is
$M^{-1}\Lambda M$, which is the spectral decomposition of representation of $T$.&lt;/p&gt;

&lt;h2 id=&quot;adjoint-operator-is-just-the-transpose&quot;&gt;Adjoint Operator is Just the Transpose&lt;/h2&gt;

&lt;p&gt;The projection perspective also explains why $T^{*} = A^{T}$.&lt;/p&gt;

&lt;p&gt;Let $Ax = y$. Each $x_i$ contributes to $y_i$ linearly. So just like a linear
equation has a unique solution as long as $A$ is of full rank, there must be a
one-to-one relationship between $T$ and $T^{*}$, which is formalized using
representation theory of functional again.&lt;/p&gt;

&lt;h2 id=&quot;svd&quot;&gt;SVD&lt;/h2&gt;

&lt;p&gt;SVD just factorizes the multi-projection into a rotation matrix and a scaling
matrix.&lt;/p&gt;

&lt;h2 id=&quot;tensor&quot;&gt;Tensor&lt;/h2&gt;

&lt;p&gt;Tensor is a generalized operator that handles multi-linearity.&lt;/p&gt;
</description>
        <pubDate>Sun, 01 May 2016 17:02:00 +0800</pubDate>
        <link>http://shawnLeeZX.github.io/blog/2016/05/01/note-on-representation-of-operator/</link>
        <guid isPermaLink="true">http://shawnLeeZX.github.io/blog/2016/05/01/note-on-representation-of-operator/</guid>
        
        
        <category>Math</category>
        
        <category>Note</category>
        
      </item>
    
      <item>
        <title>A Quick Survey on Distributed Log Processing: Unison and Logstash</title>
        <description>&lt;p&gt;Having multiple machines to train neural networks, I was trying to think how
could I automatically gather all the training logs, so I could analyze them in
one place.&lt;/p&gt;

&lt;p&gt;I did a survey on technologies available. The ones that I found are: &lt;code class=&quot;highlighter-rouge&quot;&gt;Logstash&lt;/code&gt;
and &lt;code class=&quot;highlighter-rouge&quot;&gt;unison&lt;/code&gt;. &lt;code class=&quot;highlighter-rouge&quot;&gt;Logstash&lt;/code&gt; seems to be the optimal solution, though may be a little
an overkill. However, I settled to use &lt;code class=&quot;highlighter-rouge&quot;&gt;unison&lt;/code&gt; in the end. The rationale
behind this is I have to get around many VPNs. The VPNs I used, or maybe most
VPNs setups, won’t let the machines in LAN of the VPN network ping back to the
machine that uses VPN to connect. It may just not come from a security reason,
though it could be; it may just because it is not necessary to set up the route
table to the IP addresses allocated to the connecting machine. So in this case,
the log cannot be sent back to the connecting machine, as the way &lt;code class=&quot;highlighter-rouge&quot;&gt;Logstash&lt;/code&gt;
does. A solution is needed to initialize the centralization from the connect
machine site. So &lt;code class=&quot;highlighter-rouge&quot;&gt;Logstash&lt;/code&gt; is ruled out, and I settled with &lt;code class=&quot;highlighter-rouge&quot;&gt;unison&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The following is a quick note on &lt;code class=&quot;highlighter-rouge&quot;&gt;unison&lt;/code&gt; works, which took me a while to
figure out. For an practical introduction to &lt;code class=&quot;highlighter-rouge&quot;&gt;Logstash&lt;/code&gt;, see the
&lt;a href=&quot;http://www.slashroot.in/logstash-tutorial-linux-central-logging-server&quot;&gt;tutorial&lt;/a&gt;
here.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h2 id=&quot;introductory-note&quot;&gt;Introductory Note&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://www.cis.upenn.edu/~bcpierce/unison/download/releases/stable/unison-manual.html#basics&quot;&gt;Unison&lt;/a&gt;
is a file-synchronization tool for Unix and Windows. It allows two replicas of
a collection of files and directories to be stored on different hosts (or
different disks on the same host), modified separately, and then brought up to
date by propagating the changes in each replica to the other.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Unison&lt;/code&gt; supports transmission via &lt;code class=&quot;highlighter-rouge&quot;&gt;ssh&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;socket&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;file&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;rsh&lt;/code&gt;. Each of
those protocols has its own setups, except for the &lt;code class=&quot;highlighter-rouge&quot;&gt;file&lt;/code&gt; protocol — it
synchronizes files within the single machine. For instance, to use ssh, the two
machines to be able to ssh to each other.&lt;/p&gt;

&lt;p&gt;The way &lt;code class=&quot;highlighter-rouge&quot;&gt;unison&lt;/code&gt; is used is similar with &lt;code class=&quot;highlighter-rouge&quot;&gt;scp&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;cp&lt;/code&gt; in the sense that they
are all a command line source destination style. An example would be&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;unison -testserver /tmp/ ssh://192.168.72.1//tmp
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The format of a source or destination is
&lt;code class=&quot;highlighter-rouge&quot;&gt;[protocol:]//[user@][host][:port][/path]&lt;/code&gt;. The one with no host name is
supposed to your local machine. The &lt;code class=&quot;highlighter-rouge&quot;&gt;-testserver&lt;/code&gt; option above is used to test
whether the network between the local machine and the remote machine is
reachable.&lt;/p&gt;

&lt;p&gt;To avoid typing the addresses each time, since &lt;code class=&quot;highlighter-rouge&quot;&gt;unison&lt;/code&gt; is about syncing, not
copying, &lt;code class=&quot;highlighter-rouge&quot;&gt;unison&lt;/code&gt; offers a thing called profile. The command above, without the
&lt;code class=&quot;highlighter-rouge&quot;&gt;-testserver&lt;/code&gt; option, converts to a profile is&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;root = /home/use1/work/sync/
root = ssh://192.168.72.1//home/user1/work/sync
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;For more sophisticated profiles, see the office
&lt;a href=&quot;http://www.cis.upenn.edu/~bcpierce/unison/download/releases/stable/unison-manual.html#profile&quot;&gt;doc&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The question following is where do we store profiles?&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;unison&lt;/code&gt; will store all its logistics files under the folder pointed by
environment variable &lt;code class=&quot;highlighter-rouge&quot;&gt;UNISON&lt;/code&gt;, which if not specified, is &lt;code class=&quot;highlighter-rouge&quot;&gt;.unison&lt;/code&gt; under the
&lt;code class=&quot;highlighter-rouge&quot;&gt;$HOME&lt;/code&gt; folder. A profile file us named in the format of &lt;code class=&quot;highlighter-rouge&quot;&gt;*.prf&lt;/code&gt;. Suppose the
above profile is saved as &lt;code class=&quot;highlighter-rouge&quot;&gt;test.prf&lt;/code&gt;. To use that profile, type&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;unison &lt;span class=&quot;nb&quot;&gt;test&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The last thing I spent some time to figure out is how it actually sync between
machines, so it won’t mess up my data. Roughly, it adds another layer of logic
above &lt;code class=&quot;highlighter-rouge&quot;&gt;rsync&lt;/code&gt;, which is suggested from the document&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Transfers are optimised using a version of the rsync protocol, making it ideal
for slower links. Unison has a clear and precise specification, and is
resilient to failure due to its careful handling of the replicas and its
private structures.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The logic is added I think is the way to get some fingerprints of the files, so
it knows which files is updated when syncing, and only sync those are really updated.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Touching a file without changing its contents should never affect whether or
not Unison does an update. (When running with the fastcheck preference set to
true—the default on Unix systems—Unison uses file modtimes for a quick first
pass to tell which files have definitely not changed; then, for each file that
might have changed, it computes a fingerprint of the file's contents and
compares it against the last-synchronized contents. Also, the -times option
allows you to synchronize file times, but it does not cause identical files to
be changed; Unison will only modify the file times.)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;So calling unison at either end will sync the files right.&lt;/p&gt;

&lt;h2 id=&quot;sync-between-more-than-machines&quot;&gt;Sync Between More than Machines&lt;/h2&gt;

&lt;p&gt;The built-in doc of &lt;code class=&quot;highlighter-rouge&quot;&gt;unison&lt;/code&gt;, which is available via &lt;code class=&quot;highlighter-rouge&quot;&gt;unison -doc tutorial&lt;/code&gt;,
has a section discussing how &lt;code class=&quot;highlighter-rouge&quot;&gt;unison&lt;/code&gt; could be used to sync between more than
machines.&lt;/p&gt;

&lt;p&gt;Using Unison to Synchronize More Than Two Machines&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Unison is designed for synchronizing pairs of replicas. However, it is
possible to use it to keep larger groups of machines in sync by
performing multiple pairwise synchronizations.

If you need to do this, the most reliable way to set things up is to
organize the machines into a “star topology,” with one machine
designated as the “hub” and the rest as “spokes,” and with each spoke
machine synchronizing only with the hub. The big advantage of the star
topology is that it eliminates the possibility of confusing “spurious
conflicts” arising from the fact that a separate archive is maintained
by Unison for every pair of hosts that it synchronizes.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;I did not get what does it mean in the first reading. After that, I guess the
method it suggests is to establish a pair-wise sync among machines with certain
topology, which is to say: one needs to set up multiple profiles; each profile
sync between two machines; those machines form a topology so there is a hub
that will have a centralized sync state among all machines if you sync in the
right order.&lt;/p&gt;
</description>
        <pubDate>Tue, 15 Mar 2016 10:53:00 +0800</pubDate>
        <link>http://shawnLeeZX.github.io/blog/2016/03/15/a-quick-survey-on-log-processing/</link>
        <guid isPermaLink="true">http://shawnLeeZX.github.io/blog/2016/03/15/a-quick-survey-on-log-processing/</guid>
        
        
        <category>CS</category>
        
        <category>Note</category>
        
        <category>Linux</category>
        
      </item>
    
      <item>
        <title>Note on Installing Ubuntu on Newer Machines</title>
        <description>&lt;p&gt;This is the note supposed to note something peculiar things I met during
setting up Ubuntu on a newer machine, which is to say, with UEFI replacing
BIOS, GPT replacing MBR, Display Port and HDMI replacing VGA and DVI, and with
several GPUs.&lt;/p&gt;

&lt;p&gt;Due to time reason, I fell back to my old way of installing Ubuntu, and have
not figured out what is the right way to install the newer machine mentioned
above, but the note is to note down possible guess, and the things have been
figured out, so I may have a thread to follow next time.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;At the time I entered what was called BIOS of the machine, which is called
UEFI(Unified Extensible Firmware Interface), I was amazed that it was an almost
desktop GUI. The official lab machine of mine has a similar firmware, but since
I was not supposed to have access to it, I did not play with it much. I think
my most recent laptop should have also used UEFI, but I did not have any memory
what it is like, I guess I did not need to change things so I did not enter it.&lt;/p&gt;

&lt;h2 id=&quot;gpu-control-from-boot-to-os&quot;&gt;GPU Control From Boot to OS&lt;/h2&gt;

&lt;p&gt;The first thing I tried to figure out is how a GPU could be installed
properly. In other words, how could a GPU inserted in a socket could be
detected by the motherboard, then OS?&lt;/p&gt;

&lt;p&gt;Normally a PC motherboard has an integrated card, and an optional discrete
graphical unit could be installed GPU card through PCIE sockets. There is a
switch in the UEFI to tell the motherboard where to look for a graphical
unit. Also, even if the GPU is not powered up, I could have a hint on the
monitor to tell me to what happened. So I think a GPU has a basic function unit
that offers motherboard basic graphical function so it could be used till the
machine boots into an OS.&lt;/p&gt;

&lt;p&gt;The first problem I have met is there was no output when I connect DVI adapter
of the monitor to a TITAN Black that was inserted in the latter socket of the
motherboard, and could only get output when I connect the adapter to the GPU
inserted in the first PCIE socket. The GPU is not a TITAN Black but a 760.&lt;/p&gt;

&lt;p&gt;There are two guesses why this situations happen. The first is UEFI only detect
GPU at the first PCIE socket and ignores all the remaining. This is reasonable
since no one is supposed to use multiple GPUs during boot time. But it seems I
have tried put a TITAN Black at the first socket, though I cannot clearly
remember it. So another guess is my current UEFI does not support TITAN at boot
time.&lt;/p&gt;

&lt;p&gt;After the UEFI transfer the control to OS, the drivers in UEFI should not
function anymore. So drivers need to be installed in the OS.&lt;/p&gt;

&lt;p&gt;The open source NVIDIA card driver, Nouveau, will be installed when installing
Ubuntu. I thought only when a NVIDIA GPU is physically inserted, its open
source driver would be installed. However, it seems the open source driver will
be installed even without a card. Maybe it is because in this case, a GPU card
could be used right after installation without re-installing kernel modules.&lt;/p&gt;

&lt;p&gt;Nouveau has to be removed if I want to install the newest driver from NVIDIA
through the &lt;code class=&quot;highlighter-rouge&quot;&gt;*run&lt;/code&gt; file, otherwise they would conflict. To do this, a file
needs to be added to &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/modprobe.d/&lt;/code&gt; with the following contents.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# generated by nvidia-installer
blacklist nouveau
options nouveau modeset=0
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;It is actually generated by the &lt;code class=&quot;highlighter-rouge&quot;&gt;*run&lt;/code&gt; file. I think it tells kernel not to
load nouveau module.&lt;/p&gt;

&lt;p&gt;Then regenerate your kernel&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;update-initramfs -u
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;To completely wipe out &lt;code class=&quot;highlighter-rouge&quot;&gt;nouveau&lt;/code&gt; — though I think even without doing it, it
would work, run the following command&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo apt-get remove xserver-xorg-video-nouveau
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;To run &lt;code class=&quot;highlighter-rouge&quot;&gt;*run&lt;/code&gt; file, one needs to log into a text console. A way I could find
that is commonly suggested on the web is to switch to one virtual terminal by
`Ctrl+Alt+F1’, then stop the X service&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo stop lightdm   or
sudo lightdm stop
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;It did not work for me. So I need to reboot into text mode by editing
grub. More concretely, when the grub menu pops up, press &lt;code class=&quot;highlighter-rouge&quot;&gt;e&lt;/code&gt; on the item, and
find &lt;code class=&quot;highlighter-rouge&quot;&gt;splash quiet&lt;/code&gt;, and change it to &lt;code class=&quot;highlighter-rouge&quot;&gt;text&lt;/code&gt;, then press &lt;code class=&quot;highlighter-rouge&quot;&gt;F10&lt;/code&gt; to boot using
current edited entry.&lt;/p&gt;

&lt;p&gt;One last thing before running the &lt;code class=&quot;highlighter-rouge&quot;&gt;*run&lt;/code&gt; file. The &lt;code class=&quot;highlighter-rouge&quot;&gt;*run&lt;/code&gt; file will build GPU
driver to kernel, but only once. So if your OS gets upgraded, you won’t be able
to log in desktop again. To work get around this, we need to install &lt;code class=&quot;highlighter-rouge&quot;&gt;dkms&lt;/code&gt;, so
each time the kernel gets upgraded, all modules already built will be
automatically built again into the kernel.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo apt-get install dkms
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;All are settled, just run the &lt;code class=&quot;highlighter-rouge&quot;&gt;*run&lt;/code&gt; file to install the driver.&lt;/p&gt;

&lt;p&gt;To see what modules has been managed by &lt;code class=&quot;highlighter-rouge&quot;&gt;dkms&lt;/code&gt;, use &lt;code class=&quot;highlighter-rouge&quot;&gt;dkms status&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;One last thing that tricked me up is to tell motherboard to use discrete
graphical unit after the driver has been installed. Otherwise, I could still
make it till the GUI login page, but after I have input my password, the screen
just flash a little, and ask me to log in again. I guess the problem is
since motherboard is configured to use integrated graphical unit, so the
discrete one is actually inactive, when &lt;code class=&quot;highlighter-rouge&quot;&gt;xorg.conf' tells &lt;/code&gt;X11` to use the
discrete graphical unit, nothing is there. The solution is just to fall back.&lt;/p&gt;

&lt;p&gt;I also have some guess on how &lt;code class=&quot;highlighter-rouge&quot;&gt;X11&lt;/code&gt; make use of multiple GPUs. I have two
versions of &lt;code class=&quot;highlighter-rouge&quot;&gt;xorg.conf&lt;/code&gt;, one from my official lab machine, and one from the one
I am setting up.&lt;/p&gt;

&lt;p&gt;The official one&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Section &quot;Device&quot;
    Identifier     &quot;Device0&quot;
    Driver         &quot;nvidia&quot;
    VendorName     &quot;NVIDIA Corporation&quot;
    BoardName      &quot;GeForce GTX TITAN Black&quot;
EndSection

Section &quot;Device&quot;
    Identifier     &quot;Device1&quot;
    Driver         &quot;nvidia&quot;
    VendorName     &quot;NVIDIA Corporation&quot;
    BoardName      &quot;GeForce GTX TITAN Black&quot;
    BusID          &quot;PCI:1:0:0&quot;
    Screen          1
EndSection
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The other one is just&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Section &quot;Device&quot;
    Identifier     &quot;Device0&quot;
    Driver         &quot;nvidia&quot;
    VendorName     &quot;NVIDIA Corporation&quot;
EndSection
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The first one is generated by &lt;code class=&quot;highlighter-rouge&quot;&gt;nvidia-settings', the second one is generated by
&lt;/code&gt;*run` file. I have three TITAN Black installed on the motherboard with the
second configuration file, and they are all functional.&lt;/p&gt;

&lt;p&gt;The guess now is if no bus id is specified in &lt;code class=&quot;highlighter-rouge&quot;&gt;xorg.conf&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;X11&lt;/code&gt; could pick any
one, and prefer to the one with lowest PCI id or GPU id.&lt;/p&gt;

&lt;p&gt;A side note. To get the bus id of a card, use &lt;code class=&quot;highlighter-rouge&quot;&gt;lspci&lt;/code&gt;, which output corresponds
to GPU is&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;01:00.0 VGA compatible controller: NVIDIA Corporation GK110B [GeForce GTX TITAN Black] (rev a1)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;01:00.0&lt;/code&gt; is the bus id, though I am still now know why the period becomes a colon.&lt;/p&gt;

&lt;h2 id=&quot;note-on-cuda&quot;&gt;Note On CUDA&lt;/h2&gt;

&lt;p&gt;After all those efforts to install NVIDIA driver through &lt;code class=&quot;highlighter-rouge&quot;&gt;*run&lt;/code&gt; file, I found
&lt;code class=&quot;highlighter-rouge&quot;&gt;cuda&lt;/code&gt; installation(using the network deb provided by NVIDIA) just overrided
the driver I have just installed…&lt;/p&gt;

&lt;p&gt;I am not sure whether dkms will be automatically installed, or nouveau be
automatically blacklisted, though the installation of cuda does not mention it,
which is to mean they probably will take care of this. If this is so the
installation of NVIDIA driver and CUDA will be much easier.&lt;/p&gt;

&lt;p&gt;I notice the &lt;code class=&quot;highlighter-rouge&quot;&gt;xorg.conf&lt;/code&gt; is not changed after the ``new’’ driver being
installed.&lt;/p&gt;

&lt;h2 id=&quot;bios-mode-or-uefi-mode-ubuntu&quot;&gt;BIOS mode or UEFI mode Ubuntu&lt;/h2&gt;

&lt;p&gt;The last set of note is about installing Ubuntu in BIOS mode or UEFI mode,
which corresponds to using MBR or GPT partition table, and may be some other
difference.&lt;/p&gt;

&lt;p&gt;At the time when choosing the boot media, even if your USB only has one Ubuntu
on it, the boot menu would show up as entries, one for normal BIOS mode
ubuntu(which is just named Ubuntu), one for UEFI mode(which has a UEFI in the
name). I have not tried the second one. The UEFI is a pretty new thing to me,
since the last time I learned something about it, UEFI is still in its
infancy.&lt;/p&gt;

&lt;p&gt;If UEFI is chosen, the partition table of the hard disk where the boot loader
would be installed must be GPT, which is written in the new standard. The boot
loader of MBR and GPT are different(obviously). For GPT, an explicitly
formatted and allocated partition seems to be needed(not verified). As for MBR,
as everyone knows, the space for the boot loader will always be left out. Also,
to boot from a GPT partitioned disk, a boot flag need to be marked on the disk,
otherwise, OS won’t boot. There are still many other difference I have not
figured out yet.&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.linuxsecrets.com/blog/15questions-troubleshooting/2015/09/10/1651-how-to-remove-nouveau-and-install-nvidia-drivers&quot;&gt;How to Remove Nouveau and Install Nvidia Drivers&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Tue, 08 Mar 2016 13:48:00 +0800</pubDate>
        <link>http://shawnLeeZX.github.io/blog/2016/03/08/note-on-installing-ubuntu-on-newer-machines/</link>
        <guid isPermaLink="true">http://shawnLeeZX.github.io/blog/2016/03/08/note-on-installing-ubuntu-on-newer-machines/</guid>
        
        
        <category>Linux</category>
        
        <category>Note</category>
        
        <category>CS</category>
        
      </item>
    
      <item>
        <title>VLC下使用中文字幕</title>
        <description>&lt;p&gt;记如何在VLC下使用中文字幕。&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;默认状态下，VLC会遇到两个问题，一是解码的codecs所用不对，而是用于显示字体的渲染
器(render)所用字体不对。&lt;/p&gt;

&lt;p&gt;第一个问题的解决办法一是更改VLC所用的codecs；二是修改文件的codecs为utf-8。第一
种方法在&lt;a href=&quot;http://bbs.feng.com/read-htm-tid-344593.html&quot;&gt;这里&lt;/a&gt;有介绍。第二种方法
我发现Vim可以完美完成，特此记之。&lt;/p&gt;

&lt;p&gt;用Vim打开字幕文件，然后使用如下命令：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;:set fileencoding=utf-8
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;保存，退出。&lt;/p&gt;

&lt;p&gt;第二个问题的解决也来自之上的
&lt;a href=&quot;http://bbs.feng.com/read-htm-tid-344593.html&quot;&gt;链接&lt;/a&gt;。为防止链接失效，特此重述
方法：&lt;/p&gt;

&lt;p&gt;打开VLC的&lt;code class=&quot;highlighter-rouge&quot;&gt;Preferences&lt;/code&gt;窗口（&lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl+P&lt;/code&gt;），点击右下角的&lt;code class=&quot;highlighter-rouge&quot;&gt;all&lt;/code&gt;，在左边的索引中依次选择
&lt;code class=&quot;highlighter-rouge&quot;&gt;Video -&amp;gt; Subtitles/OSD -&amp;gt; Text renderer&lt;/code&gt;，右边的设置区第一项为&lt;code class=&quot;highlighter-rouge&quot;&gt;Font&lt;/code&gt;，点击&lt;code class=&quot;highlighter-rouge&quot;&gt;Browse&lt;/code&gt;按
钮选择一项中文字体，如&lt;code class=&quot;highlighter-rouge&quot;&gt;WenQuanYi Micro Hei&lt;/code&gt;。更改完成之后需要重启VLC。&lt;/p&gt;
</description>
        <pubDate>Tue, 16 Feb 2016 22:00:00 +0800</pubDate>
        <link>http://shawnLeeZX.github.io/blog/2016/02/16/vlcxia-shi-yong-zhong-wen-zi-mu/</link>
        <guid isPermaLink="true">http://shawnLeeZX.github.io/blog/2016/02/16/vlcxia-shi-yong-zhong-wen-zi-mu/</guid>
        
        
        <category>Note</category>
        
        <category>Linux</category>
        
      </item>
    
      <item>
        <title>Note on Running Tensorflow in Anaconda</title>
        <description>&lt;p&gt;Due to conflict of protobuf version, I have to run tensorflow in a sandbox
environment, aka anaconda. This is the note to note down some of its tricky
parts I spent some time figuring out.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;Most of the packages are backward compatible, so normal packages could be
installed on servers normally, by &lt;a href=&quot;http://www.ansible&quot;&gt;Ansible&lt;/a&gt;. But if
Caffe(it seems the newest Caffe upgraded to protobuf3) and tensorflow want to
be installed in the same machine, protobuf2 and protobuf3 have to co-exist. Due
to their
&lt;a href=&quot;https://www.tensorflow.org/versions/master/get_started/os_setup.html#mac-os-x-typeerror-init-got-an-unexpected-keyword-argument-syntax&quot;&gt;conflict&lt;/a&gt;,
they cannot co-exist. So to not break others environment, I have to install
tensorflow in anaconda.&lt;/p&gt;

&lt;p&gt;There are two things I think I may need in the future:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;To install Anaconda and all consequent python packages in it using Ansible.&lt;/li&gt;
  &lt;li&gt;A bug either in pip or in conda that needs some workaround.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;using-ansible-with-anaconda&quot;&gt;Using Ansible with Anaconda&lt;/h2&gt;

&lt;p&gt;Conda has a &lt;a href=&quot;http://conda.pydata.org/docs/help/silent.html&quot;&gt;silent mode&lt;/a&gt;, so it
could be install using shell script, which could be achieved using the &lt;code class=&quot;highlighter-rouge&quot;&gt;shell&lt;/code&gt;
module in Ansible.&lt;/p&gt;

&lt;p&gt;To install consequent packages all in Anaconda environment, we could write a
playbook that has the location of &lt;code class=&quot;highlighter-rouge&quot;&gt;pip&lt;/code&gt; as a variable, so by passing different
&lt;code class=&quot;highlighter-rouge&quot;&gt;pip&lt;/code&gt; binary, we could install the python packages wherever we want.&lt;/p&gt;

&lt;h2 id=&quot;solve-cannot-remove-entries-from-nonexistent-file--easy-installpth&quot;&gt;Solve ``Cannot remove entries from nonexistent file: … easy-install.pth’’&lt;/h2&gt;

&lt;p&gt;There is a bug preventing one upgrading packages in Anaconda. Where this bug
belongs to pip/setuptools or conda seems still in
&lt;a href=&quot;https://github.com/pypa/pip/issues/2751&quot;&gt;consideration&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The workaround I used, one of the workarounds suggested by the above link,
which I think is the simplest one is to add &lt;code class=&quot;highlighter-rouge&quot;&gt;--ignore-installed&lt;/code&gt; option to
&lt;code class=&quot;highlighter-rouge&quot;&gt;pip&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;If your packages in contained in &lt;code class=&quot;highlighter-rouge&quot;&gt;conda&lt;/code&gt;’s collection, the best solution is to
install it there. For instance, for &lt;code class=&quot;highlighter-rouge&quot;&gt;numpy&lt;/code&gt;, it is just better to install by&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda update numpy
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Sat, 09 Jan 2016 19:25:00 +0800</pubDate>
        <link>http://shawnLeeZX.github.io/blog/2016/01/09/note-on-running-tensorflow-in-anaconda/</link>
        <guid isPermaLink="true">http://shawnLeeZX.github.io/blog/2016/01/09/note-on-running-tensorflow-in-anaconda/</guid>
        
        
        <category>Python</category>
        
        <category>Note</category>
        
        <category>Ansible</category>
        
      </item>
    
      <item>
        <title>Setting up Multi-Monitor on Gnome Ubuntu 14.04 with NVIDIA Card</title>
        <description>&lt;p&gt;I got an old monitor and spent some time tweaking the dual monitor setting of
my PC in the office. Here I note down&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;a tweak to make multiple monitor in Gnome functions better, and some notes
on the behavior of &lt;code class=&quot;highlighter-rouge&quot;&gt;guake&lt;/code&gt; under multi-monitor setting.&lt;/li&gt;
  &lt;li&gt;a hack to let X Windows remember the monitor layout&lt;/li&gt;
  &lt;li&gt;and a short comparison between Gnome 3 and KDE Plasma 4.&lt;/li&gt;
&lt;/ol&gt;

&lt;!-- more --&gt;

&lt;h2 id=&quot;dual-monitor-on-gnome&quot;&gt;Dual Monitor on Gnome&lt;/h2&gt;

&lt;p&gt;I uses &lt;a href=&quot;https://www.gnome.org/&quot;&gt;Gnome&lt;/a&gt; as my desktop environment ever since the
time I started using Linux. So naturally, the desktop I tried this time to
manage multi-monitor support is Gnome. By default, the dual monitor worked
pretty OK. The only one thing that may need a tweak is: by default, Gnome(my
version is 3.9.90), only supports workspace in primary monitor, so when you
switch back and forth between different workspace, the secondary monitor stays
fixed on whatever it is on. This kind of makes the extra monitor many times
less useful. To make the secondary monitor attach to current workspace, so it
moves when you switch workspaces, you need to configure Gnome a little bit, by
the following command&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;gsettings &lt;span class=&quot;nb&quot;&gt;set &lt;/span&gt;org.gnome.shell.overrides workspaces-only-on-primary &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;One drawback of making such a change is &lt;code class=&quot;highlighter-rouge&quot;&gt;guake&lt;/code&gt; will stay on the secondary
window forever. Did not get the time to look into the source code to know why
:(.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Updated on Jan 9, 2016.&lt;/em&gt;&lt;/p&gt;

&lt;strike&gt;It is weird. `guake` functions normally now, after a reboot. This is probably
not the first time I reboot. I guess it is the package updates that fixed
something.&lt;/strike&gt;

&lt;p&gt;I figured out why. When you maximize &lt;code class=&quot;highlighter-rouge&quot;&gt;guake&lt;/code&gt; it sticks with that monitor, but
your cancel maximization, it would reconsider it position by probing which
monitor the mouse is in and set itself there.&lt;/p&gt;

&lt;h2 id=&quot;physical-layout-of-monitors&quot;&gt;Physical Layout of Monitors&lt;/h2&gt;

&lt;p&gt;I do not know how much it depends on operating system, drivers and
hardware. The &lt;code class=&quot;highlighter-rouge&quot;&gt;display&lt;/code&gt;(the GUI one of Gnome) or &lt;code class=&quot;highlighter-rouge&quot;&gt;nvidia-settings&lt;/code&gt;(the CLI one
comes with proprietary driver) forgets the monitor layout after reboot, such as
&lt;code class=&quot;highlighter-rouge&quot;&gt;DVI-I-1&lt;/code&gt; should be on the left of &lt;code class=&quot;highlighter-rouge&quot;&gt;DVI-D-0&lt;/code&gt;, even if I wrote it in the
&lt;code class=&quot;highlighter-rouge&quot;&gt;xorg.conf&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Though finally I switched the monitors physically, for some other reason, and
made peace with the forgetful display manager, I struggled some time to figure
out how to make the layout right.&lt;/p&gt;

&lt;p&gt;The solution I used is to use &lt;code class=&quot;highlighter-rouge&quot;&gt;xrandr&lt;/code&gt; after the GUI session has set up by
adding a script containing the following line in the startup application of
Gnome(there is a GUI program called &lt;code class=&quot;highlighter-rouge&quot;&gt;Startup Application&lt;/code&gt;, though I do not know
what its CLI version is).&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;xrandr --output DVI-I-1 --mode 1920x1080 --right-of DVI-D-0
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;I also have tried to add the above line in &lt;code class=&quot;highlighter-rouge&quot;&gt;.profile&lt;/code&gt;, but it seems the layout
setting is decided after &lt;code class=&quot;highlighter-rouge&quot;&gt;.profile&lt;/code&gt; is loaded, so it did not work.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Updated on Mar 8, 2016.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I seems to figured out how gnome handle layout of monitors. The one that powered
on the first will be the primary monitor, and be put on the left. The one added
later will be put at the right. So if you want to change the layout of monitors,
just disconnect the one you want to put at the right, then connect again.&lt;/p&gt;

&lt;h2 id=&quot;a-peak-at-kde&quot;&gt;A Peak at KDE&lt;/h2&gt;

&lt;p&gt;At the first time I tried to set &lt;code class=&quot;highlighter-rouge&quot;&gt;workspaces-only-on-primary&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;false&lt;/code&gt;, it
did not have any effect, and first all workspaces other than the first one
started to get severe artifact when moving windows around, then even the first
one started to get artifacts. It made the desktop unusable.&lt;/p&gt;

&lt;p&gt;After trying to search for an solution in Google for a while, I learned there
seems Gnome do not have any multi-monitor support at all, at least they do not
consider this a feature to be proud of at their website for Gnome 3. So I think
maybe Gnome does not work for Gnome.&lt;/p&gt;

&lt;p&gt;Then some video introducing Plasma let me pay some attention to KDE
desktop. The modern design of KDE Plasma 5.5 really impressed me, though in
retrospect I was dazzled by Gnome 3’s new design at the first I saw it. It is
just the case that I have been used to Gnome 3 for such a long time and do not
feel its design at all now.&lt;/p&gt;

&lt;p&gt;I installed Plasma from source by&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo apt-get install kubuntu-desktop
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This is the first time I started to feel Ubuntu 14.04 is getting old. It only
has Plasma 4.14(the minor version may not be right, but it is 4).&lt;/p&gt;

&lt;p&gt;After tinkering it a little bit, though it must be the case I did not get
myself familiar with it, I have the first impression as following:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;It seems to have many widgets, which is better than Gnome, whose desktop
widget feels like antiques.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Besides that, I did not find an obvious solution to&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;multiple workspaces, which is available by default in Gnome&lt;/li&gt;
  &lt;li&gt;the dash application runner(I am not sure its exact name, just you press the
&lt;code class=&quot;highlighter-rouge&quot;&gt;super&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;win&lt;/code&gt; key in you desktop and it shows up). I tried to install
a app called &lt;code class=&quot;highlighter-rouge&quot;&gt;homerun&lt;/code&gt;, but it just adds too much icons in the desktop and
creates too much clutters.&lt;/li&gt;
  &lt;li&gt;Obvious, &lt;code class=&quot;highlighter-rouge&quot;&gt;guake&lt;/code&gt; does not work here anymore.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The above three are really killer app, and cannot not be lacking.&lt;/p&gt;

&lt;p&gt;So the first impression is KDE is for the GUI users.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;It has a good file manager called &lt;code class=&quot;highlighter-rouge&quot;&gt;Dolphin&lt;/code&gt;, whose functionality is better
than &lt;code class=&quot;highlighter-rouge&quot;&gt;Nautilus&lt;/code&gt;. But I almost do not use GUI file management since I do it
all in CLI.&lt;/li&gt;
  &lt;li&gt;A similar application launcher of dash of Gnome is &lt;code class=&quot;highlighter-rouge&quot;&gt;Krunner&lt;/code&gt;. But like
Unity, it not only search for applications, but also search for files, any
opened applications etc, which creates much clutter, though this is a
desktop user wants.&lt;/li&gt;
  &lt;li&gt;Again, no easy drop-down terminal like &lt;code class=&quot;highlighter-rouge&quot;&gt;guake&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;It adds too much clutter that may not be useful, compared with a clean wall
paper of Gnome. I think Plasma 5.5 tries to fix this, but I did not have the
chance to try.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;As having been said, it must be the case I am not familiar with a new desktop
environment, but I guess I will settle with it, because after I was little
frustrated with the KDE desktop, I tried to switch back to Gnome. Suddenly,
everything started to work well! Maybe it is because I installed a lot of
libraries when I was installing KDE, which fixed some problems. But now I feel
current setting, the one I mentioned at the first section of this note,
awesome.&lt;/p&gt;
</description>
        <pubDate>Wed, 06 Jan 2016 08:16:00 +0800</pubDate>
        <link>http://shawnLeeZX.github.io/blog/2016/01/06/setting-up-multi-monitor-on-gnome-ubuntu-14-dot-04-with-nvidia-card/</link>
        <guid isPermaLink="true">http://shawnLeeZX.github.io/blog/2016/01/06/setting-up-multi-monitor-on-gnome-ubuntu-14-dot-04-with-nvidia-card/</guid>
        
        
        <category>Note</category>
        
        <category>Gnome</category>
        
        <category>Linux</category>
        
        <category>CS</category>
        
      </item>
    
      <item>
        <title>On Environment Variable Setup of Linux</title>
        <description>&lt;p&gt;I have spent some time figuring out how Linux sets up its environment variables
for login shell, non-login shell to let Emacs inherits environment variables
and make tmux loads &lt;code class=&quot;highlighter-rouge&quot;&gt;.bashrc&lt;/code&gt; and note it here.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h2 id=&quot;login-shell&quot;&gt;Login Shell&lt;/h2&gt;

&lt;p&gt;We start by figuring out the boot process.&lt;/p&gt;

&lt;p&gt;For text console,&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;At the end of boot the mother of all processes &lt;code class=&quot;highlighter-rouge&quot;&gt;init&lt;/code&gt; is started. init’s
environment, including PATH, is defined in its source code and cannot be
changed at run time.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;init&lt;/code&gt; runs the start-up scripts from &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/init.d&lt;/code&gt; depending on the run level
set in &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/inittab&lt;/code&gt;. Since init’s environment is very bare, the scripts
define their required environment variables within themselves.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;init&lt;/code&gt; starts the text login process that waits for the user to log in. When
the user logs in, the login process checks &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/passwd&lt;/code&gt; to see what shell
should be started for this particular user.&lt;/li&gt;
  &lt;li&gt;The shell starts and reads its shell-specific configuration files.
    &lt;ol&gt;
      &lt;li&gt;For Bash, it first reads &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/profile&lt;/code&gt; to get values that are defined
for all users. After reading that file, it looks for &lt;code class=&quot;highlighter-rouge&quot;&gt;~/.bash_profile&lt;/code&gt;,
&lt;code class=&quot;highlighter-rouge&quot;&gt;~/.bash_login&lt;/code&gt;, and &lt;code class=&quot;highlighter-rouge&quot;&gt;~/.profile&lt;/code&gt;, in that order, and reads and executes
commands from the first of these files that exists and is readable.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For graphical UI,&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;At the end of booting, the mother of all processes – &lt;code class=&quot;highlighter-rouge&quot;&gt;init&lt;/code&gt; – is started.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;init&lt;/code&gt; runs the start-up scripts from &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/init.d&lt;/code&gt; depending on the run
level set in &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/inittab&lt;/code&gt;. Since &lt;code class=&quot;highlighter-rouge&quot;&gt;init&lt;/code&gt;’s environment is very bare, the
scripts define required environment variables within themselves.&lt;/li&gt;
  &lt;li&gt;Init starts the GDM display manager, which in turn will start the graphical
login.&lt;/li&gt;
  &lt;li&gt;When the user successfully logs in, GDM starts xsession, which reads the
file &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/gdm/Xsession&lt;/code&gt; and with it the environment variables for the
user’s session. The default version of the Xsession file first reads
&lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/profile&lt;/code&gt; for global settings and then &lt;code class=&quot;highlighter-rouge&quot;&gt;~/.profile&lt;/code&gt; to add the user’s
individual settings.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The above boot process is the process to set up environment to login shell. So
if any user specific environment that is need for a graphical program, one
could choose to put it in &lt;code class=&quot;highlighter-rouge&quot;&gt;~/.bash_profile&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;~/.bash_login&lt;/code&gt;, and
&lt;code class=&quot;highlighter-rouge&quot;&gt;~/.profile&lt;/code&gt;. I chose to put it in &lt;code class=&quot;highlighter-rouge&quot;&gt;.profile&lt;/code&gt;. I actually spent time figuring
this out, so Emacs could inherit environment variables the local libraries I
installed.&lt;/p&gt;

&lt;p&gt;As for system wide setup, put it in &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/profile&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;non-login-shell&quot;&gt;Non-login Shell&lt;/h2&gt;

&lt;p&gt;If a shell is needed after login, the setting should go to the non-login
shell’s, &lt;code class=&quot;highlighter-rouge&quot;&gt;.bashrc&lt;/code&gt;. For instance, the terminals created by &lt;code class=&quot;highlighter-rouge&quot;&gt;terminal&lt;/code&gt;,
&lt;code class=&quot;highlighter-rouge&quot;&gt;terminator&lt;/code&gt; and other terminal programs are non-login shells. This is where I
previously put all my configurations in.&lt;/p&gt;

&lt;p&gt;The following comes from &lt;code class=&quot;highlighter-rouge&quot;&gt;man bash&lt;/code&gt;’s &lt;em&gt;INVOCATION&lt;/em&gt; section.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;When bash is invoked as an interactive login shell, or as a non-interactive
shell with the `--login` option, it first reads and executes commands from the
file `/etc/profile`, if that file exists.  After reading that file, it looks
for `~/.bash_profile`, `~/.bash_login`, and `~/.profile`, in that order, and
reads and executes commands from the first one that exists and is readable.
The --noprofile option may be used when the shell is started to inhibit this
behavior.

When a login shell exits, bash reads and executes commands from the file
`~/.bash_logout`, if it exists.

When an interactive shell that is not a login shell is started, bash reads and
executes commands from `/etc/bash.bashrc` and `~/.bashrc`, if these files
exist.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;distribution&quot;&gt;Distribution&lt;/h2&gt;

&lt;p&gt;Each Linux distribution may tweak files mentioned above, for instance, unset
some variables somewhere, so if you set its value before where it is unset,
your setting will not take effect. Normally, if one’s configuration does not
work, consider go through all previous configurations and understand what they
exactly do in such a distribution.&lt;/p&gt;

&lt;h2 id=&quot;misc&quot;&gt;Misc&lt;/h2&gt;

&lt;p&gt;If one uses &lt;code class=&quot;highlighter-rouge&quot;&gt;tmux&lt;/code&gt;, the terminal multiplexer, note it creates login shells. So
if one wants &lt;code class=&quot;highlighter-rouge&quot;&gt;.bashrc&lt;/code&gt;, especially aliases, to work under &lt;code class=&quot;highlighter-rouge&quot;&gt;tmux&lt;/code&gt;, remember to
source it after whatever login shell configuration one may use.&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;https://wiki.debian.org/EnvironmentVariables&lt;/li&gt;
  &lt;li&gt;https://help.ubuntu.com/community/EnvironmentVariables&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Tue, 05 Jan 2016 11:28:00 +0800</pubDate>
        <link>http://shawnLeeZX.github.io/blog/2016/01/05/on-environment-variable-setup-of-linux/</link>
        <guid isPermaLink="true">http://shawnLeeZX.github.io/blog/2016/01/05/on-environment-variable-setup-of-linux/</guid>
        
        
        <category>Note</category>
        
        <category>Linux</category>
        
      </item>
    
      <item>
        <title>Optimization Summary</title>
        <description>&lt;p&gt;Yet another note on Math.&lt;/p&gt;

&lt;p&gt;The semester’s course on Optimization is going to end. This is a summary note
to unify the mathematical picture learned during this period.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h2 id=&quot;problem-formulation&quot;&gt;Problem Formulation&lt;/h2&gt;

&lt;p&gt;In the most general form, an optimization problem is to find an extreme value,
taking minimum for ease of writing, in the following form&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\min\ f(X)\\
G(X) \succeq \theta\\
H(X) = \theta&lt;/script&gt;

&lt;p&gt;where $X$ could be a scalar, vector or matrix; $G(X)$ is a stack of inequality
constrains, whose row is one inequality constrain; $\theta$ is zero vector;
$H(X)$ is a stack of equality constrains, whose row is one equality constrain.&lt;/p&gt;

&lt;p&gt;To solve the above problem, analysis should be made to properties of $f(X),
G(X)$ and $H(X)$. Geometric intuition is the source of aspiration and algebraic
descriptions or relaxation of geometric intuition is how we could solve the
problem.&lt;/p&gt;

&lt;p&gt;The geometric picture of $f(X)$ is contour of its value, whose metaphor is the
contour of the height of a mountain; or just the mountain by seeing how high
its. The first picture is in the domain of $X$, while the second one is in the
$(X, f(X))$, which adds another dimension.&lt;/p&gt;

&lt;p&gt;$G(X)$ and $H(X)$ explicitly or implicitly define an sub-area of all possible
$X$. Its picture is harder to visualize, and is the difficulty aspects in
optimization.&lt;/p&gt;

&lt;h2 id=&quot;domain-type&quot;&gt;Domain Type&lt;/h2&gt;

&lt;p&gt;Different types of variables has different structure and properties that
enforced on the domain. As an example, Conic Linear Programming is to explore
the structureness to simplify problems.&lt;/p&gt;

&lt;p&gt;It does not occur to me clearly for now how possibly the enforced peculiar
structure of Semi-definite programming or Second Order Cone Programming could
have physical meaning. But SDP how take advantage of matrix variable and
inequality is inspiring.&lt;/p&gt;

&lt;h2 id=&quot;geometry-of-domain&quot;&gt;Geometry of Domain&lt;/h2&gt;

&lt;p&gt;The work around is to assume only to solve problems who is convex, and call the
remaining problems non-convex, consequently classifying it as hard.&lt;/p&gt;

&lt;p&gt;It seems this is rather a restrict and side step the difficult but important
problems. This was the perception I had when I first heard about Optimization
years ago. But the actually it is not after really struggling through it.&lt;/p&gt;

&lt;p&gt;Convexity of a set is the atom to describe geometry of the whole set in the
following sense: if two points are in the set, then we want any points between
them are also in the set. Normally, points have some physical meaning in real
world problem, not some bizarre mathematical fabrication. In physical world,
extremity breaks thing, but not their intermediate value. Thus it is a good
model unless we discover some bizarre phenomena(which probably already exists
but I do not know).&lt;/p&gt;

&lt;p&gt;Convexity and concavity of function are the only two ways how function could
vary locally. The really mattered properties of convexity is non-decreasing, so
concavity is non-increasing. They get named quasa-convex for convexity part.&lt;/p&gt;

&lt;p&gt;If we could analyzed the atoms how sets compose a bigger set and how functions
composes a ``larger’’ function, we begin to get a look into the whole picture.&lt;/p&gt;

&lt;p&gt;Current situation of optimization is local geometry has been well studied, but
a way to generalize to the global geometry lacks. So I guess it is not the
a good understanding of convexity is the first step to understand more complex
problems.&lt;/p&gt;

&lt;h2 id=&quot;dimensionality-of-domain&quot;&gt;Dimensionality of Domain&lt;/h2&gt;

&lt;p&gt;This section is about the concept of &lt;em&gt;affine&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;The motivation of ``affine’’ is to create a term that could be used to describe
the dimension of domain. So essentially, an affine set is linear variety or the
whole space. Linear variety is a concept. For example, a linear variety in 3D
space would be a line, a plane.&lt;/p&gt;

&lt;h2 id=&quot;unifying-optimization-duality-with-functional-analysis&quot;&gt;Unifying Optimization Duality with Functional Analysis&lt;/h2&gt;

&lt;p&gt;If we start from a Linear Programming(LP), which is the following problem&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\min\ c^{T}x\\
Ax = b
x \geq 0&lt;/script&gt;

&lt;p&gt;and its dual&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\max\ b^{T}y\\
A^{T}y \leq c&lt;/script&gt;

&lt;p&gt;From function analysis point of view, those two problems involves four space,
space of $x$(we call it primal space for convenience from now), dual space of
primal space, space of $y$(we call it transformed space from now), dual space
of transformed space. Duality of LP is the characterization of relationship
between those four spaces.&lt;/p&gt;

&lt;p&gt;If we upgrade this view to non-linear case,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\min\ f(X)\\
G(X) \succeq \theta\\
H(X) = \theta&lt;/script&gt;

&lt;p&gt;we see $G(X)$ and $H(X)$ are also a transform, but not linear. But similar idea
should also apply. This is the idea of Lagrange multiplier and Lagrange
duality.&lt;/p&gt;

&lt;p&gt;The idea is to analyze in the transformed space $(f(X), Z)$, where $Z$ is the
whose variables are $G(X), H(X)$(in proof involved with Lagrange duality, we
break $H(X)$ to two inequalities). $Z$ and its dual &lt;script type=&quot;math/tex&quot;&gt;Z^{*}&lt;/script&gt; centralize all
duality in optimization.&lt;/p&gt;

&lt;p&gt;The hard part is to analyze what the space $Z$ is like. First, different types
of variables have different properties and work with different inequalities,
such as vector and vector inequality, matrix and matrix inequality. Second,
what the transformed space is like after mapping is hard to deal with.&lt;/p&gt;

&lt;p&gt;The key properties of $Z$ is whether it has an interior point and is convex,
which determines whether we could find a separating hyperplane, an element in
dual space.&lt;/p&gt;

&lt;p&gt;Farkas lemma is just a special case where we could explicitly know what the
transformed space looks like.&lt;/p&gt;

&lt;h2 id=&quot;on-cone-and-dual-cone&quot;&gt;On Cone and Dual Cone&lt;/h2&gt;

&lt;p&gt;This section is about cone and dual cone. One more example could be seen in the
next section.&lt;/p&gt;

&lt;p&gt;Cone is about direction. It is hard to describe it informally without concrete
examples. Pointed cone identifies inequality relations, which is summarized in
this &lt;a href=&quot;/blog/2015/11/28/cone-dual-cone-and-generalized-inequalities/&quot;&gt;note&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Dual cone is about the direction that at least slightly the same with primal
cone, so in this direction values also could increase, or decrease if it is a
negative dual cone. Dual cone is a set in dual space of primal space, whose
elements are normals of hyperplane. Remember a normal of a hyperplane is about
the direction where the values goes up(or down depending on definition).&lt;/p&gt;

&lt;h2 id=&quot;variational-idea-kkt-condition-fritz-john-condition&quot;&gt;Variational Idea, KKT Condition, Fritz-John Condition&lt;/h2&gt;

&lt;p&gt;Existence of Lagrange multiplier is the zero order properties of a constrained
optimal point. By considering the first derivative, we could get how gradients
at the optimal point are related to each other.&lt;/p&gt;

&lt;p&gt;Equality constrain in the limit is to carve subspace out, so all things should
happen in this subspace. Gradients of inequality constrains determine whether
the we could still have descent directions, which is Fritz-John or KKT
condition. The idea is if negative dual cone of positive range of gradients of
inequality constrains do not intersect with negative dual cone of $\nabla
f(x)$, then we reach a constrained minimum. The regularity conditions of KKT
just means the gradients of inequality constrains do not conflict with each
other, which if happens would only leave a feasible set that has nothing to do
with $f(x)$, which is the case the dual variable associated with $\nabla f(x)$
is zero in Fritz-John optimality condition.&lt;/p&gt;

&lt;h2 id=&quot;optimization-algorithms&quot;&gt;Optimization Algorithms&lt;/h2&gt;

&lt;p&gt;Few has been explored in this area for now.&lt;/p&gt;

&lt;p&gt;The idea is to explore the structures of the four spaces mentioned, and the
target function to find the extreme values and corresponding solutions, either
globally, for instance using the simplex method, or locally, using gradient
based methods.&lt;/p&gt;
</description>
        <pubDate>Wed, 16 Dec 2015 15:06:00 +0800</pubDate>
        <link>http://shawnLeeZX.github.io/blog/2015/12/16/optimization-summary/</link>
        <guid isPermaLink="true">http://shawnLeeZX.github.io/blog/2015/12/16/optimization-summary/</guid>
        
        
        <category>Optimization</category>
        
        <category>Note</category>
        
        <category>Math</category>
        
      </item>
    
  </channel>
</rss>
