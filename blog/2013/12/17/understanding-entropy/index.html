<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta content="Shawn" property="og:site_name">
  <link href="/favicon.png" rel="icon">

  
  <meta content="Understanding Entropy(Shannon)" property="og:title">
  

  
  <meta content="article" property="og:type">
  

  
  <meta content="<h1>Children of The Sun</h1>" property="og:description">
  

  
  <meta content="http://shawnLeeZX.github.io/blog/2013/12/17/understanding-entropy/" property="og:url">
  

  
  <meta content="2013-12-17T09:09:00+08:00" property="article:published_time">
  <meta content="http://shawnLeeZX.github.io/about/" property="article:author">
  

  <meta property="og:image" content="">

  
  
  <meta content="Math" property="article:section">
  
  

  
  
  

  <title>Understanding Entropy(Shannon) - Shawn</title>
  <meta name="description" content="The original intuitive is the smaller the probability one event may happen, themore its uncertainty is. This make sense. It converts the unmeasurable into th...">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.2.2/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>
  <link rel="stylesheet" href="/css/main.css">
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>

  <!-- Typesetting math using MathJax -->
  <!-- mathjax config similar to math.stackexchange -->
  <script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     jax: ["input/TeX", "output/HTML-CSS"],
     tex2jax: {
       inlineMath: [ ['$', '$'] ],
       displayMath: [ ['$$', '$$']],
       processEscapes: true,
       skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
     },
     messageStyle: "none",
     "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
   });
  </script>
  <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-44220731-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>

  <link href='https://fonts.googleapis.com/css?family=PT+Sans' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Fira+Mono' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Source+Code+Pro:400,200,300,500,600,700,900' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Gentium+Basic:400,700' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Alegreya:400,400italic,700' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Lora:400,400italic,700' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Fira+Sans:400,300,500,700' rel='stylesheet' type='text/css'>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.2.0/jquery.min.js"></script>
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.1/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-hQpvDQiCJaD2H465dQfA717v7lu5qHWtDbWNPvaTJ0ID5xnPUlVXnKzq7b8YUkbN" crossorigin="anonymous">
  <link rel="canonical" href="http://shawnLeeZX.github.io/blog/2013/12/17/understanding-entropy/">
  <link rel="alternate" type="application/rss+xml" title="Shawn" href="http://shawnLeeZX.github.io/feed.xml">
</head>

  <body>
    <section>
<nav class="navbar navbar-default navbar-fixed-top">

  <div class="container">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="/">Shawn</a>
    </div>


    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
      <ul class="nav navbar-nav navbar-right">
        <li><a href="/about">About</a></li>
        <li><a href="/blog">Blog</a></li>
        <li><a href="/blog/archives">Archive</a></li>
      </ul>

    </div><!-- /.navbar-collapse -->
  </div><!-- /.container-fluid -->
</nav>
</section>

    <section>
      <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <div class="jumbotron">
    <div class="container">
      <h1 class="page-title" itemprop="name headline">Understanding Entropy(Shannon)</h1>
      <p class="post-meta"><time datetime="2013-12-17T09:09:00+08:00" itemprop="datePublished">Dec 17, 2013</time></p>
    </div>

</div>


  <div class="post-content container" itemprop="articleBody">
    <p>The original intuitive is the smaller the probability one event may happen, the
more its uncertainty is. This make sense. It converts the unmeasurable into the
measurable.</p>

<p>Now the problem becomes what is the relation between the probability of events
and the overall uncertainty of the state?</p>

<p>One state may contain several events, which each of them have their own
probability to happen. Using the terminology from Thermodynamics, one
microstates could consist of a number of states. Returning back to the
probability, it means one state contains a number of events. To take into
account the weight of different events, the probabilities are used.</p>

<!-- more -->

<p>See the $p_i$ in: $entropy = \Sigma(p_i * log(p_i))$</p>

<p>Now, the weight part has done, how can we measure uncertainty?</p>

<p>In the book <em>Warmth Disperses and Time Passes</em>, page 106, writen by Hans
Christian Von Baeyers:</p>

<blockquote>
  <p>Whenever you multiply two integers, the numbers of their respective
digits add.</p>

  <p>eg: 60 x 600 = 36,000</p>

  <p>so two digits plus three digits equals five digits (the rule
sometimes misses by one digit, as in 3x3 = 9, but that’s a
negligible error in view of the vastness of the number of molecules
in a gas.)</p>

  <p>So Boltzmann made the bold, inspired guess that entropy equals the
number of digits of the corresponding probability</p>
</blockquote>

<p>I have not read this book. The material comes from this
<a href="http://ask.metafilter.com/128814/Help-me-Understand-Boltzmanns-entropy-formula-S-k-log-W">url</a>.</p>

<p>So, this solved my long puzzled question why log is used. We have to
think of a way to measure the uncertainty in one event. And such
measurement should be mathematically correct. That means, it should
satisfy several criteria(and obviously I do not know exactly what are
them all):</p>

<ol>
  <li>If only one event is contained in the state, the entropy should be 0.</li>
  <li>If all events happen equally, the entropy should be maximum.</li>
  <li>…</li>
</ol>

<p>Logarithm does a great job. But what is the theory underlying it? Keep
reading.</p>

<h2 id="another-example">Another Example</h2>

<p>I also tried to understand entropy from encoding perspecitive, by
comparing average encoding length(AEL) with entropy.</p>

<p>The AEL is computed as following:</p>

<p>$AEL = \Sigma(p_i * l_i)$</p>

<p>Where $P_i$ stands for the probability of one information $i$(can be
string, etc.) being chosen, and $l_i$ stands for the length of the
encoding of the information.</p>

<p>In this equation, $l_i$ is semantically similar to the corresponding
$log(p_i)$ part of the Shannon entropy.</p>

<p>Huffman encoding is a perfect example combine encoding with
entropy(The detail of Huffman encoding is omitted).</p>

<p>The main intuitive is the longer the encoding of one information, the
smaller the probability it may happen. The smaller the AEL of one
encoding method is, the better, meaning less chaotic, it is.</p>

<p>Combined with the AEL formula above, the length of the encoding of one
information is actually similar to the number of digitals the
probability have.  And, this connects the dots.</p>

<p>you can get the pdf version
<a href="https://github.com/hhiker/ml_math/blob/master/information_theory/understanding_entropy/understanding_entropy.pdf">here</a>.</p>

<h2 id="a-more-concrete-example">A More Concrete Example</h2>

<p>Updated on Feb 23, 2016</p>

<p>In the above passages, entropy is interpreted in term of assumption in
statistical mechanics, good mathematical properties and minimum coding
length. Though mathematical satisfying, it still feels like circumventing the
core of the problem.</p>

<p>Following the above arguments, information models how unexpected a event
occurs. To concretize the such a statement, I try to formulate a concrete event
and in what sense we define unexpected. The example below seems to come from my
own imagination, but some vague memory tells me I have seen similar example
somewhere else that inspires this, though I do not remember exactly where.</p>

<p>Suppose we want to search for something a large room. What is the best way to
search for that thing? A natural answer is to divide the room into equally
space grid, such as</p>

<div class="language-bash highlighter-rouge"><pre class="highlight"><code>
+-----+-----+-----+-----+
|a    |     |a    |     |
|thing|     |thing|     |
+-----+-----+-----+-----+

</code></pre>
</div>

<p>Then search for the thing one by one. Each grid above could be taken as a event
space in the overall event space, which is the whole room. To search for
something, first we need to give candidates labels to distinguish them. How
possibly could we assign them labels? So if the thing is in half of those
grids, one only need to one bit, $log(\frac{1}{1/2})$, for the label to contain
enough information, meaning certain grid has the thing or not. So that is where
$log$ comes around: in an exponential configuration of labels, what is the
minimum set of labels that contain all the information. In another terminology,
it is coding.</p>

  </div>

</article>

    </section>

    
    <div class="container">
      <section>
        <h1>Comments</h1>
        <div id="disqus_thread" aria-live="polite"><script type="text/javascript">
      var disqus_shortname = 'nautilus-shell-of-hhiker';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://shawnLeeZX.github.io/blog/2013/12/17/understanding-entropy/';
        var disqus_url = 'http://shawnLeeZX.github.io/blog/2013/12/17/understanding-entropy/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div>
      </section>
    </div>
    

    <!-- <nav class="navbar navbar-default navbar-fixed-bottom"> -->
<!-- <div class="container footer-content"> -->
    <!-- Nothing is there. -->
<!-- </div> -->
<!-- </nav> -->
  </body>

</html>
