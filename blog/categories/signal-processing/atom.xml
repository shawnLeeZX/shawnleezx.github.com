<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Signal_Processing | SHAWN LEE]]></title>
  <link href="http://shawnLeeZX.github.io/blog/categories/signal-processing/atom.xml" rel="self"/>
  <link href="http://shawnLeeZX.github.io/"/>
  <updated>2016-08-30T12:51:12+08:00</updated>
  <id>http://shawnLeeZX.github.io/</id>
  <author>
    <name><![CDATA[Shawn]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Connection between PCA and Fourier Transform]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/06/05/connection-between-pca/"/>
    <updated>2015-06-05T21:10:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/06/05/connection-between-pca</id>
    <content type="html"><![CDATA[<!-- more -->

<p>When we are running PCA on images, the first principle component we get is
normally looks like the DC term, which is the first Fourier bases of
images. After some analysis, I found that this makes a lot of sense.</p>

<p>We could unify PCA and Fourier Transform from filter bank or linear operator
point of view. Actually those two point of views are just different way to say
the same thing in signal processing and mathematics.</p>

<p>From filter bank point of view, the process of getting the PCA coefficients and
Fourier coefficients could be regarded as passing the original signal to a
Linear Time Invariant system. Each Fourier basis or eigenvector is a
filter. All of them make up the filter bank.</p>

<p>From linear operator point of view, such process could be taken as an operator
to project the point in one space to another space.</p>

<p>It turns out that Fourier basis $e^{i\omega t}$ and eigenvector $v$ of covariance
matrix are both eigenvector(this eigenvector is not specific to the eigenvector
computed from covariance matrix of the data) of the LTI system.</p>

<p>The Fourier basis eigenvectors could be taken as the eigenvector of covariance
of all possible images that could be formed by spatial complex exponential
signal. So it is fixed. As for the data driven eigenvector $v$, it is only the
eigenvector of that amount of data. They are both orthogonal with other
eigenvectors within their sets. If data driven eigenvector get normalized, it
has unit norm as well.</p>

<p>This could explain why the first principal components of covariance looks a lot
similar do the first Fourier basis. Because DC term of images affect all
pixels, naming all dimensions. So its variance is the largest, which makes it
similar with first fourier basis. I think similar argument could be made to
other principal components and Fourier bases as well. But they may be less
obvious then the first one.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Understanding Convolution]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2014/11/08/understanding-convolution/"/>
    <updated>2014-11-08T09:46:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2014/11/08/understanding-convolution</id>
    <content type="html"><![CDATA[<p>One dimension convolution(I am not sure I have understand two
dimension yet) may be a very natural idea when you are from Electrical
Engineering(EE) background – I found out this recently by reading
books about signals and system, especially for the one written by
Oppenheim(thought as I was talking with PhD from EE background, some
of them does not understand convolution.). But as a computer science
major background with no prior exposure to EE, it does not seem to be
that natural.</p>

<p>This post aims to introduce convolution from scratch.</p>

<p>Convolution roots from signal processing, mainly in Linear Time
Invariant(LTI) System. Convolution will be introduced in this
setting. Then the intuition will be explained, both in its physical
interpretation and computation procedure. Just note here that, as its
widely usage on various forms of application, it is generalized by
mathematicians, who make it a mathematical operation like correlation,
which loses its original physical Interpretation(this is where the
most confusion comes around the first time I encounter such a
concept).</p>

<!-- more -->

<h2 id="linear-time-invariant-system">Linear Time Invariant System</h2>

<p>Let’s start with LTI system.</p>

<h3 id="definition">Definition</h3>

<p>A time-invariant (TIV) system is a system whose output does not depend
explicitly on time.</p>

<p>If the input signal $x(t)$ produces an output $y(t)$ then any time
shifted input, $x(t + \delta)$, results in a time-shifted output
$y(t + \delta)$</p>

<h3 id="example">Example</h3>

<p>To demonstrate how to determine if a system is time-invariant then
consider the two systems:</p>

<p>System A: $y(t) = t x(t)$</p>

<p>System B: $y(t) = 10 x(t)$</p>

<p>Since system A explicitly depends on t outside of $x(t)$ and $y(t)$,
it is not time-invariant.  System B, however, does not depend
explicitly on t so it is time-invariant.</p>

<h3 id="intuition">Intuition</h3>

<p>The intuition behind is the system is stable as the time passes. For
instance, if we take an example from thermology, the temperature of
the system is constant which makes a number of other properties stable.</p>

<p>The explanation above is nothing different from what you could look up
in wikipedia. With my experience of teaching myself mathematics, you
never see a concept naturally, meaning you internalize it by reading
its definition, until knowing why it is brought out by reading its
history and trying to solve the old problem by yourself.</p>

<p>For LTI system, I point out two points here:</p>

<ol>
  <li>Initial rest linear differential equation, which is abundant in
circuit theory, is LTI system, which makes LTI widely applicable.</li>
  <li>It seems that the only mathematics humanity is capable of is linear
stuff. So it is through linear decomposition and recombination that
make problem manageable, at least in the preliminary development
state of one subject. So understanding LTI system should be the
first step before trying to understanding other nonlinear complex
system.</li>
</ol>

<h3 id="reference">Reference</h3>
<p>Timer-invariant System, Wikipedia,
<a href="http://en.wikipedia.org/wiki/Time-invariant_system">link</a></p>

<h2 id="origin-of-convolution-in-linear-time-invariant-system">Origin of Convolution in Linear Time Invariant System</h2>

<h3 id="prologue">Prologue</h3>

<p>Since this post is going to explain convolution, let us how the
assumption of LTI system could lead to convolution.</p>

<p>Generally, this could lead to the effort to find a basis in Hilbert
Space to represent signals(I am still learning about this, and not
going to talk about it). Now, we decompose signals using
impulse(terminology in discrete time) and delta function(terminology
in continuous time) – they actually form a set of basis.</p>

<p>For the sake of brevity, I will stay with discrete case. For
continuous case they are almost the same as long as your replace the
summation symbol with integration symbol.</p>

<p>And… I am not going to define unit impulse, since there is some
complication in its mathematical definition. It is easy to get its
intuition, if not rigorous mathematical definition by Googling.</p>

<h3 id="convolution-in-lti-system">Convolution in LTI system</h3>
<p>So how could we decompose signals using unit impulse?</p>

<p>In fact, if the response of the LTI system to the unit sample sequence
$\delta(n)$ is denoted as $h(n)$, that is,</p>

<script type="math/tex; mode=display">
h(n) \equiv \Gamma [\delta(n)]
</script>

<p>then by the time-invariance property, the response of the system to the
delayed unit sample sequence $\delta(n - k)$ is</p>

<script type="math/tex; mode=display">
h(n - k) = \Gamma[\delta(n - k)]
</script>

<p>Thus, if we decompose the input signal $x(n)$ into a series of signals
$x(k), k = 1,2 …$, with each $x(k) = x(n)\delta(n - k)$, then the output of any input signal $x(n)$ could be
computed in the following way:</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{align*}
y(n) &=& \Gamma[\sum\limits^{\infty}_{k=-\infty}x(k)\delta(n - k)]\\
     &=& \sum\limits^{\infty}_{k=-\infty}x(k)\Gamma[\delta(n - k)]\\
     &=& \sum\limits^{\infty}_{k=-\infty}x(k)h(n - k)
\end{align*}
 %]]&gt;</script>

<p>This is what originally convolution is all about.</p>

<h3 id="physical-interpretation">Physical Interpretation</h3>
<p>What is actually happening?</p>

<p>Before proceeding to the following content, it would be better find
some convolution examples to try it out by oneself(which is actually
required, since this is how math is learned – you remember the
understanding acquired when you are actually computing), which will
make the understanding better and solider. The example I recommend is
in reference 1.</p>

<p>The main intuition in the time series scenario will be explained.</p>

<p>For a system, the state in previous state will always interfere with
current state. Just think of the system in real world will give this
statement a lot of sense. In real world, the state of one system will
always be continuous. The input signal $x(t)$ will always interfere
with signal $x(t - \epsilon)$. So if we decompose signals in to
impulse like previous section, the signal in previous impulse will
interfere with current impulse.</p>

<p>Take the example in reference 1 as an example. In the original
example, the response of unit impulse is $h(n) = (1, 2, 1, -1)$,
corresponding to $n = (-1, 0, 1, 2)$. We interpret the $n$ here as
discrete time point. The negative coordinate of $n$ here actually
means how the unit impulse interfere with previous signals. As for
input signal $x(n) = (1, 2, 3, 1)$ corresponding to $n = (0, 1, 2,
3)$, we regard it as discrete impulse in those discrete time
points. To compute response $y(0)$, which we interpret it as the
response in time point 0, we have the following equations, which is
convolution:</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{align*}
y(0) &=& \sum\limits^{\infty}_{k=-\infty}x(k)h(0 - k)\\
     &=& \sum\limits^{3}_{k=0}x(k)h(0 - k)
\end{align*}
 %]]&gt;</script>

<p>When $k = 1$, we can see how the impulse in time point 1 interfere
with the one in time point 0. Work this example by yourself to see
more about it.</p>

<p><em>NOTE</em>: The inspiration of this example comes from a similar example
in reference 2.</p>

<h3 id="convolution-in-its-computation-procedure">Convolution in its computation procedure</h3>
<p>Let us step further to the computation procedure of convolution,
which is the where the most confusion lies while I was learning.</p>

<p>It is said that the procedure comes as following:</p>

<ol>
  <li><strong>Folding</strong>. Fold h(k) about $k = 0$ to obtain $h(-k)$.</li>
  <li><strong>Shifting</strong>. Shift $h(-k)$ by $n_{0}$ to the right(left) if $n_{0}$
is positive(negative), to obtain $h(n_{0} - k)$.</li>
  <li><strong>Multiplication</strong>. Multiply $x(k)$ by $h(n_{0} - k)$ to obtain the
product sequence $v_{n_{0}} \equiv x(k)h(n_{0} - k)$.</li>
  <li><strong>Summation</strong>. Sum all the values of the product sequence $v_{n_{0}}$
to obtain the value of the output at tie $n = n_{0}$.</li>
</ol>

<p>Note that this procedure results in the response of the system at a
single time instant, say $n = n_{0}$. In general, we are interested in
evaluating the response of the system over all time instants $-\infty
\leq n \leq \infty$. Consequently, steps 2 through 4 in the summary must
be repeated, for all possible time shifts $-\infty \leq n \leq \infty$.</p>

<p>As you may confuse as I the first time you see this computation
procedure. In this procedure, you actually do not use the physical
Interpretation, but use only its formula.</p>

<p>Why are we doing folding? Why shifting? Why …?</p>

<p>How I try to understand the procedure will be elaborated. In one word,
it is rather intuitive way for computation than reflecting its
physical meaning. To see this, let us return back to its original
invention introduced in previous section.</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{align*}
y(n) &=& \sum\limits^{\infty}_{k=-\infty}x(k)h(n - k)\\
\end{align*}
 %]]&gt;</script>

<p>Take some terms out, for instance, $x[n-0]h[0]$ and $x[n-1]h[1]$, try
to visualize in a graph of sequence with $x[n]$ in the above and
$h[n]$ below. For the signal $x[n]$ in this instant, it should be
multiplied by $h[n]$. For the signal that is one step earlier, its delay
should be propogate to now with the strength $h[1]$. This procedure
keeps going until you finish the computation for $y[n]$.</p>

<p>So convolution in mathematics is just cross multiplication. Thinking
of correlation between two sequences may ring a bell.</p>

<p>But how could this link to the computation procedure mentioned above?</p>

<p>To find out, do the actual computation of this cross
multiplication. It is a little not that intuitive to compute.</p>

<p>Now, return back to computation procedure. Try to visualize the
procedure in graph. There are famous graphical illustrations. Try
find an example if you do not know what I about talking about by
Googling or going for the reference I list. I not writing a textbook
so I am not going to extract it and post is here…</p>

<p>Assuming you have known the graphical illustration of the computation
procedure, ask yourself the question if you do not care about the
physical interpretation underlying, IS IT INTUITIVE TO COMPUTE?</p>

<p>The answer for me is yes.</p>

<p>This is all the computation procedure all about – finding a way to
intuitively do the computation.</p>

<h3 id="reference-1">Reference</h3>
<ol>
  <li>Chapter 2.3, mainly Page 74 - 75, Digital signal processing  principles, algorithms, and applications,</li>
  <li>Chapter 2.4 Linear Systems and Signals, 2nd Edition - B.P. Lathi</li>
  <li>Correlation and Convolution Class Notes for CMSC 426, Fall 2005 David Jacobs</li>
  <li>Signals and Systems 2nd Edition, by Oppendiem </li>
</ol>

<h2 id="convolution-in-its-mathematical-sense">Convolution in its mathematical sense</h2>
<p>As a final note, convolution is generalized as a mathematical
operation just as correlation outside LTI system. It would be more
helpful to think it as a mathematical transformation than always try
to figure out its physical interpretation. Thinking of eigenvalue may
ring a bell.</p>
]]></content>
  </entry>
  
</feed>
