<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: CS | SHAWN LEE]]></title>
  <link href="http://shawnLeeZX.github.io/blog/categories/cs/atom.xml" rel="self"/>
  <link href="http://shawnLeeZX.github.io/"/>
  <updated>2016-03-15T11:40:00+08:00</updated>
  <id>http://shawnLeeZX.github.io/</id>
  <author>
    <name><![CDATA[Shawn]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[A Quick Survey on Distributed Log Processing: Unison and Logstash]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2016/03/15/a-quick-survey-on-log-processing/"/>
    <updated>2016-03-15T10:53:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2016/03/15/a-quick-survey-on-log-processing</id>
    <content type="html"><![CDATA[<p>Having multiple machines to train neural networks, I was trying to think how
could I automatically gather all the training logs, so I could analyze them in
one place.</p>

<p>I did a survey on technologies available. The ones that I found are: <code>Logstash</code>
and <code>unison</code>. <code>Logstash</code> seems to be the optimal solution, though may be a little
an overkill. However, I settled to use <code>unison</code> in the end. The rationale
behind this is I have to get around many VPNs. The VPNs I used, or maybe most
VPNs setups, won’t let the machines in LAN of the VPN network ping back to the
machine that uses VPN to connect. It may just not come from a security reason,
though it could be; it may just because it is not necessary to set up the route
table to the IP addresses allocated to the connecting machine. So in this case,
the log cannot be sent back to the connecting machine, as the way <code>Logstash</code>
does. A solution is needed to initialize the centralization from the connect
machine site. So <code>Logstash</code> is ruled out, and I settled with <code>unison</code>.</p>

<p>The following is a quick note on <code>unison</code> works, which took me a while to
figure out. For an practical introduction to <code>Logstash</code>, see the
<a href="http://www.slashroot.in/logstash-tutorial-linux-central-logging-server">tutorial</a>
here.</p>

<!-- more -->

<h2 id="introductory-note">Introductory Note</h2>

<p><a href="http://www.cis.upenn.edu/~bcpierce/unison/download/releases/stable/unison-manual.html#basics">Unison</a>
is a file-synchronization tool for Unix and Windows. It allows two replicas of
a collection of files and directories to be stored on different hosts (or
different disks on the same host), modified separately, and then brought up to
date by propagating the changes in each replica to the other.</p>

<p><code>Unison</code> supports transmission via <code>ssh</code>, <code>socket</code>, <code>file</code> and <code>rsh</code>. Each of
those protocols has its own setups, except for the <code>file</code> protocol — it
synchronizes files within the single machine. For instance, to use ssh, the two
machines to be able to ssh to each other.</p>

<p>The way <code>unison</code> is used is similar with <code>scp</code> or <code>cp</code> in the sense that they
are all a command line source destination style. An example would be</p>

<p><code>bash
unison -testserver /tmp/ ssh://192.168.72.1//tmp
</code></p>

<p>The format of a source or destination is
<code>[protocol:]//[user@][host][:port][/path]</code>. The one with no host name is
supposed to your local machine. The <code>-testserver</code> option above is used to test
whether the network between the local machine and the remote machine is
reachable.</p>

<p>To avoid typing the addresses each time, since <code>unison</code> is about syncing, not
copying, <code>unison</code> offers a thing called profile. The command above, without the
<code>-testserver</code> option, converts to a profile is</p>

<p><code>
root = /home/use1/work/sync/
root = ssh://192.168.72.1//home/user1/work/sync
</code></p>

<p>For more sophisticated profiles, see the office
<a href="http://www.cis.upenn.edu/~bcpierce/unison/download/releases/stable/unison-manual.html#profile">doc</a>.</p>

<p>The question following is where do we store profiles?</p>

<p><code>unison</code> will store all its logistics files under the folder pointed by
environment variable <code>UNISON</code>, which if not specified, is <code>.unison</code> under the
<code>$HOME</code> folder. A profile file us named in the format of <code>*.prf</code>. Suppose the
above profile is saved as <code>test.prf</code>. To use that profile, type</p>

<p><code>bash
unison test
</code></p>

<p>The last thing I spent some time to figure out is how it actually sync between
machines, so it won’t mess up my data. Roughly, it adds another layer of logic
above <code>rsync</code>, which is suggested from the document</p>

<pre><code>Transfers are optimised using a version of the rsync protocol, making it ideal
for slower links. Unison has a clear and precise specification, and is
resilient to failure due to its careful handling of the replicas and its
private structures.
</code></pre>

<p>The logic is added I think is the way to get some fingerprints of the files, so
it knows which files is updated when syncing, and only sync those are really updated.</p>

<pre><code>Touching a file without changing its contents should never affect whether or
not Unison does an update. (When running with the fastcheck preference set to
true—the default on Unix systems—Unison uses file modtimes for a quick first
pass to tell which files have definitely not changed; then, for each file that
might have changed, it computes a fingerprint of the file's contents and
compares it against the last-synchronized contents. Also, the -times option
allows you to synchronize file times, but it does not cause identical files to
be changed; Unison will only modify the file times.)
</code></pre>

<p>So calling unison at either end will sync the files right.</p>

<h2 id="sync-between-more-than-machines">Sync Between More than Machines</h2>

<p>The built-in doc of <code>unison</code>, which is available via <code>unison -doc tutorial</code>,
has a section discussing how <code>unison</code> could be used to sync between more than
machines.</p>

<p>Using Unison to Synchronize More Than Two Machines</p>

<pre><code>Unison is designed for synchronizing pairs of replicas. However, it is
possible to use it to keep larger groups of machines in sync by
performing multiple pairwise synchronizations.

If you need to do this, the most reliable way to set things up is to
organize the machines into a “star topology,” with one machine
designated as the “hub” and the rest as “spokes,” and with each spoke
machine synchronizing only with the hub. The big advantage of the star
topology is that it eliminates the possibility of confusing “spurious
conflicts” arising from the fact that a separate archive is maintained
by Unison for every pair of hosts that it synchronizes.
</code></pre>

<p>I did not get what does it mean in the first reading. After that, I guess the
method it suggests is to establish a pair-wise sync among machines with certain
topology, which is to say: one needs to set up multiple profiles; each profile
sync between two machines; those machines form a topology so there is a hub
that will have a centralized sync state among all machines if you sync in the
right order.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Note on Installing Ubuntu on Newer Machines]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2016/03/08/note-on-installing-ubuntu-on-newer-machines/"/>
    <updated>2016-03-08T13:48:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2016/03/08/note-on-installing-ubuntu-on-newer-machines</id>
    <content type="html"><![CDATA[<p>This is the note supposed to note something peculiar things I met during
setting up Ubuntu on a newer machine, which is to say, with UEFI replacing
BIOS, GPT replacing MBR, Display Port and HDMI replacing VGA and DVI, and with
several GPUs.</p>

<p>Due to time reason, I fell back to my old way of installing Ubuntu, and have
not figured out what is the right way to install the newer machine mentioned
above, but the note is to note down possible guess, and the things have been
figured out, so I may have a thread to follow next time.</p>

<!-- more -->

<p>At the time I entered what was called BIOS of the machine, which is called
UEFI(Unified Extensible Firmware Interface), I was amazed that it was an almost
desktop GUI. The official lab machine of mine has a similar firmware, but since
I was not supposed to have access to it, I did not play with it much. I think
my most recent laptop should have also used UEFI, but I did not have any memory
what it is like, I guess I did not need to change things so I did not enter it.</p>

<h2 id="gpu-control-from-boot-to-os">GPU Control From Boot to OS</h2>

<p>The first thing I tried to figure out is how a GPU could be installed
properly. In other words, how could a GPU inserted in a socket could be
detected by the motherboard, then OS?</p>

<p>Normally a PC motherboard has an integrated card, and an optional discrete
graphical unit could be installed GPU card through PCIE sockets. There is a
switch in the UEFI to tell the motherboard where to look for a graphical
unit. Also, even if the GPU is not powered up, I could have a hint on the
monitor to tell me to what happened. So I think a GPU has a basic function unit
that offers motherboard basic graphical function so it could be used till the
machine boots into an OS.</p>

<p>The first problem I have met is there was no output when I connect DVI adapter
of the monitor to a TITAN Black that was inserted in the latter socket of the
motherboard, and could only get output when I connect the adapter to the GPU
inserted in the first PCIE socket. The GPU is not a TITAN Black but a 760.</p>

<p>There are two guesses why this situations happen. The first is UEFI only detect
GPU at the first PCIE socket and ignores all the remaining. This is reasonable
since no one is supposed to use multiple GPUs during boot time. But it seems I
have tried put a TITAN Black at the first socket, though I cannot clearly
remember it. So another guess is my current UEFI does not support TITAN at boot
time.</p>

<p>After the UEFI transfer the control to OS, the drivers in UEFI should not
function anymore. So drivers need to be installed in the OS.</p>

<p>The open source NVIDIA card driver, Nouveau, will be installed when installing
Ubuntu. I thought only when a NVIDIA GPU is physically inserted, its open
source driver would be installed. However, it seems the open source driver will
be installed even without a card. Maybe it is because in this case, a GPU card
could be used right after installation without re-installing kernel modules.</p>

<p>Nouveau has to be removed if I want to install the newest driver from NVIDIA
through the <code>*run</code> file, otherwise they would conflict. To do this, a file
needs to be added to <code>/etc/modprobe.d/</code> with the following contents.</p>

<p><code>
# generated by nvidia-installer
blacklist nouveau
options nouveau modeset=0
</code></p>

<p>It is actually generated by the <code>*run</code> file. I think it tells kernel not to
load nouveau module.</p>

<p>Then regenerate your kernel</p>

<p><code>
update-initramfs -u
</code></p>

<p>To completely wipe out <code>nouveau</code> — though I think even without doing it, it
would work, run the following command</p>

<p><code>
sudo apt-get remove xserver-xorg-video-nouveau
</code></p>

<p>To run <code>*run</code> file, one needs to log into a text console. A way I could find
that is commonly suggested on the web is to switch to one virtual terminal by
`Ctrl+Alt+F1’, then stop the X service</p>

<p><code>
sudo stop lightdm   or
sudo lightdm stop
</code></p>

<p>It did not work for me. So I need to reboot into text mode by editing
grub. More concretely, when the grub menu pops up, press <code>e</code> on the item, and
find <code>splash quiet</code>, and change it to <code>text</code>, then press <code>F10</code> to boot using
current edited entry.</p>

<p>One last thing before running the <code>*run</code> file. The <code>*run</code> file will build GPU
driver to kernel, but only once. So if your OS gets upgraded, you won’t be able
to log in desktop again. To work get around this, we need to install <code>dkms</code>, so
each time the kernel gets upgraded, all modules already built will be
automatically built again into the kernel.</p>

<p><code>
sudo apt-get install dkms
</code></p>

<p>All are settled, just run the <code>*run</code> file to install the driver.</p>

<p>To see what modules has been managed by <code>dkms</code>, use <code>dkms status</code>.</p>

<p>One last thing that tricked me up is to tell motherboard to use discrete
graphical unit after the driver has been installed. Otherwise, I could still
make it till the GUI login page, but after I have input my password, the screen
just flash a little, and ask me to log in again. I guess the problem is
since motherboard is configured to use integrated graphical unit, so the
discrete one is actually inactive, when <code>xorg.conf' tells </code>X11` to use the
discrete graphical unit, nothing is there. The solution is just to fall back.</p>

<p>I also have some guess on how <code>X11</code> make use of multiple GPUs. I have two
versions of <code>xorg.conf</code>, one from my official lab machine, and one from the one
I am setting up.</p>

<p>The official one</p>

<p>```
Section “Device”
    Identifier     “Device0”
    Driver         “nvidia”
    VendorName     “NVIDIA Corporation”
    BoardName      “GeForce GTX TITAN Black”
EndSection</p>

<p>Section “Device”
    Identifier     “Device1”
    Driver         “nvidia”
    VendorName     “NVIDIA Corporation”
    BoardName      “GeForce GTX TITAN Black”
    BusID          “PCI:1:0:0”
    Screen          1
EndSection
```</p>

<p>The other one is just</p>

<p><code>
Section "Device"
    Identifier     "Device0"
    Driver         "nvidia"
    VendorName     "NVIDIA Corporation"
EndSection
</code></p>

<p>The first one is generated by <code>nvidia-settings', the second one is generated by
</code>*run` file. I have three TITAN Black installed on the motherboard with the
second configuration file, and they are all functional.</p>

<p>The guess now is if no bus id is specified in <code>xorg.conf</code>, <code>X11</code> could pick any
one, and prefer to the one with lowest PCI id or GPU id.</p>

<p>A side note. To get the bus id of a card, use <code>lspci</code>, which output corresponds
to GPU is</p>

<p><code>
01:00.0 VGA compatible controller: NVIDIA Corporation GK110B [GeForce GTX TITAN Black] (rev a1)
</code></p>

<p><code>01:00.0</code> is the bus id, though I am still now know why the period becomes a colon.</p>

<h2 id="note-on-cuda">Note On CUDA</h2>

<p>After all those efforts to install NVIDIA driver through <code>*run</code> file, I found
<code>cuda</code> installation(using the network deb provided by NVIDIA) just overrided
the driver I have just installed…</p>

<p>I am not sure whether dkms will be automatically installed, or nouveau be
automatically blacklisted, though the installation of cuda does not mention it,
which is to mean they probably will take care of this. If this is so the
installation of NVIDIA driver and CUDA will be much easier.</p>

<p>I notice the <code>xorg.conf</code> is not changed after the ``new’’ driver being
installed.</p>

<h2 id="bios-mode-or-uefi-mode-ubuntu">BIOS mode or UEFI mode Ubuntu</h2>

<p>The last set of note is about installing Ubuntu in BIOS mode or UEFI mode,
which corresponds to using MBR or GPT partition table, and may be some other
difference.</p>

<p>At the time when choosing the boot media, even if your USB only has one Ubuntu
on it, the boot menu would show up as entries, one for normal BIOS mode
ubuntu(which is just named Ubuntu), one for UEFI mode(which has a UEFI in the
name). I have not tried the second one. The UEFI is a pretty new thing to me,
since the last time I learned something about it, UEFI is still in its
infancy.</p>

<p>If UEFI is chosen, the partition table of the hard disk where the boot loader
would be installed must be GPT, which is written in the new standard. The boot
loader of MBR and GPT are different(obviously). For GPT, an explicitly
formatted and allocated partition seems to be needed(not verified). As for MBR,
as everyone knows, the space for the boot loader will always be left out. Also,
to boot from a GPT partitioned disk, a boot flag need to be marked on the disk,
otherwise, OS won’t boot. There are still many other difference I have not
figured out yet.</p>

<h2 id="reference">Reference</h2>

<ol>
  <li><a href="http://www.linuxsecrets.com/blog/15questions-troubleshooting/2015/09/10/1651-how-to-remove-nouveau-and-install-nvidia-drivers">How to Remove Nouveau and Install Nvidia Drivers</a></li>
</ol>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Setting up Multi-Monitor on Gnome Ubuntu 14.04 with NVIDIA Card]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2016/01/06/setting-up-multi-monitor-on-gnome-ubuntu-14-dot-04-with-nvidia-card/"/>
    <updated>2016-01-06T08:16:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2016/01/06/setting-up-multi-monitor-on-gnome-ubuntu-14-dot-04-with-nvidia-card</id>
    <content type="html"><![CDATA[<p>I got an old monitor and spent some time tweaking the dual monitor setting of
my PC in the office. Here I note down</p>

<ol>
  <li>a tweak to make multiple monitor in Gnome functions better, and some notes
on the behavior of <code>guake</code> under multi-monitor setting.</li>
  <li>a hack to let X Windows remember the monitor layout</li>
  <li>and a short comparison between Gnome 3 and KDE Plasma 4.</li>
</ol>

<!-- more -->

<h2 id="dual-monitor-on-gnome">Dual Monitor on Gnome</h2>

<p>I uses <a href="https://www.gnome.org/">Gnome</a> as my desktop environment ever since the
time I started using Linux. So naturally, the desktop I tried this time to
manage multi-monitor support is Gnome. By default, the dual monitor worked
pretty OK. The only one thing that may need a tweak is: by default, Gnome(my
version is 3.9.90), only supports workspace in primary monitor, so when you
switch back and forth between different workspace, the secondary monitor stays
fixed on whatever it is on. This kind of makes the extra monitor many times
less useful. To make the secondary monitor attach to current workspace, so it
moves when you switch workspaces, you need to configure Gnome a little bit, by
the following command</p>

<p><code>bash
gsettings set org.gnome.shell.overrides workspaces-only-on-primary false
</code></p>

<p>One drawback of making such a change is <code>guake</code> will stay on the secondary
window forever. Did not get the time to look into the source code to know why
:(.</p>

<p><em>Updated on Jan 9, 2016.</em></p>

<strike>It is weird. `guake` functions normally now, after a reboot. This is probably
not the first time I reboot. I guess it is the package updates that fixed
something.</strike>

<p>I figured out why. When you maximize <code>guake</code> it sticks with that monitor, but
your cancel maximization, it would reconsider it position by probing which
monitor the mouse is in and set itself there.</p>

<h2 id="physical-layout-of-monitors">Physical Layout of Monitors</h2>

<p>I do not know how much it depends on operating system, drivers and
hardware. The <code>display</code>(the GUI one of Gnome) or <code>nvidia-settings</code>(the CLI one
comes with proprietary driver) forgets the monitor layout after reboot, such as
<code>DVI-I-1</code> should be on the left of <code>DVI-D-0</code>, even if I wrote it in the
<code>xorg.conf</code>.</p>

<p>Though finally I switched the monitors physically, for some other reason, and
made peace with the forgetful display manager, I struggled some time to figure
out how to make the layout right.</p>

<p>The solution I used is to use <code>xrandr</code> after the GUI session has set up by
adding a script containing the following line in the startup application of
Gnome(there is a GUI program called <code>Startup Application</code>, though I do not know
what its CLI version is).</p>

<p><code>
xrandr --output DVI-I-1 --mode 1920x1080 --right-of DVI-D-0
</code></p>

<p>I also have tried to add the above line in <code>.profile</code>, but it seems the layout
setting is decided after <code>.profile</code> is loaded, so it did not work.</p>

<p><em>Updated on Mar 8, 2016.</em></p>

<p>I seems to figured out how gnome handle layout of monitors. The one that powered
on the first will be the primary monitor, and be put on the left. The one added
later will be put at the right. So if you want to change the layout of monitors,
just disconnect the one you want to put at the right, then connect again.</p>

<h2 id="a-peak-at-kde">A Peak at KDE</h2>

<p>At the first time I tried to set <code>workspaces-only-on-primary</code> to <code>false</code>, it
did not have any effect, and first all workspaces other than the first one
started to get severe artifact when moving windows around, then even the first
one started to get artifacts. It made the desktop unusable.</p>

<p>After trying to search for an solution in Google for a while, I learned there
seems Gnome do not have any multi-monitor support at all, at least they do not
consider this a feature to be proud of at their website for Gnome 3. So I think
maybe Gnome does not work for Gnome.</p>

<p>Then some video introducing Plasma let me pay some attention to KDE
desktop. The modern design of KDE Plasma 5.5 really impressed me, though in
retrospect I was dazzled by Gnome 3’s new design at the first I saw it. It is
just the case that I have been used to Gnome 3 for such a long time and do not
feel its design at all now.</p>

<p>I installed Plasma from source by</p>

<p><code>bash
sudo apt-get install kubuntu-desktop
</code></p>

<p>This is the first time I started to feel Ubuntu 14.04 is getting old. It only
has Plasma 4.14(the minor version may not be right, but it is 4).</p>

<p>After tinkering it a little bit, though it must be the case I did not get
myself familiar with it, I have the first impression as following:</p>

<ol>
  <li>It seems to have many widgets, which is better than Gnome, whose desktop
widget feels like antiques.</li>
</ol>

<p>Besides that, I did not find an obvious solution to</p>

<ol>
  <li>multiple workspaces, which is available by default in Gnome</li>
  <li>the dash application runner(I am not sure its exact name, just you press the
<code>super</code> or <code>win</code> key in you desktop and it shows up). I tried to install
a app called <code>homerun</code>, but it just adds too much icons in the desktop and
creates too much clutters.</li>
  <li>Obvious, <code>guake</code> does not work here anymore.</li>
</ol>

<p>The above three are really killer app, and cannot not be lacking.</p>

<p>So the first impression is KDE is for the GUI users.</p>

<ol>
  <li>It has a good file manager called <code>Dolphin</code>, whose functionality is better
than <code>Nautilus</code>. But I almost do not use GUI file management since I do it
all in CLI.</li>
  <li>A similar application launcher of dash of Gnome is <code>Krunner</code>. But like
Unity, it not only search for applications, but also search for files, any
opened applications etc, which creates much clutter, though this is a
desktop user wants.</li>
  <li>Again, no easy drop-down terminal like <code>guake</code>.</li>
  <li>It adds too much clutter that may not be useful, compared with a clean wall
paper of Gnome. I think Plasma 5.5 tries to fix this, but I did not have the
chance to try.</li>
</ol>

<p>As having been said, it must be the case I am not familiar with a new desktop
environment, but I guess I will settle with it, because after I was little
frustrated with the KDE desktop, I tried to switch back to Gnome. Suddenly,
everything started to work well! Maybe it is because I installed a lot of
libraries when I was installing KDE, which fixed some problems. But now I feel
current setting, the one I mentioned at the first section of this note,
awesome.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On Code Completion & Navigation for C/C++ in Emacs]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/08/11/on-code-completion-for-c-slash-c-plus-plus/"/>
    <updated>2015-08-11T09:21:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/08/11/on-code-completion-for-c-slash-c-plus-plus</id>
    <content type="html"><![CDATA[<p>Due to the same reason that I decided to add <code>company</code> to provide faster and
more accurate completion functionality, I switched from
<a href="http://cedet.sourceforge.net/">CEDET</a> to
<a href="https://github.com/Sarcasm/irony-mode">irony</a> +
<a href="https://github.com/leoliu/ggtags">ggtags</a>.</p>

<p>Here is the note TODO</p>

<!-- more -->

<h2 id="irony">Irony</h2>

<h3 id="installation">Installation</h3>

<p>To setup <code>irony</code>, in the <a href="https://github.com/Sarcasm/irony-mode">README</a> of
<code>irony</code>’s git repo, the installation process provided by the author is pretty
workable. The only thing may need to be noted is that what packages you need to
install if you are not going to compile <code>libclang</code> from source.</p>

<p>In Ubuntu, you need those two packages: <code>libclang-dev</code> and <code>clang</code>. By
mentioning only <code>libclang</code>, it gives me the feeling that I do not need an
executable of <code>clang</code>, however, there is some errors occurs without
<code>clang</code>. But due to the trial and error when making <code>irony-mode</code> to work, I am
not sure it is really caused by lacking of <code>clang</code>.</p>

<h3 id="make-it-work">Make It Work</h3>

<p>You need to let <code>clang</code> know where to find you source file for it to parse
it. To achieve this, <code>irony</code> provides a concept called
<a href="https://github.com/Sarcasm/irony-mode#compilation-database">compilation database</a>. Refer
to it to know how to make <code>irony</code> work. The following is some remarks.</p>

<p>Basically, the most important compilation flags are the include folder path for
header files. Since <code>irony</code> does not aim to provide code navigation function,
all information it needs are in header files.</p>

<p>One problem that bugs me a lot when I was setting up <code>irony</code> is that <code>clang</code> in
<code>irony</code> and <code>gcc</code> handles <code>-I</code> flag differently. The path must immediately
follows the <code>-I</code>, with no spaces. If there are spaces, <code>irony</code> could not find
the corresponding paths.</p>

<h3 id="limitations">Limitations</h3>

<p>During my testing with <code>irony</code>, I found that it could not handle definition
with template, which is used a lot in C++ numerical library. The limitation
also makes sense since that declarations are generated dynamically during
compilation for template definition, so maybe you could not get relevant
information just by parsing the template definition.</p>

<h2 id="ggtags">ggtags</h2>

<p><a href="http://www.gnu.org/software/global/">gtags</a> is better
<a href="http://ctags.sourceforge.net/">ctags</a> in various ways. See the
<a href="https://github.com/leoliu/ggtags">table</a> provided by
<a href="https://github.com/leoliu/ggtags">ggtags</a>’s developers.</p>

<h3 id="setup-system-tags">Setup System Tags</h3>

<p>I copy this section from this
<a href="http://tuhdo.github.io/c-ide.html#sec-7-2">tutorial</a> in case I may forget it.</p>

<p><code>GNU Global</code> has an environment variable named <code>GTAGSLIBPATH</code>. This variable holds
<code>GTAGS</code> database of external libraries that your project depends on but not
inside your project. For example, your project may rely on system headers such
as <code>stdio.h</code>, <code>stdlib.h</code>… but these headers are internal to your project. However,
remember that you can only jump to tag definitions of external dependencies,
and nothing else (such as files or references). But, again, once you are inside
the external library, you can start jumping around sicne it becomes your
current project.</p>

<p>To make <code>GNU Global</code> sees your system headers, follow these steps:</p>

<p>Export this environment variable in your shell init file, such as <code>.bashrc</code> or
<code>.zshrc</code>:</p>

<p><code>bash
export GTAGSLIBPATH=$HOME/.gtags/
</code></p>

<p>Execute these commands in your terminal:</p>

<p>```bash
# Create a directory for holding database, since
# you cannot create a database in your system paths
mkdir ~/.gtags</p>

<h1 id="create-symbolic-links-to-your-external-libraries">Create symbolic links to your external libraries</h1>
<p>ln -s /usr/include usr-include
ln -s /usr/local/include/ usr-local-include</p>

<h1 id="generate-gnu-global-database">Generate GNU Global database</h1>
<p>gtags -c
```</p>

<p>The <code>-c</code> option tells <code>GNU Global</code> to generate tag database in compact format. It
is necessary because if your project contains C++ headers like <code>Boost</code>, without
<code>-c</code> your <code>GTAGS</code> database can be more than 1 GB. Same goes for <code>ctags</code>. The <code>GNU
Global</code> devs explained that it is because the <code>GTAGS</code> database includes the image
of tagged line, and the <code>Boost</code> headers have a lot of very long lines.</p>

<p>After all the above steps, restart with a shell loaded with that variable. To
verify Emacs gets the variable, <code>M-x getenv</code> and enter <code>GTAGSLIBPATH</code> and see
if your predefined value is available. Executing <code>ggtags-find-tag-dwim</code> or
<code>helm-gtags-dwim</code> jumps to the definition of a system tag like a normal tag.</p>

<p>The disadvantage of using <code>GNU Global</code> is that currently it cannot include
files without extension. In the C++ system include directory like
<code>/usr/include/c++/4.8/</code>, it contains files without extension such as
<code>iostream</code>, <code>string</code>, <code>set</code>, <code>map</code>…. so you can write <code>#include</code> directives
without having to append <code>.h</code> at the end. <code>GNU Global</code> devs are considering to
add support for this use case.</p>

<h2 id="some-remarks">Some Remarks</h2>

<ul>
  <li><code>semantic-mode</code> is still used to provide method overview for ECB. It is
configured to only parse current buffer, which is rather acceptable in speed.</li>
  <li>If you want to know more about CEDET, here is
<a href="http://alexott.net/en/writings/emacs-devenv/EmacsCedet.html">a nice introductory post</a>
explaining it.</li>
  <li>Though <code>CEDET</code> gets disabled, company still takes advantage of some part of
tools provided by <code>CEDET</code>. One of them is
<a href="http://cedet.sourceforge.net/ede.shtml">EDE</a>, the project
manager. See the github README page of
<a href="https://github.com/randomphrase/company-c-headers">company-c-headers</a> to see
how could you use <code>EDE</code> to tell <code>company</code> to use system include path.</li>
  <li><a href="https://github.com/emacs-helm/helm">helm</a> is an alternative to
<a href="https://www.masteringemacs.org/article/introduction-to-ido-mode">ido</a>. Maybe
it could be tried while I have more time.</li>
  <li><a href="https://github.com/abingham/emacs-ycmd">emacs-ycmd</a> is another completion
framework for Emacs.</li>
  <li><code>irony</code> offers a flychecker, since I already uses the google style and
cpplint, I will not try <code>flycheck-irony</code> for the time being, though it may
offer advantages such as full compilation error detection.</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On Auto Completion in Emacs]]></title>
    <link href="http://shawnLeeZX.github.io/blog/2015/08/11/on-auto-completion-in-emacs/"/>
    <updated>2015-08-11T09:07:00+08:00</updated>
    <id>http://shawnLeeZX.github.io/blog/2015/08/11/on-auto-completion-in-emacs</id>
    <content type="html"><![CDATA[<p>Just finished setting up Emacs using
<a href="http://company-mode.github.io/">company</a> to do auto-completion. Here I would
like to note down the reason why I made the shift from
<a href="https://github.com/auto-complete/auto-complete">auto-complete</a> to <code>company</code>
for programming. However, for tasks like writing configuration file, LaTeX
documents or markdown note, I still use <code>auto-complete</code>.</p>

<!-- more -->

<h2 id="comparison-between-company-and-auto-complete">Comparison Between <code>company</code> and <code>auto-complete</code></h2>

<p>At the first iteration of my Emacs configuration for C/C++, I followed the
following three videos to get a basic setup:</p>

<ul>
  <li><a href="https://www.youtube.com/watch?v=HTUE03LnaXA">Emacs as a C/C++ Editor/IDE (Part I): auto-complete, yasnippet, and autoplete</a></li>
  <li><a href="https://www.youtube.com/watch?v=r_HW0EB67eY">Emacs as a C/C++ Editor/IDE (Part 2): iedit, flymake-google-cpplint, google-c-style</a></li>
  <li><a href="https://www.youtube.com/watch?v=Ib914gNr0ys">Emacs as a C/C++ Editor/IDE (Part 3): Installing CEDET mode for true intellisense</a></li>
</ul>

<p>which introduces the <code>auto-complete</code> for doing automatically completion.</p>

<p>At the same time, the extension
 <a href="https://github.com/tkf/emacs-jedi">emacs-jedi</a> only supports <code>auto-complete</code>
backend. And <code>emacs-jedi</code> is the only python code completion extension for
Emacs at then, which turns out that there were a number of others I did not
notice(see previously post on Python in Emacs). So I decided to use
auto-complete.</p>

<p>Then as the projects I worked on got bigger, the possible candidates provided
by <code>auto-complete</code> becomes too large to be useful due to the reason that
<code>auto-complete</code> will fetch all candidates from all sources.</p>

<p>The same problem happens to <code>auto-complete</code> in file path completion as
well. You get a lot of non-sense completion when you only want to get
completion in the path you want, which is a rather narrow space in the whole
space of all your possible completion candidates.</p>

<p>There could be a way to dynamically change the order of sources, but <code>company</code>
seems to do this automatically or people writes the backends for <code>company</code> do
this. In whatever case, the user does not need to attend to those things.</p>

<p>That is not the fatal problem yet, <code>auto-complete</code> has a annoying problem which
I do not know how to fix is that the time needed for the completion list to
respond to new input is at the magnitude of seconds. I am pretty sure this is
not a performance problem given that the completion list comes up pretty fast.</p>

<p><code>company</code> also solves the file completion problem and c headers completion
problem by providing a separate function in their respective backends, which I
just need to map another key binding to it so the completion will be very
accurate when you are programming.</p>

<p><code>auto-complete</code> does good when you are writing text heavy contents such as
LaTeX or markdown but not logically heavy ones such as programming language.</p>

<p>For a more complete comparison you could refer to the end of the 
<a href="http://company-mode.github.io/">github page</a> of <code>company</code>.</p>

<h2 id="on-using-them-together">On Using Them Together</h2>

<p>One more realization is that those two extensions are not exclusive at all. I
did not find a backend like the sources provided by <code>auto-complete</code> for
complete word in buffers related functions, which is the area <code>auto-complete</code> 
works well.</p>

<p>Below is some sample on how to use them from my
<a href="https://github.com/shawnLeeZX/emacs.d">Emacs configuration</a>.</p>

<p>```cl
(add-hook ‘after-init-hook ‘global-company-mode)</p>

<p>;;   “Modes for which <code>company-mode' mode is turned on by
;; </code>global-company-mode’.  If nil, means no modes.  If t, then all major modes
;; have it turned on.  If a list, it should be a list of <code>major-mode' symbol
;; names for which </code>company-mode’ should be automatically turned on.  The sense
;; of the list is negated if it begins with <code>not'.  For example: (c-mode
;; c++-mode) means that </code>company-mode’ is turned on for buffers in C and C++
;; modes only.  (not message-mode) means that <code>company-mode' is always turned
;; on except in </code>message-mode’ buffers.”
(setq company-global-modes ‘(
                            c-mode
                            c++-mode
                            ))
```</p>

<p><code>cl
;; Enable auto-complete for modes in ac-modes by default.
(global-auto-complete-mode t)
;; We reset the default mode for auto-complete given that we want to some modes
;; to use company-mode.
(set-default 'ac-modes
             '(
               magit-log-edit-mode
               log-edit-mode org-mode text-mode haml-mode
               git-commit-mode
               conf-mode conf-unix-mode conf-colon-mode
               inferior-emacs-lisp-mode inferior-python-mode
               sql-interactive-mode
               sass-mode yaml-mode csv-mode espresso-mode haskell-mode
               html-mode nxml-mode smarty-mode clojure-mode
               lisp-mode textile-mode markdown-mode tuareg-mode
               js3-mode css-mode less-css-mode sql-mode
               web-mode
               ))
</code></p>

<h2 id="difference-between-tab-and-tab">Difference Between <tab> and TAB</tab></h2>

<p>The last thing I want to note down is that TAB key.</p>

<p>Emacs has two tabs, <code>(kbd "&lt;tab&gt;")</code> and <code>(kbd "TAB")</code>. To make things more
complex, <code>yasnippet</code>, <code>auto-complete</code>, indentation in Emacs, typing real tab
stops and <code>company</code> all uses <code>tab</code>, which makes it very complicated.</p>

<p>From this
<a href="https://www.reddit.com/r/emacs/comments/2aemny/difference_between_tab_and_tab/">thread</a>
in Reddit, here, I knew that <code>(kbd "&lt;tab&gt;")</code> stands for the physical key you
have pressed and <code>(kbd "TAB")</code> stands for the control character. So to speak,
normally, if you are not binding <code>&lt;tab&gt;</code> to <code>TAB</code>, the tab you typed is not
actually the control character TAB, but triggers some function that is hooked
on the physical key’s response.</p>

<p>As for the second part of the puzzle, when you are typing tab at a location
where the indentation of the statement is not right, Emacs will indent your
line first. The key to differentiate <code>yasnippet</code> and <code>auto-complete</code> is whether
you are typing or not when you pressed the tab key. If you are, completion menu
will be triggered, if you are not <code>yasnippet</code> will be triggered(this is a
mechanism that could be configured in auto-complete and is not the default, by
default, I think the completion menu will pop up automatically). As for
<code>company</code> and <code>yasnippet</code>, in my experiments, after setting the trigger key to
tab, by default it seems that snippets are always gotten expanded the first,
then <code>company-complete</code> will be triggered if no snippets could be found. See
the following code snippets for how to set up key binding for <code>company</code>(it only
uses <code>company</code> if <code>irony-mode</code> is in usage).</p>

<p><code>cl
;; Setup keymapping for company-complete.
(add-hook 'irony-mode-hook (lambda ()
                             (local-set-key (kbd "&lt;tab&gt;") 'company-complete-common)
                             (local-set-key (kbd "C-c C-f") 'company-files)
                             ))
</code></p>

<h2 id="reference">Reference</h2>

<ul>
  <li><a href="https://www.youtube.com/watch?v=HTUE03LnaXA">Emacs as a C/C++ Editor/IDE (Part I): auto-complete, yasnippet, and autoplete</a></li>
  <li><a href="https://www.youtube.com/watch?v=r_HW0EB67eY">Emacs as a C/C++ Editor/IDE (Part 2): iedit, flymake-google-cpplint, google-c-style</a></li>
  <li><a href="https://www.youtube.com/watch?v=Ib914gNr0ys">Emacs as a C/C++ Editor/IDE (Part 3): Installing CEDET mode for true intellisense</a></li>
  <li><a href="http://tuhdo.github.io/c-ide.html">tutorial on customizing C/C++ environment for emacs</a></li>
  <li><a href="https://www.masteringemacs.org/article/mastering-key-bindings-emacs">Mastering Key Bindings in Emacs</a></li>
</ul>
]]></content>
  </entry>
  
</feed>
